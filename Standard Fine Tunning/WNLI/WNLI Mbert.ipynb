{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db5abe51-5df4-4a98-9920-22c650445a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "007e38cc-ab3d-46d6-83da-3bf9ef584a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2 — Load WNLI TRAIN\n",
    "train_path = r\"C:\\Users\\areesa\\Documents\\Urdu_GLUE_xlm_roberta\\data\\raw\\U-WNLI\\WNLI_train_urdu-2 - Final.tsv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb8d104-0246-45f6-925b-26d1c023be90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((639, 4),\n",
       " Index(['Unnamed: 0', 'label', 'sentence1_urdu', 'sentence2_urdu'], dtype='object'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.3 — Inspect TRAIN schema\n",
    "train_df.shape, train_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dda1e151-46dd-43b0-8818-46fac6fd9435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence1_urdu</th>\n",
       "      <th>sentence2_urdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ہنری کئی بار ان انٹرویوز میں موجود رہا تھا جو ...</td>\n",
       "      <td>وہ مواقع ہنری کے لیے سرخ حروف والے دنوں کے طور...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ہنری کئی بار ان انٹرویوز میں موجود رہا تھا جو ...</td>\n",
       "      <td>وہ مواقع والد کے لیے یادگار اور خاص دنوں کی حی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک...</td>\n",
       "      <td>آدم اس وقت تک چلا جائے گا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک...</td>\n",
       "      <td>باب اس وقت تک چلا جائے گا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک...</td>\n",
       "      <td>باب اس وقت تک یہاں پہنچ چکا ہوگا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک...</td>\n",
       "      <td>آدم اس وقت تک یہاں پہنچ چکا ہوگا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک...</td>\n",
       "      <td>باب اس وقت تک یہاں پہنچ چکا ہوگا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ایلس نے ہجوم میں اپنی دوست جیڈ کو تلاش کیا ۔ چ...</td>\n",
       "      <td>چونکہ جیڈ ہمیشہ خوش قسمت رہتی ہے ، اس لیے ایلس...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ایلس نے ہجوم میں اپنی دوست جیڈ کو تلاش کیا ۔ چ...</td>\n",
       "      <td>چونکہ ایلس ہمیشہ خوش قسمت رہتی ہے ، اس لیے ایل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ایلس نے ہجوم میں اپنی دوست جیڈ کو تلاش کیا ۔ چ...</td>\n",
       "      <td>چونکہ جیڈ ہمیشہ سرخ پگڑی پہنتی ہے ، اس لیے ایل...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label                                     sentence1_urdu  \\\n",
       "0           1    1.0  ہنری کئی بار ان انٹرویوز میں موجود رہا تھا جو ...   \n",
       "1           2    0.0  ہنری کئی بار ان انٹرویوز میں موجود رہا تھا جو ...   \n",
       "2           3    1.0  آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک...   \n",
       "3           4    0.0  آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک...   \n",
       "4           5    1.0  آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک...   \n",
       "5           6    0.0  آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک...   \n",
       "6           7    1.0  آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک...   \n",
       "7           8    0.0  ایلس نے ہجوم میں اپنی دوست جیڈ کو تلاش کیا ۔ چ...   \n",
       "8           9    1.0  ایلس نے ہجوم میں اپنی دوست جیڈ کو تلاش کیا ۔ چ...   \n",
       "9          10    1.0  ایلس نے ہجوم میں اپنی دوست جیڈ کو تلاش کیا ۔ چ...   \n",
       "\n",
       "                                      sentence2_urdu  \n",
       "0  وہ مواقع ہنری کے لیے سرخ حروف والے دنوں کے طور...  \n",
       "1  وہ مواقع والد کے لیے یادگار اور خاص دنوں کی حی...  \n",
       "2                        آدم اس وقت تک چلا جائے گا ۔  \n",
       "3                        باب اس وقت تک چلا جائے گا ۔  \n",
       "4                 باب اس وقت تک یہاں پہنچ چکا ہوگا ۔  \n",
       "5                 آدم اس وقت تک یہاں پہنچ چکا ہوگا ۔  \n",
       "6                 باب اس وقت تک یہاں پہنچ چکا ہوگا ۔  \n",
       "7  چونکہ جیڈ ہمیشہ خوش قسمت رہتی ہے ، اس لیے ایلس...  \n",
       "8  چونکہ ایلس ہمیشہ خوش قسمت رہتی ہے ، اس لیے ایل...  \n",
       "9  چونکہ جیڈ ہمیشہ سرخ پگڑی پہنتی ہے ، اس لیے ایل...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.4 — First look at TRAIN\n",
    "train_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c6225c9-307e-482d-ae37-c56b14e703bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0., nan])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.5 — Label sanity check (TRAIN)\n",
    "train_df[\"label\"].value_counts(dropna=False)\n",
    "train_df[\"label\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c10120a-7948-4a38-8b72-f3c695a1025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 — DEV DATASET INSPECTION (mBERT)\n",
    "# 1.1 — Load DEV\n",
    "dev_path = r\"C:\\Users\\areesa\\Documents\\Urdu_GLUE_xlm_roberta\\data\\raw\\U-WNLI\\Copy of WNLI_dev_urdu-2 - dev_urdu-2.tsv\"\n",
    "\n",
    "dev_df = pd.read_csv(dev_path, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c125cfa5-2340-424b-9d01-99956ac20e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((71, 3), Index(['label', 'Sentence1', 'Sentence2'], dtype='object'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2 — Inspect DEV schema\n",
    "dev_df.shape, dev_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6daa8e6-9815-4e6a-8b31-e9bad7c8489d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>نالی بالوں سے بھری ہوئی ہے۔ اسے صاف کرنا ہوگا۔</td>\n",
       "      <td>بالوں کو صاف کرنا پڑتا ہے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>جین نے سوسن کا دروازہ کھٹکھٹایا لیکن اس نے کوئ...</td>\n",
       "      <td>سوسن نے کوئی جواب نہیں دیا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>بیتھ سیلی سے ناراض نہیں ہوئی جس نے اسے کاٹ دیا...</td>\n",
       "      <td>سیلی رک گئی اور دس تک گنتی کی ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>کوئی بھی فیس بک اس لیے استعمال نہیں کرتا کہ وہ...</td>\n",
       "      <td>فیس بک ہمیں بالکل ایسا ہی محسوس کراتا ہے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>وہ آدمی اپنے بیٹے کو اٹھا نہیں سکتا تھا کیونکہ...</td>\n",
       "      <td>بیٹا بہت بھاری تھا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>سوسن جانتی تھی کہ این کا بیٹا کار حادثے میں تھ...</td>\n",
       "      <td>این نے اسے اس کے بارے میں بتایا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>جب ٹومی نے اپنی آئس کریم ٹمی کو گرا دیا تو اس ...</td>\n",
       "      <td>والد نے ٹمی کو سخت نظر سے دیکھا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>میرے اور اسٹیج کے درمیان ایک ستون ہے اور میں ا...</td>\n",
       "      <td>میں ستون کے ارد گرد نہیں دیکھ سکتا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>اس ڈک کے بالکل نیچے ایک مینو تیراکی ہے اسے بہت...</td>\n",
       "      <td>بہتر ہے کہ ڈک تیزی سے محفوظ مقام پر چلا جائے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>برنارڈ جس نے سرکاری اہلکار کو یہ نہیں بتایا تھ...</td>\n",
       "      <td>جو کوئی بھی جانتا تھا کہ اس کی عمر 19 سال ہے و...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          Sentence1  \\\n",
       "0      0     نالی بالوں سے بھری ہوئی ہے۔ اسے صاف کرنا ہوگا۔   \n",
       "1      1  جین نے سوسن کا دروازہ کھٹکھٹایا لیکن اس نے کوئ...   \n",
       "2      0  بیتھ سیلی سے ناراض نہیں ہوئی جس نے اسے کاٹ دیا...   \n",
       "3      1  کوئی بھی فیس بک اس لیے استعمال نہیں کرتا کہ وہ...   \n",
       "4      1  وہ آدمی اپنے بیٹے کو اٹھا نہیں سکتا تھا کیونکہ...   \n",
       "5      0  سوسن جانتی تھی کہ این کا بیٹا کار حادثے میں تھ...   \n",
       "6      1  جب ٹومی نے اپنی آئس کریم ٹمی کو گرا دیا تو اس ...   \n",
       "7      1  میرے اور اسٹیج کے درمیان ایک ستون ہے اور میں ا...   \n",
       "8      0  اس ڈک کے بالکل نیچے ایک مینو تیراکی ہے اسے بہت...   \n",
       "9      0  برنارڈ جس نے سرکاری اہلکار کو یہ نہیں بتایا تھ...   \n",
       "\n",
       "                                           Sentence2  \n",
       "0                        بالوں کو صاف کرنا پڑتا ہے ۔  \n",
       "1                       سوسن نے کوئی جواب نہیں دیا ۔  \n",
       "2                    سیلی رک گئی اور دس تک گنتی کی ۔  \n",
       "3         فیس بک ہمیں بالکل ایسا ہی محسوس کراتا ہے ۔  \n",
       "4                               بیٹا بہت بھاری تھا ۔  \n",
       "5                  این نے اسے اس کے بارے میں بتایا ۔  \n",
       "6                  والد نے ٹمی کو سخت نظر سے دیکھا ۔  \n",
       "7               میں ستون کے ارد گرد نہیں دیکھ سکتا ۔  \n",
       "8     بہتر ہے کہ ڈک تیزی سے محفوظ مقام پر چلا جائے ۔  \n",
       "9  جو کوئی بھی جانتا تھا کہ اس کی عمر 19 سال ہے و...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3 — First look at DEV\n",
    "dev_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66cfa88b-5c44-47fa-a348-64917741675a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.4 — Label sanity check (DEV)\n",
    "dev_df[\"label\"].value_counts(dropna=False)\n",
    "dev_df[\"label\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de8082de-0990-4ec2-a135-9081858e7e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 — Load TEST (safe method)\n",
    "test_path = r\"C:\\Users\\areesa\\Documents\\Urdu_GLUE_xlm_roberta\\data\\raw\\U-WNLI\\Copy of WNLI_test_urdu-3 - test_urdu-3.tsv\"\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    test_path,\n",
    "    sep=\"\\t\",\n",
    "    engine=\"python\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "559cf28e-0e82-47bb-a2aa-de31dbfa1493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), Index(['index', 'sentence1', 'sentence2'], dtype='object'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.2 — Inspect TEST schema\n",
    "test_df.shape, test_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c04578d-f025-43f6-b8af-d260935721b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>موڈ اور ڈورا کے نظر آنے پر گھوڑے بھاگ گئے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>ٹرینیں نظر آنے پر گھوڑے بھاگ گئے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>پف نظر آنے پر گھوڑے بھاگ گئے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>گرج کی آواز سنائی دینے پر گھوڑے بھاگ گئے۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>سیٹی نظر آنے پر گھوڑے بھاگ گئے۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>گھوڑے نظر آنے پر گھوڑے بھاگ گئے۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>موڈ اور ڈورا نے ایک ٹرین کو آتے ہوئے دیکھا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>ٹرینوں نے ایک ٹرین کو آتے ہوئے دیکھا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>دھوئیں کے مرغولوں نے ایک ٹرین کو آتے ہوئے دیکھا۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>گرجنے والوں نے ایک ٹرین کو آتے دیکھا ۔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index                                          sentence1  \\\n",
       "0     0  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "1     1  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "2     2  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "3     3  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "4     4  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "5     5  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "6     6  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "7     7  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "8     8  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "9     9  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "\n",
       "                                          sentence2  \n",
       "0       موڈ اور ڈورا کے نظر آنے پر گھوڑے بھاگ گئے ۔  \n",
       "1                ٹرینیں نظر آنے پر گھوڑے بھاگ گئے ۔  \n",
       "2                    پف نظر آنے پر گھوڑے بھاگ گئے ۔  \n",
       "3         گرج کی آواز سنائی دینے پر گھوڑے بھاگ گئے۔  \n",
       "4                   سیٹی نظر آنے پر گھوڑے بھاگ گئے۔  \n",
       "5                  گھوڑے نظر آنے پر گھوڑے بھاگ گئے۔  \n",
       "6      موڈ اور ڈورا نے ایک ٹرین کو آتے ہوئے دیکھا ۔  \n",
       "7            ٹرینوں نے ایک ٹرین کو آتے ہوئے دیکھا ۔  \n",
       "8  دھوئیں کے مرغولوں نے ایک ٹرین کو آتے ہوئے دیکھا۔  \n",
       "9            گرجنے والوں نے ایک ٹرین کو آتے دیکھا ۔  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.3 — First look at TEST\n",
    "test_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7d91f13-2982-4c5f-84ba-89c0c335a471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'sentence1', 'sentence2'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.4 — Verify TEST labels (should NOT exist)\n",
    "test_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f153af3-b0bd-4c04-8602-03ed41a2fd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 151)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.5 — Count skipped lines\n",
    "with open(test_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "len(test_df), total_lines\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bd4df86-a3af-4d6e-98d0-6be27e9636d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 — Clean TRAIN dataset\n",
    "# 3.1.1 Drop index column\n",
    "train_df = train_df.drop(columns=[\"Unnamed: 0\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9723560e-b978-4bc6-8630-0bc37b676b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.2 Drop row with missing label\n",
    "train_df = train_df.dropna(subset=[\"label\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ef046f5-6b5a-497d-a4cc-14ad8a8277e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.3 Convert labels to integer\n",
    "train_df[\"label\"] = train_df[\"label\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f8ab1d8-e07d-477f-976e-869a497c6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.4 Rename sentence columns\n",
    "train_df = train_df.rename(columns={\n",
    "    \"sentence1_urdu\": \"sentence1\",\n",
    "    \"sentence2_urdu\": \"sentence2\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "056c4859-1428-47e9-b04c-66a07839b0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1.5 Verify TRAIN after cleaning\n",
    "train_df.shape\n",
    "train_df.columns\n",
    "train_df[\"label\"].value_counts()\n",
    "train_df[\"label\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efd66bba-eba9-49e0-abe2-648280f8c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.1 Rename sentence columns\n",
    "dev_df = dev_df.rename(columns={\n",
    "    \"Sentence1\": \"sentence1\",\n",
    "    \"Sentence2\": \"sentence2\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f543441-9eee-4ea9-84c6-7428e4ce7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.2 Ensure label type is integer\n",
    "dev_df[\"label\"] = dev_df[\"label\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01699c3d-186a-4032-a2b6-a282252222c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2.3 Verify DEV after cleaning\n",
    "dev_df.shape\n",
    "dev_df.columns\n",
    "dev_df[\"label\"].value_counts()\n",
    "dev_df[\"label\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94d7f19d-d4ef-446d-a8ad-c61048451b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3.1 Drop index column\n",
    "test_df = test_df.drop(columns=[\"index\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98c3a2f6-8fcf-4088-87f0-43c2586fb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3.2 Ensure sentence columns are strings\n",
    "for col in [\"sentence1\", \"sentence2\"]:\n",
    "    test_df[col] = test_df[col].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76b4955a-ed6c-4ff8-81a5-0caf09acfd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>موڈ اور ڈورا کے نظر آنے پر گھوڑے بھاگ گئے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>ٹرینیں نظر آنے پر گھوڑے بھاگ گئے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>پف نظر آنے پر گھوڑے بھاگ گئے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>گرج کی آواز سنائی دینے پر گھوڑے بھاگ گئے۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...</td>\n",
       "      <td>سیٹی نظر آنے پر گھوڑے بھاگ گئے۔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "1  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "2  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "3  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "4  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے...   \n",
       "\n",
       "                                     sentence2  \n",
       "0  موڈ اور ڈورا کے نظر آنے پر گھوڑے بھاگ گئے ۔  \n",
       "1           ٹرینیں نظر آنے پر گھوڑے بھاگ گئے ۔  \n",
       "2               پف نظر آنے پر گھوڑے بھاگ گئے ۔  \n",
       "3    گرج کی آواز سنائی دینے پر گھوڑے بھاگ گئے۔  \n",
       "4              سیٹی نظر آنے پر گھوڑے بھاگ گئے۔  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.3.3 Verify TEST after cleaning\n",
    "test_df.shape\n",
    "test_df.columns\n",
    "test_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f00282c-8705-4391-877a-7275b5072b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\anaconda3\\envs\\urdu_glue_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 4 — Create HuggingFace Datasets (WNLI + mBERT)\n",
    "# 4.1 Create HF datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(\n",
    "    train_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "dev_dataset = Dataset.from_pandas(\n",
    "    dev_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(\n",
    "    test_df[[\"sentence1\", \"sentence2\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a782c100-3f59-439b-80bc-71351f752152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2'],\n",
       "    num_rows: 150\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.2 Quick sanity check\n",
    "train_dataset\n",
    "dev_dataset\n",
    "test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38b9cbc1-74a8-44f5-9e57-2f280bed8f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'نالی بالوں سے بھری ہوئی ہے۔ اسے صاف کرنا ہوگا۔',\n",
       " 'sentence2': 'بالوں کو صاف کرنا پڑتا ہے ۔',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]\n",
    "dev_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61ec9af7-e276-4581-9cd7-937087847d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Load mBERT tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eef2865f-4f65-410d-9254-21d09c3faecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Define tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence1\"],\n",
    "        examples[\"sentence2\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b13507cc-c2df-4def-acb4-666e8d479d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Defensive casting\n",
    "for col in [\"sentence1\", \"sentence2\"]:\n",
    "    train_df[col] = train_df[col].astype(str)\n",
    "    dev_df[col] = dev_df[col].astype(str)\n",
    "    test_df[col] = test_df[col].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b55c3df-1bd1-46a7-9511-6a11724a32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Re-create HF datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(\n",
    "    train_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "dev_dataset = Dataset.from_pandas(\n",
    "    dev_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(\n",
    "    test_df[[\"sentence1\", \"sentence2\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "383f8d46-e38e-49e8-9f6c-6f05fb671e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████| 638/638 [00:00<00:00, 13342.87 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████| 71/71 [00:00<00:00, 8870.88 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████| 150/150 [00:00<00:00, 13406.33 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 5.5 Tokenize TRAIN / DEV / TEST\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
    "dev_tokenized   = dev_dataset.map(tokenize_function, batched=True)\n",
    "test_tokenized  = test_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "caa46eca-8421-4304-bd5a-292ee0c464ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.6 Set PyTorch format\n",
    "cols = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "\n",
    "train_tokenized.set_format(type=\"torch\", columns=cols)\n",
    "dev_tokenized.set_format(type=\"torch\", columns=cols)\n",
    "\n",
    "test_tokenized.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6202aef5-67dc-4c50-b1a2-4cd111f48940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(0),\n",
       " 'input_ids': tensor([  101, 20224, 10278, 10909, 29426, 13185, 11689,   764, 63764, 10278,\n",
       "         33994, 10861,   837, 43632,   777, 18562, 65409, 18779, 47238,   837,\n",
       "           102, 10909, 29426, 13185, 13244,   777, 18562, 65409,   817, 28971,\n",
       "         17821, 10861,   837,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.7 Sanity check\n",
    "train_tokenized[0]\n",
    "dev_tokenized[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5efdd5-a913-4857-acc3-27c9d8d6deed",
   "metadata": {},
   "source": [
    "# ZERO-SHOT WNLI (mBERT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52fca32d-dc0f-4b1f-9d97-388874e257af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Load mBERT model (binary classification)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"not_entailment\", 1: \"entailment\"},\n",
    "    label2id={\"not_entailment\": 0, \"entailment\": 1}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a481e116-b70f-4200-9ebd-60c0f8ac0582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Freeze encoder (CRITICAL for zero-shot)\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98287bcf-a175-46fa-9d66-d03ed01b66eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.requires_grad for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "323e62c0-c8a1-490e-987e-8286f78dcd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Metrics (Accuracy + Macro-F1)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f0045b6-2aa7-4d29-9ec1-f9fa7484c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4 TrainingArguments — SAME STANDARD PIPELINE\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_wnli_zero_mb = TrainingArguments(\n",
    "    output_dir=\"./wnli_zero_shot_mbert\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=20,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3efcda9e-82fa-4311-b0f5-c1412f06e117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_49204\\2518463092.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_zero_mb = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# 6.5 Trainer\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_zero_mb = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_wnli_zero_mb,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=dev_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8cc3624b-b845-4cb5-be10-fce4c41b7013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 00:24, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.696400</td>\n",
       "      <td>0.689020</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.470013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.689130</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.470013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.694500</td>\n",
       "      <td>0.689378</td>\n",
       "      <td>0.577465</td>\n",
       "      <td>0.461032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>0.689082</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.470013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.693700</td>\n",
       "      <td>0.689357</td>\n",
       "      <td>0.577465</td>\n",
       "      <td>0.461032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.689914</td>\n",
       "      <td>0.605634</td>\n",
       "      <td>0.526667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.695300</td>\n",
       "      <td>0.690168</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.495762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.692600</td>\n",
       "      <td>0.690677</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.473182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.690588</td>\n",
       "      <td>0.521127</td>\n",
       "      <td>0.484188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.693400</td>\n",
       "      <td>0.690547</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.506087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.693500</td>\n",
       "      <td>0.690671</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.495152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.693300</td>\n",
       "      <td>0.690904</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.462121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.694400</td>\n",
       "      <td>0.690801</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.462121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.694700</td>\n",
       "      <td>0.690994</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.480669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.692700</td>\n",
       "      <td>0.690966</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.462121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>0.690993</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.480669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.693900</td>\n",
       "      <td>0.691007</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.469269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.695900</td>\n",
       "      <td>0.691055</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.469269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>0.691055</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.469269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.694600</td>\n",
       "      <td>0.691014</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.469269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=0.6943538618087769, metrics={'train_runtime': 24.4208, 'train_samples_per_second': 522.505, 'train_steps_per_second': 16.379, 'total_flos': 839324266598400.0, 'train_loss': 0.6943538618087769, 'epoch': 20.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_zero_mb.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a0785a0-0cd0-4740-8de8-b6c04a45c2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6899139881134033,\n",
       " 'eval_accuracy': 0.6056338028169014,\n",
       " 'eval_f1': 0.5266666666666666,\n",
       " 'eval_runtime': 0.0583,\n",
       " 'eval_samples_per_second': 1217.983,\n",
       " 'eval_steps_per_second': 51.464,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_results_wnli_mb = trainer_zero_mb.evaluate()\n",
    "zero_shot_results_wnli_mb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1133c33a-8e68-41f7-8d7b-e4ab53d55638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16-SHOT WNLI (mBERT)\n",
    "# 7.1 — Create 16-shot dataset\n",
    "fewshot_df = (\n",
    "    train_df\n",
    "    .groupby(\"label\", sort=False)\n",
    "    .head(16)\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1dbdd6f6-0527-4741-9207-baa4c6705def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    16\n",
       "0    16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.2 — Verify balance\n",
    "fewshot_df.shape\n",
    "fewshot_df[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "985d9fa4-1ecf-4387-bfb4-c3121dc9268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 — Convert to HF Dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "fewshot_dataset = Dataset.from_pandas(\n",
    "    fewshot_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f8e3fd2-a8f2-4daa-8c66-bf3a0000ad0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'ہنری کئی بار ان انٹرویوز میں موجود رہا تھا جو اس کے والد نے معروف جاسوسوں کے ساتھ کیے تھے جو پیچیدہ اسرار کو حل کرنے میں اس کی مدد چاہتے تھے اور وہ مواقع اس کے لیے سرخ حروف کے دنوں کے طور پر کھڑے تھے ۔',\n",
       " 'sentence2': 'وہ مواقع ہنری کے لیے سرخ حروف والے دنوں کے طور پر نمایاں تھے ۔',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fewshot_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed19df9b-88ca-48aa-8cbb-809dc91dfbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 4996.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 7.4 — Tokenize 16-shot data\n",
    "fewshot_tokenized = fewshot_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "fewshot_tokenized.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "357b6639-db60-497b-8344-a4bff095f153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 7.5 — Load mBERT model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"not_entailment\", 1: \"entailment\"},\n",
    "    label2id={\"not_entailment\": 0, \"entailment\": 1}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02f0f1e1-b601-40a1-839a-5f3d0ba3b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.6 — TrainingArguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_wnli_16_mb = TrainingArguments(\n",
    "    output_dir=\"./wnli_16shot_mbert\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=20,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f0a71fff-070a-44b8-bc71-3c2e7d90eea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_49204\\2352020876.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_16_mb = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:57, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.686455</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.360360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.688635</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.427579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695533</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>0.411646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.701557</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.297030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.705147</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.297030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.705209</td>\n",
       "      <td>0.422535</td>\n",
       "      <td>0.297030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.704886</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.349542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.707248</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.374304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712973</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.374304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.721418</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.374304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.723715</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.389040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.719971</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>0.411646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.715731</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.393162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712275</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.410299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.710903</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.434552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.710962</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.422764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712117</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.422764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.713895</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.422764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.715659</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.422764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.656500</td>\n",
       "      <td>0.716745</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.434552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=0.6565288543701172, metrics={'train_runtime': 58.4362, 'train_samples_per_second': 10.952, 'train_steps_per_second': 0.342, 'total_flos': 42097768857600.0, 'train_loss': 0.6565288543701172, 'epoch': 20.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.7 — Trainer & Train\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_16_mb = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_wnli_16_mb,\n",
    "    train_dataset=fewshot_tokenized,\n",
    "    eval_dataset=dev_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer_16_mb.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6020e6ad-8fb1-48f0-b821-2fd8cb1920e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6886348724365234,\n",
       " 'eval_accuracy': 0.5915492957746479,\n",
       " 'eval_f1': 0.4275785376702808,\n",
       " 'eval_runtime': 0.0596,\n",
       " 'eval_samples_per_second': 1191.368,\n",
       " 'eval_steps_per_second': 50.34,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_16shot_wnli_mb = trainer_16_mb.evaluate()\n",
    "results_16shot_wnli_mb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6fe7f1-22f5-4eba-bb7c-298d89a89b9a",
   "metadata": {},
   "source": [
    "# 80/20 WNLI (mBERT, Full Fine-Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab5cbd06-cde7-425f-b97f-c122aeb60689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Create stratified 80/20 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_80_df, val_20_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_df[\"label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09097ec3-0570-4905-971e-493c68d21507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    65\n",
       "1    63\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_80_df.shape, val_20_df.shape\n",
    "train_80_df[\"label\"].value_counts()\n",
    "val_20_df[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e86125fe-21c6-4253-9370-11b17fe38404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.2 Convert to HuggingFace Datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "train_80_dataset = Dataset.from_pandas(\n",
    "    train_80_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "val_20_dataset = Dataset.from_pandas(\n",
    "    val_20_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7545c9e8-8e24-45fc-b159-4effd80f6f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████| 510/510 [00:00<00:00, 17472.13 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<?, ? examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 8.3 Tokenize\n",
    "train_80_tok = train_80_dataset.map(tokenize_function, batched=True)\n",
    "val_20_tok   = val_20_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "cols = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "train_80_tok.set_format(type=\"torch\", columns=cols)\n",
    "val_20_tok.set_format(type=\"torch\", columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ee07c33-c0b1-4a3d-9d01-60ad3908aeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(1),\n",
       " 'input_ids': tensor([  101, 13141, 12574, 80224, 84361, 29006, 23473, 30393, 10861, 11363,\n",
       "         25971, 98205, 21024, 12427,   789, 17317, 81330,   770, 69339, 10429,\n",
       "         10861,   837, 21035, 43867, 23523, 13244, 11722, 10916, 89826, 18779,\n",
       "         65176, 75399,   837,   102, 21035, 43867, 23523, 13244,   789, 26649,\n",
       "         84361, 10916, 89826, 18779, 65176, 75399,   837,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_80_tok[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dff5ab49-d7cd-4403-a107-274428c8d5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 8.4 Load mBERT model (FULL fine-tuning)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"not_entailment\", 1: \"entailment\"},\n",
    "    label2id={\"not_entailment\": 0, \"entailment\": 1}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7e50877f-fad2-4818-aa39-6b905fb28e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 TrainingArguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_wnli_80_mb = TrainingArguments(\n",
    "    output_dir=\"./wnli_80_20_mbert\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=20,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5352aa14-55c2-41a9-9562-139e21050d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_49204\\3472005805.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_80_mb = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [320/320 01:14, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694515</td>\n",
       "      <td>0.460938</td>\n",
       "      <td>0.460114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.699013</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.694200</td>\n",
       "      <td>0.709839</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.329843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.712833</td>\n",
       "      <td>0.414062</td>\n",
       "      <td>0.303490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.685800</td>\n",
       "      <td>0.769283</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.256733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.685800</td>\n",
       "      <td>0.915431</td>\n",
       "      <td>0.226562</td>\n",
       "      <td>0.218501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.670100</td>\n",
       "      <td>1.064350</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.207017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.645400</td>\n",
       "      <td>1.213408</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>0.179237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.592600</td>\n",
       "      <td>1.488399</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.154392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>1.470074</td>\n",
       "      <td>0.179688</td>\n",
       "      <td>0.164958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>1.735788</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>0.145883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.539700</td>\n",
       "      <td>1.928656</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.132336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.465300</td>\n",
       "      <td>2.115427</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.132760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.439400</td>\n",
       "      <td>2.298465</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>0.147136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>2.474303</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.124786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>2.669511</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.115838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>2.782733</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.132336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.308200</td>\n",
       "      <td>2.867787</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.109158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>2.951028</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.093529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>2.970556</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.093529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=320, training_loss=0.516286002099514, metrics={'train_runtime': 74.857, 'train_samples_per_second': 136.26, 'train_steps_per_second': 4.275, 'total_flos': 670933191168000.0, 'train_loss': 0.516286002099514, 'epoch': 20.0})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8.6 Trainer & Run\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_80_mb = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_wnli_80_mb,\n",
    "    train_dataset=train_80_tok,\n",
    "    eval_dataset=val_20_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer_80_mb.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "131266ee-9d63-4025-aff7-30d92338b7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6990127563476562,\n",
       " 'eval_accuracy': 0.5078125,\n",
       " 'eval_f1': 0.33678756476683935,\n",
       " 'eval_runtime': 0.0642,\n",
       " 'eval_samples_per_second': 1993.342,\n",
       " 'eval_steps_per_second': 62.292,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_80_wnli_mb = trainer_80_mb.evaluate()\n",
    "results_80_wnli_mb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e9f81-d40e-4f8a-acd0-7b8926f58102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (urdu_glue_gpu)",
   "language": "python",
   "name": "urdu_glue_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
