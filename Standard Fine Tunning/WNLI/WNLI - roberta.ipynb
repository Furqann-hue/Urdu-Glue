{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "085e5729-fe88-493f-9839-e3ea1bdf87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 — WNLI DATASET LOADING & INSPECTION\n",
    "# 0.1 — Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19f5e241-cc2d-42b9-bd7f-a9e4429e4bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2 — Load TRAIN dataset\n",
    "train_path = r\"C:\\Users\\areesa\\Documents\\Urdu_GLUE_xlm_roberta\\data\\raw\\U-WNLI\\WNLI_train_urdu-2 - Final.tsv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "500e68ed-d72f-4c64-9547-32f5246873b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((639, 4),\n",
       " Index(['Unnamed: 0', 'label', 'sentence1_urdu', 'sentence2_urdu'], dtype='object'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.3 — Inspect TRAIN schema\n",
    "train_df.shape, train_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a28c2e0a-df09-4c80-b3bc-375e9ef96296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence1_urdu</th>\n",
       "      <th>sentence2_urdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ہنری کئی بار ان انٹرویوز میں موجود رہا تھا جو اس کے والد نے معروف جاسوسوں کے ساتھ کیے تھے جو پیچیدہ اسرار کو حل کرنے میں اس کی مدد چاہتے تھے اور وہ مواقع اس کے لیے سرخ حروف کے دنوں کے طور پر کھڑے ...</td>\n",
       "      <td>وہ مواقع ہنری کے لیے سرخ حروف والے دنوں کے طور پر نمایاں تھے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ہنری کئی بار ان انٹرویوز میں موجود رہا تھا جو اس کے والد نے معروف جاسوسوں کے ساتھ کیے تھے جو پیچیدہ اسرار کو حل کرنے میں اس کی مدد چاہتے تھے اور وہ مواقع اس کے لیے سرخ حروف کے دنوں کے طور پر کھڑے ...</td>\n",
       "      <td>وہ مواقع والد کے لیے یادگار اور خاص دنوں کی حیثیت رکھتے تھے۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک کہ باب اس کی جگہ لینے نہیں آتا ۔ اگر باب وقت پر کام کے لیے گھر سے نکل جاتا تو وہ اس وقت تک چلا جاتا ۔</td>\n",
       "      <td>آدم اس وقت تک چلا جائے گا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک کہ باب اس کی جگہ لینے نہیں آتا ۔ اگر باب وقت پر کام کے لیے گھر سے نکل جاتا تو وہ اس وقت تک چلا جاتا ۔</td>\n",
       "      <td>باب اس وقت تک چلا جائے گا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک کہ باب اس کی جگہ لینے نہیں آتا ۔ اگر باب وقت پر کام کے لیے گھر سے نکل جاتا تو وہ اس وقت تک یہاں پہنچ جاتا ۔</td>\n",
       "      <td>باب اس وقت تک یہاں پہنچ چکا ہوگا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک کہ باب اس کی جگہ لینے نہیں آتا ۔ اگر باب وقت پر کام کے لیے گھر سے نکل جاتا تو وہ اس وقت تک یہاں پہنچ جاتا ۔</td>\n",
       "      <td>آدم اس وقت تک یہاں پہنچ چکا ہوگا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک کہ باب اس کی جگہ لینے نہیں آتا ۔ اگر باب وقت پر کام کے لیے گھر سے نکل جاتا تو وہ اس وقت تک یہاں پہنچ جاتا ۔</td>\n",
       "      <td>باب اس وقت تک یہاں پہنچ چکا ہوگا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ایلس نے ہجوم میں اپنی دوست جیڈ کو تلاش کیا ۔ چونکہ وہ ہمیشہ خوش قسمت رہتی ہے ۔ ایلس نے اسے جلدی سے دیکھ لیا ۔</td>\n",
       "      <td>چونکہ جیڈ ہمیشہ خوش قسمت رہتی ہے ، اس لیے ایلس نے اسے جلدی سے دیکھ لیا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ایلس نے ہجوم میں اپنی دوست جیڈ کو تلاش کیا ۔ چونکہ وہ ہمیشہ خوش قسمت رہتی ہے ۔ ایلس نے اسے جلدی سے دیکھ لیا ۔</td>\n",
       "      <td>چونکہ ایلس ہمیشہ خوش قسمت رہتی ہے ، اس لیے ایلس نے اسے جلدی سے دیکھ لیا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ایلس نے ہجوم میں اپنی دوست جیڈ کو تلاش کیا ۔ چونکہ وہ ہمیشہ سرخ پگڑی پہنتی ہے اس لیے ایلس نے اسے جلدی سے دیکھ لیا ۔</td>\n",
       "      <td>چونکہ جیڈ ہمیشہ سرخ پگڑی پہنتی ہے ، اس لیے ایلس نے اسے جلدی سے دیکھا ۔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label  \\\n",
       "0           1    1.0   \n",
       "1           2    0.0   \n",
       "2           3    1.0   \n",
       "3           4    0.0   \n",
       "4           5    1.0   \n",
       "5           6    0.0   \n",
       "6           7    1.0   \n",
       "7           8    0.0   \n",
       "8           9    1.0   \n",
       "9          10    1.0   \n",
       "\n",
       "                                                                                                                                                                                            sentence1_urdu  \\\n",
       "0  ہنری کئی بار ان انٹرویوز میں موجود رہا تھا جو اس کے والد نے معروف جاسوسوں کے ساتھ کیے تھے جو پیچیدہ اسرار کو حل کرنے میں اس کی مدد چاہتے تھے اور وہ مواقع اس کے لیے سرخ حروف کے دنوں کے طور پر کھڑے ...   \n",
       "1  ہنری کئی بار ان انٹرویوز میں موجود رہا تھا جو اس کے والد نے معروف جاسوسوں کے ساتھ کیے تھے جو پیچیدہ اسرار کو حل کرنے میں اس کی مدد چاہتے تھے اور وہ مواقع اس کے لیے سرخ حروف کے دنوں کے طور پر کھڑے ...   \n",
       "2                                                     آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک کہ باب اس کی جگہ لینے نہیں آتا ۔ اگر باب وقت پر کام کے لیے گھر سے نکل جاتا تو وہ اس وقت تک چلا جاتا ۔   \n",
       "3                                                     آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک کہ باب اس کی جگہ لینے نہیں آتا ۔ اگر باب وقت پر کام کے لیے گھر سے نکل جاتا تو وہ اس وقت تک چلا جاتا ۔   \n",
       "4                                               آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک کہ باب اس کی جگہ لینے نہیں آتا ۔ اگر باب وقت پر کام کے لیے گھر سے نکل جاتا تو وہ اس وقت تک یہاں پہنچ جاتا ۔   \n",
       "5                                               آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک کہ باب اس کی جگہ لینے نہیں آتا ۔ اگر باب وقت پر کام کے لیے گھر سے نکل جاتا تو وہ اس وقت تک یہاں پہنچ جاتا ۔   \n",
       "6                                               آدم اس وقت تک یہاں سے کام نہیں چھوڑ سکتا جب تک کہ باب اس کی جگہ لینے نہیں آتا ۔ اگر باب وقت پر کام کے لیے گھر سے نکل جاتا تو وہ اس وقت تک یہاں پہنچ جاتا ۔   \n",
       "7                                                                                            ایلس نے ہجوم میں اپنی دوست جیڈ کو تلاش کیا ۔ چونکہ وہ ہمیشہ خوش قسمت رہتی ہے ۔ ایلس نے اسے جلدی سے دیکھ لیا ۔   \n",
       "8                                                                                            ایلس نے ہجوم میں اپنی دوست جیڈ کو تلاش کیا ۔ چونکہ وہ ہمیشہ خوش قسمت رہتی ہے ۔ ایلس نے اسے جلدی سے دیکھ لیا ۔   \n",
       "9                                                                                      ایلس نے ہجوم میں اپنی دوست جیڈ کو تلاش کیا ۔ چونکہ وہ ہمیشہ سرخ پگڑی پہنتی ہے اس لیے ایلس نے اسے جلدی سے دیکھ لیا ۔   \n",
       "\n",
       "                                                              sentence2_urdu  \n",
       "0             وہ مواقع ہنری کے لیے سرخ حروف والے دنوں کے طور پر نمایاں تھے ۔  \n",
       "1               وہ مواقع والد کے لیے یادگار اور خاص دنوں کی حیثیت رکھتے تھے۔  \n",
       "2                                                آدم اس وقت تک چلا جائے گا ۔  \n",
       "3                                                باب اس وقت تک چلا جائے گا ۔  \n",
       "4                                         باب اس وقت تک یہاں پہنچ چکا ہوگا ۔  \n",
       "5                                         آدم اس وقت تک یہاں پہنچ چکا ہوگا ۔  \n",
       "6                                         باب اس وقت تک یہاں پہنچ چکا ہوگا ۔  \n",
       "7   چونکہ جیڈ ہمیشہ خوش قسمت رہتی ہے ، اس لیے ایلس نے اسے جلدی سے دیکھ لیا ۔  \n",
       "8  چونکہ ایلس ہمیشہ خوش قسمت رہتی ہے ، اس لیے ایلس نے اسے جلدی سے دیکھ لیا ۔  \n",
       "9     چونکہ جیڈ ہمیشہ سرخ پگڑی پہنتی ہے ، اس لیے ایلس نے اسے جلدی سے دیکھا ۔  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.4 — First look at TRAIN data\n",
    "train_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "128fe532-f2ca-4f4e-aa95-8db67a487b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.5 — Label sanity check (TRAIN)\n",
    "train_df.iloc[:, -1].value_counts()\n",
    "train_df.iloc[:, -1].unique()\n",
    "train_df.iloc[:, -1].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee786e7-4d26-4e98-adab-7976a85e741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 — Load DEV dataset\n",
    "dev_path = r\"C:\\Users\\areesa\\Documents\\Urdu_GLUE_xlm_roberta\\data\\raw\\U-WNLI\\Copy of WNLI_dev_urdu-2 - dev_urdu-2.tsv\"\n",
    "\n",
    "dev_df = pd.read_csv(dev_path, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a7dfb3e-8dbe-45ec-b2b7-7be5fef11d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((71, 3), Index(['label', 'Sentence1', 'Sentence2'], dtype='object'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2 — Inspect DEV schema\n",
    "dev_df.shape, dev_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2b6cc8a-cdcf-4a82-b369-c89c35e47a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>نالی بالوں سے بھری ہوئی ہے۔ اسے صاف کرنا ہوگا۔</td>\n",
       "      <td>بالوں کو صاف کرنا پڑتا ہے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>جین نے سوسن کا دروازہ کھٹکھٹایا لیکن اس نے کوئی جواب نہیں دیا ۔</td>\n",
       "      <td>سوسن نے کوئی جواب نہیں دیا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>بیتھ سیلی سے ناراض نہیں ہوئی جس نے اسے کاٹ دیا تھا کیونکہ وہ رک گئی تھی اور دس تک گنتی کی تھی ۔</td>\n",
       "      <td>سیلی رک گئی اور دس تک گنتی کی ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>کوئی بھی فیس بک اس لیے استعمال نہیں کرتا کہ وہ اداس اور تنہا ہو جائے، لیکن وسکونسن یونیورسٹی کے ماہرِ نفسیات جارج لنکن کی ایک نئی تحقیق کے مطابق فیس بک ہمیں واقعی ایسا ہی محسوس کراتا ہے۔</td>\n",
       "      <td>فیس بک ہمیں بالکل ایسا ہی محسوس کراتا ہے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>وہ آدمی اپنے بیٹے کو اٹھا نہیں سکتا تھا کیونکہ وہ بہت بھاری تھا ۔</td>\n",
       "      <td>بیٹا بہت بھاری تھا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>سوسن جانتی تھی کہ این کا بیٹا کار حادثے میں تھا ، اس لیے اس نے اسے اس کے بارے میں بتایا ۔</td>\n",
       "      <td>این نے اسے اس کے بارے میں بتایا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>جب ٹومی نے اپنی آئس کریم ٹمی کو گرا دیا تو اس لیے والد نے اسے سخت نظر سے دیکھا ۔</td>\n",
       "      <td>والد نے ٹمی کو سخت نظر سے دیکھا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>میرے اور اسٹیج کے درمیان ایک ستون ہے اور میں اس کے ارد گرد نہیں دیکھ سکتا ۔</td>\n",
       "      <td>میں ستون کے ارد گرد نہیں دیکھ سکتا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>اس ڈک کے بالکل نیچے ایک مینو تیراکی ہے اسے بہتر ہے کہ تیزی سے سیفٹی پر چلے جائیں</td>\n",
       "      <td>بہتر ہے کہ ڈک تیزی سے محفوظ مقام پر چلا جائے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>برنارڈ جس نے سرکاری اہلکار کو یہ نہیں بتایا تھا کہ اس کی عمر 21 سال سے کم ہے جب اس نے گھر کے دعوے کے لیے درخواست دائر کی تھی ۔ اس نے اس بات پر غور نہیں کیا کہ اس نے کچھ بے ایمانانہ کیا ہے ۔ پھر بھ...</td>\n",
       "      <td>جو کوئی بھی جانتا تھا کہ اس کی عمر 19 سال ہے وہ اس کا دعوی کسی سے بھی چھین سکتا تھا ۔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      0   \n",
       "1      1   \n",
       "2      0   \n",
       "3      1   \n",
       "4      1   \n",
       "5      0   \n",
       "6      1   \n",
       "7      1   \n",
       "8      0   \n",
       "9      0   \n",
       "\n",
       "                                                                                                                                                                                                 Sentence1  \\\n",
       "0                                                                                                                                                           نالی بالوں سے بھری ہوئی ہے۔ اسے صاف کرنا ہوگا۔   \n",
       "1                                                                                                                                          جین نے سوسن کا دروازہ کھٹکھٹایا لیکن اس نے کوئی جواب نہیں دیا ۔   \n",
       "2                                                                                                          بیتھ سیلی سے ناراض نہیں ہوئی جس نے اسے کاٹ دیا تھا کیونکہ وہ رک گئی تھی اور دس تک گنتی کی تھی ۔   \n",
       "3               کوئی بھی فیس بک اس لیے استعمال نہیں کرتا کہ وہ اداس اور تنہا ہو جائے، لیکن وسکونسن یونیورسٹی کے ماہرِ نفسیات جارج لنکن کی ایک نئی تحقیق کے مطابق فیس بک ہمیں واقعی ایسا ہی محسوس کراتا ہے۔   \n",
       "4                                                                                                                                        وہ آدمی اپنے بیٹے کو اٹھا نہیں سکتا تھا کیونکہ وہ بہت بھاری تھا ۔   \n",
       "5                                                                                                                سوسن جانتی تھی کہ این کا بیٹا کار حادثے میں تھا ، اس لیے اس نے اسے اس کے بارے میں بتایا ۔   \n",
       "6                                                                                                                         جب ٹومی نے اپنی آئس کریم ٹمی کو گرا دیا تو اس لیے والد نے اسے سخت نظر سے دیکھا ۔   \n",
       "7                                                                                                                              میرے اور اسٹیج کے درمیان ایک ستون ہے اور میں اس کے ارد گرد نہیں دیکھ سکتا ۔   \n",
       "8                                                                                                                         اس ڈک کے بالکل نیچے ایک مینو تیراکی ہے اسے بہتر ہے کہ تیزی سے سیفٹی پر چلے جائیں   \n",
       "9  برنارڈ جس نے سرکاری اہلکار کو یہ نہیں بتایا تھا کہ اس کی عمر 21 سال سے کم ہے جب اس نے گھر کے دعوے کے لیے درخواست دائر کی تھی ۔ اس نے اس بات پر غور نہیں کیا کہ اس نے کچھ بے ایمانانہ کیا ہے ۔ پھر بھ...   \n",
       "\n",
       "                                                                               Sentence2  \n",
       "0                                                            بالوں کو صاف کرنا پڑتا ہے ۔  \n",
       "1                                                           سوسن نے کوئی جواب نہیں دیا ۔  \n",
       "2                                                        سیلی رک گئی اور دس تک گنتی کی ۔  \n",
       "3                                             فیس بک ہمیں بالکل ایسا ہی محسوس کراتا ہے ۔  \n",
       "4                                                                   بیٹا بہت بھاری تھا ۔  \n",
       "5                                                      این نے اسے اس کے بارے میں بتایا ۔  \n",
       "6                                                      والد نے ٹمی کو سخت نظر سے دیکھا ۔  \n",
       "7                                                   میں ستون کے ارد گرد نہیں دیکھ سکتا ۔  \n",
       "8                                         بہتر ہے کہ ڈک تیزی سے محفوظ مقام پر چلا جائے ۔  \n",
       "9  جو کوئی بھی جانتا تھا کہ اس کی عمر 19 سال ہے وہ اس کا دعوی کسی سے بھی چھین سکتا تھا ۔  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3 — First look at DEV data\n",
    "dev_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb15bc12-15f2-4159-a112-2ab3ae187db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.4 — Label sanity check (DEV)\n",
    "dev_df.iloc[:, -1].value_counts()\n",
    "dev_df.iloc[:, -1].unique()\n",
    "dev_df.iloc[:, -1].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9ac6abe-c66a-400e-9fcd-278f426183b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 — Load TEST dataset\n",
    "test_df = pd.read_csv(\n",
    "    test_path,\n",
    "    sep=\"\\t\",\n",
    "    engine=\"python\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a0d9315-2d7e-44ee-8597-69244f688036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), Index(['index', 'sentence1', 'sentence2'], dtype='object'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape, test_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9000509-f9f1-40a9-adad-ff24403917e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 151)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(test_path, encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "len(test_df), total_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e7ab476-d852-4192-bc26-c872a4e55778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 — Clean TRAIN dataset\n",
    "# 3.1.1 Drop index column\n",
    "train_df = train_df.drop(columns=[\"Unnamed: 0\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39d59c27-48fa-42c8-a714-97491f34bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.2 Drop row with missing label\n",
    "train_df = train_df.dropna(subset=[\"label\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2bb18b5-889f-4837-8266-4ce7eaf03a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.3 Convert labels to integer (0/1)\n",
    "train_df[\"label\"] = train_df[\"label\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1c37b43-51e5-4d67-a6a6-c5c63da50257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.4 Rename sentence columns (standardize)\n",
    "train_df = train_df.rename(columns={\n",
    "    \"sentence1_urdu\": \"sentence1\",\n",
    "    \"sentence2_urdu\": \"sentence2\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f69812e6-42b4-4bb4-a418-8edf54bcfa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1.5 Verify TRAIN after cleaning\n",
    "train_df.shape\n",
    "train_df.columns\n",
    "train_df[\"label\"].value_counts()\n",
    "train_df[\"label\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74a0f7ae-c936-4ba4-b029-91b360239ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label', 'Sentence1', 'Sentence2']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2.1 Rename sentence columns\n",
    "['label', 'Sentence1', 'Sentence2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c9e4067-07e5-4511-8ffd-3e172c15641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = dev_df.rename(columns={\n",
    "    \"Sentence1\": \"sentence1\",\n",
    "    \"Sentence2\": \"sentence2\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f750aeca-6aee-4a2a-88c8-92bf1cf95418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.2 Ensure label type is integer\n",
    "dev_df[\"label\"] = dev_df[\"label\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "942546be-1386-4b32-90f9-4d69bf0652a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2.3 Verify DEV after cleaning: \n",
    "dev_df.shape\n",
    "dev_df.columns\n",
    "dev_df[\"label\"].value_counts()\n",
    "dev_df[\"label\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c06d47f-c46b-423d-8499-2bd31fe30f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 — DEV CLEANING (FINAL, CORRECT)\n",
    "# 3.2.1 Rename sentence columns\n",
    "dev_df = dev_df.rename(columns={\n",
    "    \"Sentence1\": \"sentence1\",\n",
    "    \"Sentence2\": \"sentence2\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62373281-6cd8-4174-843e-c7dbde49b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.2 Ensure label is integer (safe to re-run)\n",
    "dev_df[\"label\"] = dev_df[\"label\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a923316-54f4-48f0-ad7d-eb8c1ef84805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2.3 Verify DEV after cleaning\n",
    "dev_df.shape\n",
    "dev_df.columns\n",
    "dev_df[\"label\"].value_counts()\n",
    "dev_df[\"label\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b67c7101-2890-4db7-8c52-770500ce622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 — Clean & Unify TEST Dataset\n",
    "# 3.3.1 Drop index column\n",
    "test_df = test_df.drop(columns=[\"index\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b1967bd-4a44-4242-80d5-2e5164cd90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3.2 Ensure sentence columns are strings\n",
    "for col in [\"sentence1\", \"sentence2\"]:\n",
    "    test_df[col] = test_df[col].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0d80289-9816-461e-8fa3-d0672724ca9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے دوڑتے ہوئے دیکھا تھا، جن کے انجن سے کالے دھوئیں کے لمبے، گھومتے ہوئے مرغولے پیچھے کی طرف اٹھ رہے تھے۔ ان کی گرج اور تیز، صاف سیٹیاں دور سے سنائی دے ر...</td>\n",
       "      <td>موڈ اور ڈورا کے نظر آنے پر گھوڑے بھاگ گئے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے دوڑتے ہوئے دیکھا تھا، جن کے انجن سے کالے دھوئیں کے لمبے، گھومتے ہوئے مرغولے پیچھے کی طرف اٹھ رہے تھے۔ ان کی گرج اور تیز، صاف سیٹیاں دور سے سنائی دے ر...</td>\n",
       "      <td>ٹرینیں نظر آنے پر گھوڑے بھاگ گئے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے دوڑتے ہوئے دیکھا تھا، جن کے انجن سے کالے دھوئیں کے لمبے، گھومتے ہوئے مرغولے پیچھے کی طرف اٹھ رہے تھے۔ ان کی گرج اور تیز، صاف سیٹیاں دور سے سنائی دے ر...</td>\n",
       "      <td>پف نظر آنے پر گھوڑے بھاگ گئے ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے دوڑتے ہوئے دیکھا تھا، جن کے انجن سے کالے دھوئیں کے لمبے، گھومتے ہوئے مرغولے پیچھے کی طرف اٹھ رہے تھے۔ ان کی گرج اور تیز، صاف سیٹیاں دور سے سنائی دے ر...</td>\n",
       "      <td>گرج کی آواز سنائی دینے پر گھوڑے بھاگ گئے۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے دوڑتے ہوئے دیکھا تھا، جن کے انجن سے کالے دھوئیں کے لمبے، گھومتے ہوئے مرغولے پیچھے کی طرف اٹھ رہے تھے۔ ان کی گرج اور تیز، صاف سیٹیاں دور سے سنائی دے ر...</td>\n",
       "      <td>سیٹی نظر آنے پر گھوڑے بھاگ گئے۔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                 sentence1  \\\n",
       "0  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے دوڑتے ہوئے دیکھا تھا، جن کے انجن سے کالے دھوئیں کے لمبے، گھومتے ہوئے مرغولے پیچھے کی طرف اٹھ رہے تھے۔ ان کی گرج اور تیز، صاف سیٹیاں دور سے سنائی دے ر...   \n",
       "1  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے دوڑتے ہوئے دیکھا تھا، جن کے انجن سے کالے دھوئیں کے لمبے، گھومتے ہوئے مرغولے پیچھے کی طرف اٹھ رہے تھے۔ ان کی گرج اور تیز، صاف سیٹیاں دور سے سنائی دے ر...   \n",
       "2  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے دوڑتے ہوئے دیکھا تھا، جن کے انجن سے کالے دھوئیں کے لمبے، گھومتے ہوئے مرغولے پیچھے کی طرف اٹھ رہے تھے۔ ان کی گرج اور تیز، صاف سیٹیاں دور سے سنائی دے ر...   \n",
       "3  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے دوڑتے ہوئے دیکھا تھا، جن کے انجن سے کالے دھوئیں کے لمبے، گھومتے ہوئے مرغولے پیچھے کی طرف اٹھ رہے تھے۔ ان کی گرج اور تیز، صاف سیٹیاں دور سے سنائی دے ر...   \n",
       "4  موڈ اور ڈورا نے ٹرینوں کو پریری کے پار تیزی سے دوڑتے ہوئے دیکھا تھا، جن کے انجن سے کالے دھوئیں کے لمبے، گھومتے ہوئے مرغولے پیچھے کی طرف اٹھ رہے تھے۔ ان کی گرج اور تیز، صاف سیٹیاں دور سے سنائی دے ر...   \n",
       "\n",
       "                                     sentence2  \n",
       "0  موڈ اور ڈورا کے نظر آنے پر گھوڑے بھاگ گئے ۔  \n",
       "1           ٹرینیں نظر آنے پر گھوڑے بھاگ گئے ۔  \n",
       "2               پف نظر آنے پر گھوڑے بھاگ گئے ۔  \n",
       "3    گرج کی آواز سنائی دینے پر گھوڑے بھاگ گئے۔  \n",
       "4              سیٹی نظر آنے پر گھوڑے بھاگ گئے۔  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.3.3 Verify TEST after cleaning\n",
    "test_df.shape\n",
    "test_df.columns\n",
    "test_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9de9b59-45b1-4959-88d5-2e16a6e3346f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\anaconda3\\envs\\urdu_glue_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 4 — Create HuggingFace Datasets (WNLI)\n",
    "# 4.1 Create HF datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(\n",
    "    train_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "dev_dataset = Dataset.from_pandas(\n",
    "    dev_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(\n",
    "    test_df[[\"sentence1\", \"sentence2\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d92c51c-f35d-4730-b87b-2fa4cf239407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2'],\n",
       "    num_rows: 150\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.2 Inspect datasets (quick sanity)\n",
    "train_dataset\n",
    "dev_dataset\n",
    "test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b282ab71-54f8-4661-8ceb-d92c5187a6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'نالی بالوں سے بھری ہوئی ہے۔ اسے صاف کرنا ہوگا۔',\n",
       " 'sentence2': 'بالوں کو صاف کرنا پڑتا ہے ۔',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]\n",
    "dev_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9decbe5b-0a72-40e1-b4b1-518d7fd2f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Load tokenizer (XLM-R)\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "904cc99c-1e29-4774-9aaf-651ecec4e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Define tokenization function (sentence pairs)\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence1\"],\n",
    "        examples[\"sentence2\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "768e4fbe-e0a1-435b-84b6-17d164455384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Defensive: ensure text columns are strings\n",
    "for col in [\"sentence1\", \"sentence2\"]:\n",
    "    train_df[col] = train_df[col].astype(str)\n",
    "    dev_df[col] = dev_df[col].astype(str)\n",
    "    test_df[col] = test_df[col].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d843533b-044d-489a-8c76-d5552a7c9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Recreate HF datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(\n",
    "    train_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "dev_dataset = Dataset.from_pandas(\n",
    "    dev_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(\n",
    "    test_df[[\"sentence1\", \"sentence2\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0da40df7-3a40-4976-8ead-2de0ebc87209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████| 638/638 [00:00<00:00, 20756.31 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████| 71/71 [00:00<00:00, 14030.42 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████| 150/150 [00:00<00:00, 11933.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 5.5 Tokenize TRAIN / DEV / TEST\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
    "dev_tokenized = dev_dataset.map(tokenize_function, batched=True)\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3438273f-2a50-43e5-a6b0-cb65afdafcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.6 Set PyTorch format\n",
    "columns = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "\n",
    "train_tokenized.set_format(type=\"torch\", columns=columns)\n",
    "dev_tokenized.set_format(type=\"torch\", columns=columns)\n",
    "\n",
    "# TEST has no labels\n",
    "test_tokenized.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85098ee5-d848-4457-8d69-d679a47bb2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(0),\n",
       " 'input_ids': tensor([     0,   3832,   8494,   1705,    904,    504,  23450,    140,  19606,\n",
       "           1633,  17248,  56679,  12738, 104929,      2,      2,   1705,    904,\n",
       "            554,  56679,  12738, 181027,    639,   3481,      2,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.7 Sanity check\n",
    "train_tokenized[0]\n",
    "dev_tokenized[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1762e2-9153-4642-88a7-102d5da79360",
   "metadata": {},
   "source": [
    "# ZERO-SHOT WNLI (XLM-RoBERTa-Large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5818472d-6734-4711-9e4f-34b426effbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Load XLM-R model (binary classification)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-large\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"not_entailment\", 1: \"entailment\"},\n",
    "    label2id={\"not_entailment\": 0, \"entailment\": 1}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a0d6685-24e0-473d-8012-daef2107fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2  Freeze encoder\n",
    "for param in model.roberta.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81136491-7ffc-4241-baeb-d16643191f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.requires_grad for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a830434c-9ea2-422a-aa13-45ab928841ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Metrics (Accuracy + Macro-F1)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2530602-0369-4a2e-8ca8-3e012a8a7b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4 TrainingArguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_wnli_zero = TrainingArguments(\n",
    "    output_dir=\"./wnli_zero_shot_xlmr\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20342917-1118-49a3-b670-75562a7770d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_23868\\3993473632.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_zero = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# 6.5 Trainer (ZERO-SHOT)\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_zero = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_wnli_zero,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=dev_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81d46db3-0169-44d3-b634-76c93874c386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 01:37, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.685767</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.360360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.686874</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.360360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.699500</td>\n",
       "      <td>0.690395</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.360360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.699500</td>\n",
       "      <td>0.686633</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.360360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.695900</td>\n",
       "      <td>0.692197</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.416729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.695900</td>\n",
       "      <td>0.688573</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.360360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.695900</td>\n",
       "      <td>0.689453</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.360360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.700500</td>\n",
       "      <td>0.689866</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.360360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.700500</td>\n",
       "      <td>0.690079</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>0.360360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.696900</td>\n",
       "      <td>0.693332</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.505473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.696900</td>\n",
       "      <td>0.693676</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.428483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.696900</td>\n",
       "      <td>0.693504</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.487981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>0.690856</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.354545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>0.693483</td>\n",
       "      <td>0.521127</td>\n",
       "      <td>0.518740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.698300</td>\n",
       "      <td>0.693091</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.548490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.698300</td>\n",
       "      <td>0.692789</td>\n",
       "      <td>0.507042</td>\n",
       "      <td>0.500703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.698300</td>\n",
       "      <td>0.693043</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.533731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.693793</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.439784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.693710</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.434552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.693607</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>0.472172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=0.697438097000122, metrics={'train_runtime': 97.3096, 'train_samples_per_second': 131.128, 'train_steps_per_second': 4.111, 'total_flos': 2972861049016320.0, 'train_loss': 0.697438097000122, 'epoch': 20.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_zero.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13731085-62a0-4b2e-8b5f-e3488907e994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6857670545578003,\n",
       " 'eval_accuracy': 0.5633802816901409,\n",
       " 'eval_f1': 0.36036036036036034,\n",
       " 'eval_runtime': 0.1175,\n",
       " 'eval_samples_per_second': 604.362,\n",
       " 'eval_steps_per_second': 25.536,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_results_wnli = trainer_zero.evaluate()\n",
    "zero_shot_results_wnli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c664a1-0ea5-4642-a256-ab6d7d830e67",
   "metadata": {},
   "source": [
    "# 16-SHOT WNLI (XLM-R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0fe5123-c3f8-4e90-9018-21423d5688ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Create 16-shot dataset (from TRAIN)\n",
    "fewshot_df = (\n",
    "    train_df\n",
    "    .groupby(\"label\", sort=False)\n",
    "    .head(16)\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a3fac93-2a5e-4a94-8fbd-2312583a0438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    16\n",
       "0    16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.2 Verify size & balance\n",
    "fewshot_df.shape\n",
    "fewshot_df[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2abd7fd8-b0da-4f5d-90c7-86b51b2b9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 Convert to HuggingFace Dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "fewshot_dataset = Dataset.from_pandas(\n",
    "    fewshot_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21651389-052d-4c28-b32f-85f0d4c1a4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'ہنری کئی بار ان انٹرویوز میں موجود رہا تھا جو اس کے والد نے معروف جاسوسوں کے ساتھ کیے تھے جو پیچیدہ اسرار کو حل کرنے میں اس کی مدد چاہتے تھے اور وہ مواقع اس کے لیے سرخ حروف کے دنوں کے طور پر کھڑے تھے ۔',\n",
       " 'sentence2': 'وہ مواقع ہنری کے لیے سرخ حروف والے دنوں کے طور پر نمایاں تھے ۔',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fewshot_dataset\n",
    "fewshot_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05870ef7-baeb-4702-b63d-15e50327327b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<?, ? examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 7.4 Tokenize 16-shot dataset\n",
    "fewshot_tokenized = fewshot_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "columns = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "fewshot_tokenized.set_format(type=\"torch\", columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8cd2376e-44eb-45c5-b98b-242f756abb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(1),\n",
       " 'input_ids': tensor([     0,      6, 105140,  11660,  33140,   3697,    716, 158432,   1469,\n",
       "            317,   7233,  12288,   4566,    715,    754,    216,  19601,    778,\n",
       "          32952, 153950,    904,    216,   4863,  42318,  12598,    715, 131317,\n",
       "           2929,    907, 205833,    554,   8413,   3210,    317,    754,    288,\n",
       "          21157,  67815,  12598,    490,   2598,  52689,    754,    216,   4199,\n",
       "          93947, 199723,    216, 100238,    216,   5461,    523, 168233,  12598,\n",
       "           3481,      2,      2,   2598,  52689,      6, 105140,  11660,    216,\n",
       "           4199,  93947, 199723,   7314, 100238,    216,   5461,    523,  82086,\n",
       "          10252,  12598,   3481,      2,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fewshot_tokenized[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f7722fb-f071-4b4a-b2df-c00e1e4794ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 7.5 Load XLM-R model (FULL fine-tuning)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-large\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"not_entailment\", 1: \"entailment\"},\n",
    "    label2id={\"not_entailment\": 0, \"entailment\": 1}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36f8df80-6ca3-4c09-bc21-9dc2ac0718a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.6 TrainingArguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_wnli_16 = TrainingArguments(\n",
    "    output_dir=\"./wnli_16shot_xlmr\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=20,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "038669dd-21cb-45a2-aa71-e361b13c6e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_23868\\1217571534.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_16 = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# 7.7 Trainer (16-shot)\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_16 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_wnli_16,\n",
    "    train_dataset=fewshot_tokenized,\n",
    "    eval_dataset=dev_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c377fee6-cdbc-47c6-8943-a105f82eb1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 20:35, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.731844</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.303922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.716756</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.303922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694755</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>0.477214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694755</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>0.477214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.689474</td>\n",
       "      <td>0.521127</td>\n",
       "      <td>0.342593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.692390</td>\n",
       "      <td>0.521127</td>\n",
       "      <td>0.440167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.697080</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>0.472172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.702922</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.433511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.702922</td>\n",
       "      <td>0.492958</td>\n",
       "      <td>0.433511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.708465</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.365636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712131</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.365636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.708548</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.365636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712292</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.365636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712292</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.365636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.723316</td>\n",
       "      <td>0.436620</td>\n",
       "      <td>0.356884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.724616</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.365636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.389040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.729073</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.389040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.729386</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.379843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.701000</td>\n",
       "      <td>0.725073</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.379843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=0.7010183334350586, metrics={'train_runtime': 1239.2436, 'train_samples_per_second': 0.516, 'train_steps_per_second': 0.016, 'total_flos': 149109018132480.0, 'train_loss': 0.7010183334350586, 'epoch': 20.0})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_16.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "537a2856-7690-45a2-895a-4ff14ec47b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6894737482070923,\n",
       " 'eval_accuracy': 0.5211267605633803,\n",
       " 'eval_f1': 0.3425925925925926,\n",
       " 'eval_runtime': 0.1419,\n",
       " 'eval_samples_per_second': 500.33,\n",
       " 'eval_steps_per_second': 21.141,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_16shot_wnli = trainer_16.evaluate()\n",
    "results_16shot_wnli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66da4934-b647-4a58-a566-54c9d4c665e3",
   "metadata": {},
   "source": [
    "# 80/20 WNLI (XLM-R, Full Fine-Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28923d6d-efbb-4284-a0fa-458634882cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Create stratified 80/20 split (from TRAIN)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_80_df, val_20_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_df[\"label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35cf224d-7dbd-4447-98c7-f46cdf2408e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    65\n",
       "1    63\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_80_df.shape, val_20_df.shape\n",
    "train_80_df[\"label\"].value_counts()\n",
    "val_20_df[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d25f5257-8c65-4646-9b6a-d8dbd47aea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.2 Convert to HF Datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "train_80_dataset = Dataset.from_pandas(\n",
    "    train_80_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "val_20_dataset = Dataset.from_pandas(\n",
    "    val_20_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f7207ef1-8d93-43aa-9c2b-5058faab2a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████| 510/510 [00:00<00:00, 32302.85 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████| 128/128 [00:00<00:00, 16000.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 8.3 Tokenize\n",
    "train_80_tok = train_80_dataset.map(tokenize_function, batched=True)\n",
    "val_20_tok   = val_20_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "cols = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "train_80_tok.set_format(type=\"torch\", columns=cols)\n",
    "val_20_tok.set_format(type=\"torch\", columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd6a1bf1-1ff7-436e-8410-bf4793c81e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(1),\n",
       " 'input_ids': tensor([     0,    715,    778,  26074,  17201, 161050,   6388,    639,    490,\n",
       "           7060,  29343,   6501,   1541,  45045,  62638,  12004,    258,    639,\n",
       "           3481,   2598, 184670,    554,    754,    317,  49856,   2437,   9355,\n",
       "           7482,   3481,      2,      2,   2598, 184670,    554,  52560,  17201,\n",
       "            317,  49856,   2437,   9355,   7482,   3481,      2,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_80_tok[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1fef8bdb-5027-43dc-a51a-b9bfe5019811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 8.4 Load model (FULL fine-tuning)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-large\",\n",
    "    num_labels=2,\n",
    "    id2label={0: \"not_entailment\", 1: \"entailment\"},\n",
    "    label2id={\"not_entailment\": 0, \"entailment\": 1}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67637104-1e2c-4e9f-bfb9-4faa9a02e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 TrainingArguments (same standard pipeline)\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_wnli_80 = TrainingArguments(\n",
    "    output_dir=\"./wnli_80_20_xlmr\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=20,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "590c6729-3281-4cf7-891b-d0c2454f7643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_23868\\3202363473.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_80 = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='320' max='320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [320/320 29:59, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.693394</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.698200</td>\n",
       "      <td>0.693764</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.693260</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>0.694073</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.329843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>0.693760</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.329843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.700300</td>\n",
       "      <td>0.694344</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.702300</td>\n",
       "      <td>0.693142</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.692928</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.701400</td>\n",
       "      <td>0.693703</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.329843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.701400</td>\n",
       "      <td>0.693680</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.329843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.694900</td>\n",
       "      <td>0.693108</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.694500</td>\n",
       "      <td>0.693054</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.697500</td>\n",
       "      <td>0.693150</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.329843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.692989</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.693684</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.695900</td>\n",
       "      <td>0.693401</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.693428</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.693645</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.698500</td>\n",
       "      <td>0.693748</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.336788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=320, training_loss=0.6968573331832886, metrics={'train_runtime': 1801.9453, 'train_samples_per_second': 5.661, 'train_steps_per_second': 0.178, 'total_flos': 2376424976486400.0, 'train_loss': 0.6968573331832886, 'epoch': 20.0})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8.6 Trainer & Run\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_80 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_wnli_80,\n",
    "    train_dataset=train_80_tok,\n",
    "    eval_dataset=val_20_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer_80.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ad800e8-32cc-4fba-abae-6495c3a24738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6933937072753906,\n",
       " 'eval_accuracy': 0.5078125,\n",
       " 'eval_f1': 0.33678756476683935,\n",
       " 'eval_runtime': 2.179,\n",
       " 'eval_samples_per_second': 58.743,\n",
       " 'eval_steps_per_second': 1.836,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_80_wnli = trainer_80.evaluate()\n",
    "results_80_wnli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d29ddd-e04f-4037-86ab-50296724faad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (urdu_glue_gpu)",
   "language": "python",
   "name": "urdu_glue_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
