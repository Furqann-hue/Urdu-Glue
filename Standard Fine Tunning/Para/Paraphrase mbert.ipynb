{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a620d551-46eb-4184-95c0-cb1d3b4de64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\anaconda3\\envs\\urdu_glue_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Core\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# HuggingFace\n",
    "from datasets import Dataset, ClassLabel\n",
    "\n",
    "# Metrics (will be reused later)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba237f2-2ffa-4b44-bf42-56cc557270a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe605db9-c1c6-46e7-aa7e-8d9b813d309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = r\"C:\\Users\\areesa\\Documents\\Urdu_GLUE_xlm_roberta\\data\\raw\\Urdu Paraphrasing\\UPPC\\UPPC Corpus\"\n",
    "DATA_DIR = os.path.join(DATASET_ROOT, \"data\")\n",
    "LABEL_FILE = os.path.join(DATASET_ROOT, \"all_files.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd004b22-25cd-4f2b-96bd-7f73bc2b326b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(DATA_DIR)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f1d5833-6f74-4910-a29b-1191e76917a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_urdu_text(file_path):\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "    soup = BeautifulSoup(raw, \"xml\")\n",
    "    doc = soup.find(\"UPPC_document\")\n",
    "    return doc.get_text().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96c06243-7ad0-41d9-ab17-35ff05774bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents loaded: 160\n"
     ]
    }
   ],
   "source": [
    "doc_texts = {}\n",
    "\n",
    "for fname in os.listdir(DATA_DIR):\n",
    "    doc_texts[fname] = extract_urdu_text(os.path.join(DATA_DIR, fname))\n",
    "\n",
    "print(\"Documents loaded:\", len(doc_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d86a96c0-e806-4a0b-890d-6d13290182a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "\n",
    "with open(LABEL_FILE, encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    f1, f2, label = line.strip().split(\",\")\n",
    "\n",
    "    pairs.append({\n",
    "        \"sentence1\": doc_texts[f1],\n",
    "        \"sentence2\": doc_texts[f2],\n",
    "        \"label\": 1 if label == \"P\" else 0\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "838922f9-6cd3-4ea0-8838-6caaed1e8fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 3)\n",
      "label\n",
      "1    75\n",
      "0    65\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>چودھری رحمت علی  16 نومبر1897  کو مشرقی پنجاب ...</td>\n",
       "      <td>چودھر ی رحمت علی 16 نومبر 1897ء کو ہوشیارپور ک...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>تقریباً 25 سال کی عمر میں آپ صلی اللہ علیہ و آ...</td>\n",
       "      <td>حضرت محمد دیناوی تاریخ میں اہم ترین شخصیت کے ط...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لیاقت علی خان پاکستان کے پہلے وزیراعظم تھے۔ آپ...</td>\n",
       "      <td>پاکستان کے پہلے وزیر اعظم نواب لیاقت علی خان م...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مرزا غالب 1797- 1869 اردو زبان کے سب سے بڑے شا...</td>\n",
       "      <td>1797ء سے 1869ء تک کے دور میں مرزا غالب اردو زب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ٹیپو سلطان 10 نومبر1750~ 4 مئی 1799 ہندوستان م...</td>\n",
       "      <td>تاریخ کا وہ عظیم نام جس کا نام سنتے ہی اس کے د...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  چودھری رحمت علی  16 نومبر1897  کو مشرقی پنجاب ...   \n",
       "1  تقریباً 25 سال کی عمر میں آپ صلی اللہ علیہ و آ...   \n",
       "2  لیاقت علی خان پاکستان کے پہلے وزیراعظم تھے۔ آپ...   \n",
       "3  مرزا غالب 1797- 1869 اردو زبان کے سب سے بڑے شا...   \n",
       "4  ٹیپو سلطان 10 نومبر1750~ 4 مئی 1799 ہندوستان م...   \n",
       "\n",
       "                                           sentence2  label  \n",
       "0  چودھر ی رحمت علی 16 نومبر 1897ء کو ہوشیارپور ک...      0  \n",
       "1  حضرت محمد دیناوی تاریخ میں اہم ترین شخصیت کے ط...      0  \n",
       "2  پاکستان کے پہلے وزیر اعظم نواب لیاقت علی خان م...      0  \n",
       "3  1797ء سے 1869ء تک کے دور میں مرزا غالب اردو زب...      0  \n",
       "4  تاریخ کا وہ عظیم نام جس کا نام سنتے ہی اس کے د...      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df[\"label\"].value_counts())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82a33ab9-5803-4462-b94a-2fbc05d6c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"uppc_paraphrase_pairs.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14c2e226-a442-4164-a143-ef9fdfa7b45b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label'],\n",
       "    num_rows: 140\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert DataFrame → HuggingFace Dataset\n",
    "from datasets import Dataset, ClassLabel\n",
    "\n",
    "hf_dataset = Dataset.from_pandas(df)\n",
    "hf_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c61a349f-f3be-45f2-830e-69729f3cb4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 70005.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Cast label to ClassLabe\n",
    "label_feature = ClassLabel(\n",
    "    num_classes=2,\n",
    "    names=[\"not_paraphrase\", \"paraphrase\"]\n",
    ")\n",
    "\n",
    "hf_dataset = hf_dataset.cast_column(\"label\", label_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ca6f9ae-c76d-4833-a38d-e613bc904b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value('string'),\n",
       " 'sentence2': Value('string'),\n",
       " 'label': ClassLabel(names=['not_paraphrase', 'paraphrase'])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset.features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1244f48d-188e-4f03-bdbf-2490ff13559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Shot Dataset\n",
    "zero_shot_dataset = hf_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0cdbf61-bdca-494d-a285-977c5255afd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 65\n"
     ]
    }
   ],
   "source": [
    "# 16-Shot Dataset\n",
    "df_pos = df[df[\"label\"] == 1]   # paraphrase\n",
    "df_neg = df[df[\"label\"] == 0]   # not paraphrase\n",
    "\n",
    "print(len(df_pos), len(df_neg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b86c5e3-5c0c-4b70-9587-8946c17bccb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    16\n",
       "0    16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take FIRST 16 from each class\n",
    "df_16shot = pd.concat([\n",
    "    df_pos.iloc[:16],\n",
    "    df_neg.iloc[:16]\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "df_16shot[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07cebb05-c205-4a61-907a-266840b8e6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 15959.30 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label'],\n",
       "    num_rows: 32\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to HF Dataset\n",
    "hf_16shot = Dataset.from_pandas(df_16shot)\n",
    "hf_16shot = hf_16shot.cast_column(\"label\", label_feature)\n",
    "\n",
    "hf_16shot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ad4ec0b-b6e0-431b-aee5-240c0bef5a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████████████████████████████████████████████████████████| 108/108 [00:00<00:00, 96585.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Remaining data for evaluation\n",
    "df_remaining = df.drop(df_16shot.index).reset_index(drop=True)\n",
    "\n",
    "hf_16shot_eval = Dataset.from_pandas(df_remaining)\n",
    "hf_16shot_eval = hf_16shot_eval.cast_column(\"label\", label_feature)\n",
    "\n",
    "print(len(hf_16shot), len(hf_16shot_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "911705ff-65b0-46ca-965d-7ee1bc07f8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 112\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 28\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80 / 20 Stratified Split\n",
    "hf_80_20 = hf_dataset.train_test_split(\n",
    "    test_size=0.2,\n",
    "    seed=SEED,\n",
    "    stratify_by_column=\"label\"\n",
    ")\n",
    "\n",
    "hf_80_20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a883488-a05b-4a23-8ff9-f716d28e4f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels: Counter({1: 60, 0: 52})\n",
      "Test labels: Counter({1: 15, 0: 13})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Train labels:\", Counter(hf_80_20[\"train\"][\"label\"]))\n",
    "print(\"Test labels:\", Counter(hf_80_20[\"test\"][\"label\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cefc3bc-f9d2-4bd4-8696-92f4ae5610ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer (mBERT)\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1189060-c690-457e-be57-dd705abb54db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tokenization Function (Sentence-Pair)\n",
    "MAX_LEN = 128\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"sentence1\"],\n",
    "        batch[\"sentence2\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea914ca4-0574-4a3e-8c37-36886334b8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 577.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize All Datasets\n",
    "# Zero-shot\n",
    "tokenized_zero = zero_shot_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4230a242-d80e-439a-ab8d-9a8d7f27b353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 438.62 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:00<00:00, 576.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 16-shot\n",
    "tokenized_16_train = hf_16shot.map(tokenize_function, batched=True)\n",
    "tokenized_16_eval  = hf_16shot_eval.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "010d69fd-5224-4a41-9f61-154330e49e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 540.16 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 425.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 80 / 20\n",
    "tokenized_80_train = hf_80_20[\"train\"].map(tokenize_function, batched=True)\n",
    "tokenized_80_test  = hf_80_20[\"test\"].map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50edc89a-23c8-45b1-9e8a-3ac012632ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Torch Format (Trainer-Ready)\n",
    "columns = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "\n",
    "tokenized_zero.set_format(type=\"torch\", columns=columns)\n",
    "tokenized_16_train.set_format(type=\"torch\", columns=columns)\n",
    "tokenized_16_eval.set_format(type=\"torch\", columns=columns)\n",
    "tokenized_80_train.set_format(type=\"torch\", columns=columns)\n",
    "tokenized_80_test.set_format(type=\"torch\", columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ce832ec-9ff5-49f7-bf5a-926fee78b6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(1),\n",
       " 'input_ids': tensor([   101,    818,  16351,  63764,  10278,    773,  86131,  10502,  21732,\n",
       "          10250, 101278,  45987, 100595,  13244,  81780,  10278,  38755,  10691,\n",
       "          19216,  18779, 105449,  10673,  84801,  10691,  75399,  96786,  13185,\n",
       "            788,  11145,  52437,  13437,  10916,  12427,  24104,  30745,  25306,\n",
       "          53065,  14634,    769,  24728,  10278,  47889,  10691,    829,  13437,\n",
       "          29315,  27226,    837,  56744,  15974,  65479,  52874,  12574,  12427,\n",
       "            788,  60312,  11086,  11689,  29145,  11076,  13141,  12427,  38784,\n",
       "          53789,    102,    818,  16351,  63764,  10278,    773,  86131,  10502,\n",
       "          21732,  38755,  10691,  19216,  18779, 105449,  10673,  84801,  10691,\n",
       "          12427, 108754,    788,  11145,  52437,  13437,  10916,  12427,  30745,\n",
       "          25306,  53065,  14634,    769,  24728,  10278,  47889,  10691,    829,\n",
       "          13437,  10250, 101278,  12549,  12611,  13244,  29315,  27226,    837,\n",
       "          52874,  12574,  56744,  15974,  65479,  12427,    788,  78238,  11242,\n",
       "          11689,  29145,  11076,  21516,  13244,  12427,  38784,  53789,    818,\n",
       "          20451,    102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_16_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92127fca-b2f4-4015-90ae-036e95964cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# mBERT: Zero-Shot Experiment\n",
    "# Load mBERT Model (FRESH)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    num_labels=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d82e657f-666a-49fd-a83d-222fdf357ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze Encoder (ZERO-SHOT RULE)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ecafa76-98cf-473e-a563-c6162da20b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.requires_grad for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d0cd8c4-d200-4241-9023-712af5865b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingArguments (STANDARD TEMPLATE)\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/uppc_mbert_zero\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    fp16=True,\n",
    "    max_grad_norm=1.0,\n",
    "\n",
    "    report_to=\"none\",\n",
    "    seed=SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "223de21d-adec-49f8-89e7-262c54731ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac3bd149-3fe2-49a0-ab62-c91d30ff9eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_31028\\3859933720.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_zero = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Trainer (Zero-Shot)\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_zero = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_zero,\n",
    "    eval_dataset=tokenized_zero,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2776402-9c31-49fb-abd0-fdb28bf9872e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:17, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.723800</td>\n",
       "      <td>0.725291</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.715700</td>\n",
       "      <td>0.723087</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.722300</td>\n",
       "      <td>0.720176</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.726500</td>\n",
       "      <td>0.717557</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.715400</td>\n",
       "      <td>0.715224</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.703700</td>\n",
       "      <td>0.713149</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.718000</td>\n",
       "      <td>0.711370</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.714700</td>\n",
       "      <td>0.709881</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.710100</td>\n",
       "      <td>0.708807</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.704500</td>\n",
       "      <td>0.707799</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.711300</td>\n",
       "      <td>0.707070</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.702400</td>\n",
       "      <td>0.706424</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.709800</td>\n",
       "      <td>0.705950</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.708400</td>\n",
       "      <td>0.705399</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.700700</td>\n",
       "      <td>0.704935</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.714800</td>\n",
       "      <td>0.704663</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.702600</td>\n",
       "      <td>0.704395</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.704245</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.701900</td>\n",
       "      <td>0.704126</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.707300</td>\n",
       "      <td>0.704116</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\anaconda3\\envs\\urdu_glue_gpu\\lib\\site-packages\\transformers\\trainer.py:4380: UserWarning: mtime may not be reliable on this filesystem, falling back to numerical ordering\n",
      "  warnings.warn(\"mtime may not be reliable on this filesystem, falling back to numerical ordering\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.7109502410888672, metrics={'train_runtime': 17.993, 'train_samples_per_second': 155.616, 'train_steps_per_second': 5.558, 'total_flos': 184177738752000.0, 'train_loss': 0.7109502410888672, 'epoch': 20.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_zero.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0db56b99-64b3-4d1f-8bc5-9a313b8cb883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7252912521362305,\n",
       " 'eval_accuracy': 0.4642857142857143,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_runtime': 0.0963,\n",
       " 'eval_samples_per_second': 1453.526,\n",
       " 'eval_steps_per_second': 51.912,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_results = trainer_zero.evaluate()\n",
    "zero_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc3a1c1f-228c-48da-8041-1386cca9efef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# mBERT: 16-Shot Fine-Tuning\n",
    "# Load a FRESH mBERT Model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    num_labels=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5131fb56-eece-43ee-b631-88b354614c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.requires_grad for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f150582d-581f-433b-b133-76651de052ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingArguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_16 = TrainingArguments(\n",
    "    output_dir=\"./results/uppc_mbert_16shot\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    fp16=True,\n",
    "    max_grad_norm=1.0,\n",
    "\n",
    "    report_to=\"none\",\n",
    "    seed=SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f048d511-77d9-48bd-9d9d-d35a0521e7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_31028\\3821337507.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_16 = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Trainer (16-Shot)\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_16 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_16,\n",
    "    train_dataset=tokenized_16_train,\n",
    "    eval_dataset=tokenized_16_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80f2cf66-517a-4c01-be9d-42ac36e75cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:51, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.685700</td>\n",
       "      <td>0.704490</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.695300</td>\n",
       "      <td>0.686569</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.715328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>0.663963</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.815642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.670200</td>\n",
       "      <td>0.663963</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.815642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.673700</td>\n",
       "      <td>0.647936</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.819672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.671800</td>\n",
       "      <td>0.638247</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.819672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.663700</td>\n",
       "      <td>0.632883</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.829545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.624600</td>\n",
       "      <td>0.635023</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.812121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.617200</td>\n",
       "      <td>0.636497</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.585700</td>\n",
       "      <td>0.630697</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.565300</td>\n",
       "      <td>0.625068</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.780142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.522400</td>\n",
       "      <td>0.614916</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.780142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.600240</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.788732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.447100</td>\n",
       "      <td>0.584416</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.794521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.408600</td>\n",
       "      <td>0.569491</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.391000</td>\n",
       "      <td>0.560647</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.390400</td>\n",
       "      <td>0.555863</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.802548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.333100</td>\n",
       "      <td>0.551817</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.357700</td>\n",
       "      <td>0.549130</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.330800</td>\n",
       "      <td>0.547960</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=0.5405887603759766, metrics={'train_runtime': 50.9825, 'train_samples_per_second': 12.553, 'train_steps_per_second': 0.392, 'total_flos': 42097768857600.0, 'train_loss': 0.5405887603759766, 'epoch': 20.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_16.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67871eb1-d499-4c0d-8b23-c729949317d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6328825354576111,\n",
       " 'eval_accuracy': 0.7222222222222222,\n",
       " 'eval_f1': 0.8295454545454546,\n",
       " 'eval_runtime': 0.0729,\n",
       " 'eval_samples_per_second': 1481.548,\n",
       " 'eval_steps_per_second': 54.872,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_16 = trainer_16.evaluate()\n",
    "results_16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46021a5e-05f3-4db6-b1e1-08baed49298f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# mBERT: 80 / 20 Full Fine-Tuning\n",
    "# Load a FRESH mBERT Model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    num_labels=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32f6eb43-2302-40ff-afa9-fdc138fd3ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.requires_grad for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44cbc67e-d81c-465b-9421-c4c4805e3aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingArguments (80/20)\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_80 = TrainingArguments(\n",
    "    output_dir=\"./results/uppc_mbert_80_20\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    fp16=True,\n",
    "    max_grad_norm=1.0,\n",
    "\n",
    "    report_to=\"none\",\n",
    "    seed=SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2870ba90-f3c2-4f18-b71a-4b79c82058ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_31028\\1890712667.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_80 = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Trainer (80/20)\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_80 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_80,\n",
    "    train_dataset=tokenized_80_train,\n",
    "    eval_dataset=tokenized_80_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be822b8f-7433-496b-842f-21cc729445eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:55, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.703100</td>\n",
       "      <td>0.691197</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.702200</td>\n",
       "      <td>0.681431</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.693900</td>\n",
       "      <td>0.688215</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.685900</td>\n",
       "      <td>0.699611</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>0.703387</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.668800</td>\n",
       "      <td>0.647112</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.650200</td>\n",
       "      <td>0.679827</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.608400</td>\n",
       "      <td>0.642665</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.539500</td>\n",
       "      <td>0.632725</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.593951</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.365500</td>\n",
       "      <td>0.559906</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.276700</td>\n",
       "      <td>0.592054</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.241800</td>\n",
       "      <td>0.655863</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>0.645999</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.642408</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.696567</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>0.632320</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>0.680263</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.671770</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>0.684848</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=0.4121783971786499, metrics={'train_runtime': 55.8601, 'train_samples_per_second': 40.1, 'train_steps_per_second': 1.432, 'total_flos': 147342191001600.0, 'train_loss': 0.4121783971786499, 'epoch': 20.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_80.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "762369e1-367d-495d-b5a2-59df193083c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6965670585632324,\n",
       " 'eval_accuracy': 0.7857142857142857,\n",
       " 'eval_f1': 0.8333333333333334,\n",
       " 'eval_runtime': 0.0198,\n",
       " 'eval_samples_per_second': 1412.75,\n",
       " 'eval_steps_per_second': 50.455,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_80 = trainer_80.evaluate()\n",
    "results_80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26d358-f46a-48ce-8f30-d7be67d98832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (urdu_glue_gpu)",
   "language": "python",
   "name": "urdu_glue_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
