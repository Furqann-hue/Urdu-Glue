{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea86887-f9fc-4e59-ad54-fd1cba017d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\anaconda3\\envs\\urdu_glue_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports \n",
    "# Core\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# HuggingFace\n",
    "from datasets import Dataset, ClassLabel\n",
    "\n",
    "# Metrics (will be reused)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ebe82d-e46d-423d-9f3c-9e0f7708f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Random Seed\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a19da1-8349-4ce8-afd2-da8c6c943364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Paths (UPPC)\n",
    "DATASET_ROOT = r\"C:\\Users\\areesa\\Documents\\Urdu_GLUE_xlm_roberta\\data\\raw\\Urdu Paraphrasing\\UPPC\\UPPC Corpus\"\n",
    "DATA_DIR = os.path.join(DATASET_ROOT, \"data\")\n",
    "LABEL_FILE = os.path.join(DATASET_ROOT, \"all_files.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "030380f8-dde8-47d6-9fc9-bcb01b6cfacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(DATA_DIR)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0a6f00a-d0e8-405e-8f98-3fd59ac3bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML Text Extraction Function\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_urdu_text(file_path):\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "    soup = BeautifulSoup(raw, \"xml\")\n",
    "    doc = soup.find(\"UPPC_document\")\n",
    "    return doc.get_text().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af0411f3-50b0-499f-9a9a-7c5f1ccb69eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents loaded: 160\n"
     ]
    }
   ],
   "source": [
    "# Load All Documents\n",
    "doc_texts = {}\n",
    "\n",
    "for fname in os.listdir(DATA_DIR):\n",
    "    doc_texts[fname] = extract_urdu_text(os.path.join(DATA_DIR, fname))\n",
    "\n",
    "print(\"Documents loaded:\", len(doc_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab66df59-56a6-4bd2-9269-20e3fb89a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Paraphrase DataFrame\n",
    "pairs = []\n",
    "\n",
    "with open(LABEL_FILE, encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    f1, f2, label = line.strip().split(\",\")\n",
    "\n",
    "    pairs.append({\n",
    "        \"sentence1\": doc_texts[f1],\n",
    "        \"sentence2\": doc_texts[f2],\n",
    "        \"label\": 1 if label == \"P\" else 0\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b6c6c4-24e5-433b-a278-a9837342ebf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 3)\n",
      "label\n",
      "1    75\n",
      "0    65\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>چودھری رحمت علی  16 نومبر1897  کو مشرقی پنجاب ...</td>\n",
       "      <td>چودھر ی رحمت علی 16 نومبر 1897ء کو ہوشیارپور ک...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>تقریباً 25 سال کی عمر میں آپ صلی اللہ علیہ و آ...</td>\n",
       "      <td>حضرت محمد دیناوی تاریخ میں اہم ترین شخصیت کے ط...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لیاقت علی خان پاکستان کے پہلے وزیراعظم تھے۔ آپ...</td>\n",
       "      <td>پاکستان کے پہلے وزیر اعظم نواب لیاقت علی خان م...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>مرزا غالب 1797- 1869 اردو زبان کے سب سے بڑے شا...</td>\n",
       "      <td>1797ء سے 1869ء تک کے دور میں مرزا غالب اردو زب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ٹیپو سلطان 10 نومبر1750~ 4 مئی 1799 ہندوستان م...</td>\n",
       "      <td>تاریخ کا وہ عظیم نام جس کا نام سنتے ہی اس کے د...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  چودھری رحمت علی  16 نومبر1897  کو مشرقی پنجاب ...   \n",
       "1  تقریباً 25 سال کی عمر میں آپ صلی اللہ علیہ و آ...   \n",
       "2  لیاقت علی خان پاکستان کے پہلے وزیراعظم تھے۔ آپ...   \n",
       "3  مرزا غالب 1797- 1869 اردو زبان کے سب سے بڑے شا...   \n",
       "4  ٹیپو سلطان 10 نومبر1750~ 4 مئی 1799 ہندوستان م...   \n",
       "\n",
       "                                           sentence2  label  \n",
       "0  چودھر ی رحمت علی 16 نومبر 1897ء کو ہوشیارپور ک...      0  \n",
       "1  حضرت محمد دیناوی تاریخ میں اہم ترین شخصیت کے ط...      0  \n",
       "2  پاکستان کے پہلے وزیر اعظم نواب لیاقت علی خان م...      0  \n",
       "3  1797ء سے 1869ء تک کے دور میں مرزا غالب اردو زب...      0  \n",
       "4  تاریخ کا وہ عظیم نام جس کا نام سنتے ہی اس کے د...      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df[\"label\"].value_counts())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cb01a33-2bfe-4a27-b971-d8111b53e4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label'],\n",
       "    num_rows: 140\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to HuggingFace Dataset\n",
    "hf_dataset = Dataset.from_pandas(df)\n",
    "hf_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "210da880-6ec2-4800-83fd-2d9fd8083770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 70013.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Cast Label to ClassLabel\n",
    "label_feature = ClassLabel(\n",
    "    num_classes=2,\n",
    "    names=[\"not_paraphrase\", \"paraphrase\"]\n",
    ")\n",
    "\n",
    "hf_dataset = hf_dataset.cast_column(\"label\", label_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "362d442e-3e23-4a2f-b3d7-3fc835687f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value('string'),\n",
       " 'sentence2': Value('string'),\n",
       " 'label': ClassLabel(names=['not_paraphrase', 'paraphrase'])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_dataset.features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91735b02-e88c-467d-b92c-a933999efdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Shot Dataset\n",
    "zero_shot_dataset = hf_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a26bd1b-8f28-4932-b640-e40c7fbfd5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 65\n"
     ]
    }
   ],
   "source": [
    "# 16-Shot Dataset\n",
    "df_pos = df[df[\"label\"] == 1]   # paraphrase\n",
    "df_neg = df[df[\"label\"] == 0]   # not paraphrase\n",
    "\n",
    "print(len(df_pos), len(df_neg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db5d7f61-6b30-473b-b21a-6dd3bddc25cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    16\n",
       "0    16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take FIRST 16 per class\n",
    "df_16shot = pd.concat([\n",
    "    df_pos.iloc[:16],\n",
    "    df_neg.iloc[:16]\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "df_16shot[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50b3437b-69ba-4046-82a1-6fbcfde42a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|███████████████████████████████████████████████████████████████████████████| 32/32 [00:00<?, ? examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label'],\n",
       "    num_rows: 32\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to HF Dataset\n",
    "hf_16shot = Dataset.from_pandas(df_16shot)\n",
    "hf_16shot = hf_16shot.cast_column(\"label\", label_feature)\n",
    "\n",
    "hf_16shot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c28f6f90-246a-44c3-b90e-a63950ca784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Casting the dataset: 100%|██████████████████████████████████████████████████████████████| 108/108 [00:00<00:00, 80674.06 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Remaining data for evaluation\n",
    "df_remaining = df.drop(df_16shot.index).reset_index(drop=True)\n",
    "\n",
    "hf_16shot_eval = Dataset.from_pandas(df_remaining)\n",
    "hf_16shot_eval = hf_16shot_eval.cast_column(\"label\", label_feature)\n",
    "\n",
    "print(len(hf_16shot), len(hf_16shot_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e541301-76d7-4435-b16f-40a7730db43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 112\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 28\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80 / 20 Stratified Split\n",
    "hf_80_20 = hf_dataset.train_test_split(\n",
    "    test_size=0.2,\n",
    "    seed=SEED,\n",
    "    stratify_by_column=\"label\"\n",
    ")\n",
    "\n",
    "hf_80_20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38947dfb-644b-494e-a23f-8a7149f1e83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels: Counter({1: 60, 0: 52})\n",
      "Test labels: Counter({1: 15, 0: 13})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Train labels:\", Counter(hf_80_20[\"train\"][\"label\"]))\n",
    "print(\"Test labels:\", Counter(hf_80_20[\"test\"][\"label\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e29108cd-35c9-4742-8cd9-871d759d8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load XLM-R Tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de352243-1f28-4e45-9e7b-a9270298bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tokenization Function\n",
    "MAX_LEN = 128\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"sentence1\"],\n",
    "        batch[\"sentence2\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f0564d2-e513-4dbd-8ffc-63175e232dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 860.84 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize All Datasets\n",
    "# Zero-shot\n",
    "tokenized_zero = zero_shot_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46fdb5c3-aeee-41d0-a422-022f3967ef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 1044.37 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:00<00:00, 966.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 16-shot\n",
    "tokenized_16_train = hf_16shot.map(tokenize_function, batched=True)\n",
    "tokenized_16_eval  = hf_16shot_eval.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "013fb375-a0ec-42d1-8138-9699c43d1860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 895.49 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:00<00:00, 778.02 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 80 / 20\n",
    "tokenized_80_train = hf_80_20[\"train\"].map(tokenize_function, batched=True)\n",
    "tokenized_80_test  = hf_80_20[\"test\"].map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24dd21c3-84d3-4f46-b377-1fad90913a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Torch Format\n",
    "columns = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "\n",
    "tokenized_zero.set_format(type=\"torch\", columns=columns)\n",
    "tokenized_16_train.set_format(type=\"torch\", columns=columns)\n",
    "tokenized_16_eval.set_format(type=\"torch\", columns=columns)\n",
    "tokenized_80_train.set_format(type=\"torch\", columns=columns)\n",
    "tokenized_80_test.set_format(type=\"torch\", columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d69044ec-5ff1-40fa-a0f5-49837ec46572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(1),\n",
       " 'input_ids': tensor([     0, 208300,  91990,   8286,    611, 112591,   1819,  14773,    554,\n",
       "         173991,  21345,    216,  69222,   2437,    870,  46467,  34957,    216,\n",
       "           7482,   3239,    904,   5086,  32276,  10252,    317,   1541,  69300,\n",
       "          18900,   4914,  71598,  64170,    140,  31517,    216, 105003,  11712,\n",
       "         151090, 166486,  36455,  15368,    778,   1541, 220202,    504,   9564,\n",
       "            288,    715,   1541,  20096,  31975,  91542,   7778,  22407, 131335,\n",
       "           1901,    498,  35498,    431,   6708,  29000,  11917,  96071, 121379,\n",
       "              2,      2, 208300,  91990,   8286,  21345,    216,  69222,   2437,\n",
       "            870,  46467,  34957,    216,   1541, 181839,   5086,  32276,  10252,\n",
       "            317,   1541,  18900,   4914,  71598,  64170,    140,  31517,    216,\n",
       "         105003,    611, 112591, 117430,   3088,    554,  11712, 151090,  15368,\n",
       "            778, 166486,  36455,   1541,  82287,    907,    504,   9564,    288,\n",
       "           4660,    554,   1541,  20096,  31975,  91542,   7778,  22407,   3662,\n",
       "            778, 131335,   1901,    498,  35498,   8067,  60658,  29000,  11917,\n",
       "          96071,      2]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_16_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "848b9b11-8b3d-4fe1-97c0-20e5f2d3d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load XLM-RoBERTa-Large\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-large\",\n",
    "    num_labels=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a9c5077-0710-4d94-88a2-8dfac81dffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze Encoder (Zero-Shot Rule)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "075a3481-83e2-494e-87e5-ff339ccc2dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.requires_grad for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fecd2d44-1b1b-4785-b9ba-dc2c1d334ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingArguments (Zero-Shot)\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/uppc_xlmr_zero\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    fp16=True,\n",
    "    max_grad_norm=1.0,\n",
    "\n",
    "    report_to=\"none\",\n",
    "    seed=SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "050eb519-81a0-4404-af88-4ffc8fa39f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7dccea9-9761-4596-979e-fb0605c59b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_61552\\3859933720.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_zero = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Trainer (Zero-Shot)\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_zero = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_zero,\n",
    "    eval_dataset=tokenized_zero,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd142459-2694-4c95-a1b6-b0aed8bda0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 00:52, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.718400</td>\n",
       "      <td>0.700541</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.708300</td>\n",
       "      <td>0.694789</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.691643</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.694400</td>\n",
       "      <td>0.690360</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.706800</td>\n",
       "      <td>0.689914</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.709900</td>\n",
       "      <td>0.689701</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.690800</td>\n",
       "      <td>0.689481</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.680700</td>\n",
       "      <td>0.689289</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.698600</td>\n",
       "      <td>0.689101</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.689300</td>\n",
       "      <td>0.688993</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>0.688822</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.698500</td>\n",
       "      <td>0.688682</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.697600</td>\n",
       "      <td>0.688546</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.693500</td>\n",
       "      <td>0.688435</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.683900</td>\n",
       "      <td>0.688361</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.688200</td>\n",
       "      <td>0.688292</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.680900</td>\n",
       "      <td>0.688246</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.688184</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.688163</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.700400</td>\n",
       "      <td>0.688138</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.6954454016685486, metrics={'train_runtime': 52.0471, 'train_samples_per_second': 53.797, 'train_steps_per_second': 1.921, 'total_flos': 652351954329600.0, 'train_loss': 0.6954454016685486, 'epoch': 20.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zero-Shot\n",
    "trainer_zero.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf6383bf-c2d4-475a-a893-4f71a476938e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6916434168815613,\n",
       " 'eval_accuracy': 0.5357142857142857,\n",
       " 'eval_f1': 0.6976744186046512,\n",
       " 'eval_runtime': 0.202,\n",
       " 'eval_samples_per_second': 693.039,\n",
       " 'eval_steps_per_second': 24.751,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_zero_results = trainer_zero.evaluate()\n",
    "xlmr_zero_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d94fbd10-4406-4f40-b05e-9c42adf8556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 16-Shot Fine-Tuning\n",
    "# Load a FRESH XLM-R Model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-large\",\n",
    "    num_labels=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76b4a65d-fec3-410b-9f7b-5bb1dc89bb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.requires_grad for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8153c42d-f84d-48af-8c55-9d78b14b11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingArguments (16-Shot)\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_16 = TrainingArguments(\n",
    "    output_dir=\"./results/uppc_xlmr_16shot\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    fp16=True,\n",
    "    max_grad_norm=1.0,\n",
    "\n",
    "    report_to=\"none\",\n",
    "    seed=SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38c0a567-13c9-445d-88b5-d20bc46f4110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_61552\\3821337507.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_16 = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Trainer (16-Shot)\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_16 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_16,\n",
    "    train_dataset=tokenized_16_train,\n",
    "    eval_dataset=tokenized_16_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d55e7733-c78d-48f7-898a-eb4bf45f0eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 03:46, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.710800</td>\n",
       "      <td>0.640024</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.819672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.695900</td>\n",
       "      <td>0.658922</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.819672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.742300</td>\n",
       "      <td>0.685045</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.656600</td>\n",
       "      <td>0.702203</td>\n",
       "      <td>0.453704</td>\n",
       "      <td>0.351648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.739500</td>\n",
       "      <td>0.710497</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.615300</td>\n",
       "      <td>0.738483</td>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.192771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.628700</td>\n",
       "      <td>0.755769</td>\n",
       "      <td>0.435185</td>\n",
       "      <td>0.314607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.725108</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.514851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.595300</td>\n",
       "      <td>0.725108</td>\n",
       "      <td>0.546296</td>\n",
       "      <td>0.514851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.598400</td>\n",
       "      <td>0.681505</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.721311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.582800</td>\n",
       "      <td>0.655391</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.738462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.527700</td>\n",
       "      <td>0.622446</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.791367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.516500</td>\n",
       "      <td>0.602177</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.843537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.572500</td>\n",
       "      <td>0.589565</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.542700</td>\n",
       "      <td>0.585128</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.866242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>0.577273</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.866242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.479300</td>\n",
       "      <td>0.574931</td>\n",
       "      <td>0.842593</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.492600</td>\n",
       "      <td>0.574560</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.900662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.503400</td>\n",
       "      <td>0.576282</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.453500</td>\n",
       "      <td>0.579443</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=0.587109375, metrics={'train_runtime': 227.9017, 'train_samples_per_second': 2.808, 'train_steps_per_second': 0.088, 'total_flos': 149109018132480.0, 'train_loss': 0.587109375, 'epoch': 20.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_16.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c99dcdc6-53db-4654-bb67-022539a4c780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5745601058006287,\n",
       " 'eval_accuracy': 0.8611111111111112,\n",
       " 'eval_f1': 0.9006622516556292,\n",
       " 'eval_runtime': 0.1975,\n",
       " 'eval_samples_per_second': 546.723,\n",
       " 'eval_steps_per_second': 20.249,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_16_results = trainer_16.evaluate()\n",
    "xlmr_16_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f6f8525-4cd5-424d-9742-d83373f0b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 80 / 20 Full Fine-Tuning\n",
    "# Load a FRESH XLM-R Model\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-large\",\n",
    "    num_labels=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ef15f95-fc45-4fcf-b7fc-fd6b6320d626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.requires_grad for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b2bc774-f6bf-4828-95f0-544441183606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainingArguments (80/20)\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_80 = TrainingArguments(\n",
    "    output_dir=\"./results/uppc_xlmr_80_20\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    fp16=True,\n",
    "    max_grad_norm=1.0,\n",
    "\n",
    "    report_to=\"none\",\n",
    "    seed=SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e647a19-c984-46fd-9942-0f382e5ad7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_61552\\1890712667.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_80 = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Trainer (80/20)\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_80 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_80,\n",
    "    train_dataset=tokenized_80_train,\n",
    "    eval_dataset=tokenized_80_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29f42046-cbda-4b6e-ba41-e3ed47216b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 09:45, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.730300</td>\n",
       "      <td>0.710153</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>0.694318</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.742100</td>\n",
       "      <td>0.747110</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.721100</td>\n",
       "      <td>0.661482</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.665200</td>\n",
       "      <td>0.645194</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.568200</td>\n",
       "      <td>0.650532</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.505079</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.515900</td>\n",
       "      <td>0.520469</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.481700</td>\n",
       "      <td>0.504669</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.413300</td>\n",
       "      <td>0.623469</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.350100</td>\n",
       "      <td>0.618154</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.418000</td>\n",
       "      <td>0.623795</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.428200</td>\n",
       "      <td>0.675778</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.327400</td>\n",
       "      <td>0.480391</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.317800</td>\n",
       "      <td>0.555760</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.274800</td>\n",
       "      <td>0.514215</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.580020</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.579819</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.581800</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.198900</td>\n",
       "      <td>0.574951</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=0.45747569054365156, metrics={'train_runtime': 589.6714, 'train_samples_per_second': 3.799, 'train_steps_per_second': 0.136, 'total_flos': 521881563463680.0, 'train_loss': 0.45747569054365156, 'epoch': 20.0})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train (80/20)\n",
    "trainer_80.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d37e98a9-f9d4-4e68-a741-c3ac2f1ce986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5050789713859558,\n",
       " 'eval_accuracy': 0.8928571428571429,\n",
       " 'eval_f1': 0.9032258064516129,\n",
       " 'eval_runtime': 1.0023,\n",
       " 'eval_samples_per_second': 27.936,\n",
       " 'eval_steps_per_second': 0.998,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Evaluation\n",
    "xlmr_80_results = trainer_80.evaluate()\n",
    "xlmr_80_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddfc91a-e34d-4672-bb1b-9fcad7a188a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (urdu_glue_gpu)",
   "language": "python",
   "name": "urdu_glue_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
