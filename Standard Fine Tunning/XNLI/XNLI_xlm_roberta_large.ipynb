{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740c0b58-e50c-434c-89f5-ecd70fa66271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Import ONLY inspection libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d34ae34-e8ed-4d42-b76a-7763b0e03a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Load the DEV dataset\n",
    "dev_path = r\"C:\\Users\\areesa\\Documents\\Urdu_GLUE_xlm_roberta\\data\\raw\\XNLI_Dev_Urdu - Sheet1 (1).tsv\"\n",
    "\n",
    "dev_df = pd.read_csv(dev_path, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a56d54d0-7c79-428c-a928-d18267cad15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2490, 3), Index(['gold_label', 'sentence1', 'sentence2'], dtype='object'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.shape, dev_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74741e8b-49a3-4577-8c94-77e5fb3e54bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.</td>\n",
       "      <td>ان کے فوائد کا اندازہ لگایا گیا تھا لیکن اس کا امکان غلط تھا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entailment</td>\n",
       "      <td>، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.</td>\n",
       "      <td>انہوں نے فوائد کا تخمینہ لگایا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.</td>\n",
       "      <td>انہیں فوائد کا تخمینیہ لگانے کا کوئی خیال  نہیں تھا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>.. کیوں ان کے پاس اتنی چھوٹی قدر ہے کہ وہ چور اور قاتلوں کی دوستی کی قدر کرتے ہیں.</td>\n",
       "      <td>ان کا کوئی ایک دوست بھی چور اچکا یا قاتل نہیں ہے۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entailment</td>\n",
       "      <td>.. کیوں ان کے پاس اتنی چھوٹی قدر ہے کہ وہ چور اور قاتلوں کی دوستی کی قدر کرتے ہیں.</td>\n",
       "      <td>ان کے کچھ دوست چور اور قاتل ہی۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutral</td>\n",
       "      <td>.. کیوں ان کے پاس اتنی چھوٹی قدر ہے کہ وہ چور اور قاتلوں کی دوستی کی قدر کرتے ہیں.</td>\n",
       "      <td>ان کے کچھ دوستو میں ببل گم چرائی ہے</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>..، لیکن دوسرا وقت سامنا ہے وہ دو دوستوں کے درمیان درمیان میں پکڑا جاتا ہے.</td>\n",
       "      <td>اس کے ساتھ صرف ایک مٹھ بھیڑ ہوئی جس میں اس کا دوست شامل ہے۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entailment</td>\n",
       "      <td>..، لیکن دوسرا وقت سامنا ہے وہ دو دوستوں کے درمیان درمیان میں پکڑا جاتا ہے.</td>\n",
       "      <td>دوسری مرتبہ ہونے والے مقابلے میں تین لوگ شامل ہیں۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral</td>\n",
       "      <td>..، لیکن دوسرا وقت سامنا ہے وہ دو دوستوں کے درمیان درمیان میں پکڑا جاتا ہے.</td>\n",
       "      <td>وہ نہیں جانتا کہ اپنے دونوں دوستوں میں سے کسی کی طرف داری کریں</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entailment</td>\n",
       "      <td>.تم نہیں جاؤ گے؟س نے کہا سوال اور دعوے کے درمیان</td>\n",
       "      <td>کیا تم نہیں جا رہے ہو؟ اس نے پوچھا۔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label  \\\n",
       "0        neutral   \n",
       "1     entailment   \n",
       "2  contradiction   \n",
       "3  contradiction   \n",
       "4     entailment   \n",
       "5        neutral   \n",
       "6  contradiction   \n",
       "7     entailment   \n",
       "8        neutral   \n",
       "9     entailment   \n",
       "\n",
       "                                                                                                                                 sentence1  \\\n",
       "0  ، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.   \n",
       "1  ، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.   \n",
       "2  ، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.   \n",
       "3                                                       .. کیوں ان کے پاس اتنی چھوٹی قدر ہے کہ وہ چور اور قاتلوں کی دوستی کی قدر کرتے ہیں.   \n",
       "4                                                       .. کیوں ان کے پاس اتنی چھوٹی قدر ہے کہ وہ چور اور قاتلوں کی دوستی کی قدر کرتے ہیں.   \n",
       "5                                                       .. کیوں ان کے پاس اتنی چھوٹی قدر ہے کہ وہ چور اور قاتلوں کی دوستی کی قدر کرتے ہیں.   \n",
       "6                                                              ..، لیکن دوسرا وقت سامنا ہے وہ دو دوستوں کے درمیان درمیان میں پکڑا جاتا ہے.   \n",
       "7                                                              ..، لیکن دوسرا وقت سامنا ہے وہ دو دوستوں کے درمیان درمیان میں پکڑا جاتا ہے.   \n",
       "8                                                              ..، لیکن دوسرا وقت سامنا ہے وہ دو دوستوں کے درمیان درمیان میں پکڑا جاتا ہے.   \n",
       "9                                                                                         .تم نہیں جاؤ گے؟س نے کہا سوال اور دعوے کے درمیان   \n",
       "\n",
       "                                                        sentence2  \n",
       "0    ان کے فوائد کا اندازہ لگایا گیا تھا لیکن اس کا امکان غلط تھا  \n",
       "1                                انہوں نے فوائد کا تخمینہ لگایا ۔  \n",
       "2           انہیں فوائد کا تخمینیہ لگانے کا کوئی خیال  نہیں تھا ۔  \n",
       "3               ان کا کوئی ایک دوست بھی چور اچکا یا قاتل نہیں ہے۔  \n",
       "4                                 ان کے کچھ دوست چور اور قاتل ہی۔  \n",
       "5                             ان کے کچھ دوستو میں ببل گم چرائی ہے  \n",
       "6     اس کے ساتھ صرف ایک مٹھ بھیڑ ہوئی جس میں اس کا دوست شامل ہے۔  \n",
       "7              دوسری مرتبہ ہونے والے مقابلے میں تین لوگ شامل ہیں۔  \n",
       "8  وہ نہیں جانتا کہ اپنے دونوں دوستوں میں سے کسی کی طرف داری کریں  \n",
       "9                             کیا تم نہیں جا رہے ہو؟ اس نے پوچھا۔  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.4 First look at the data\n",
    "dev_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e46d1390-2499-4ae3-9300-e58f27a1f838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold_label\n",
       "neutral          830\n",
       "entailment       830\n",
       "contradiction    830\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1 Count label frequencies\n",
    "dev_df[\"gold_label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b63eb8e7-b3f6-4fb4-942f-3b36c84846c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.2 Check for missing or invalid labels\n",
    "dev_df[\"gold_label\"].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ad745ef-310a-4320-b64a-25bdcffb679e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'entailment', 'contradiction'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df[\"gold_label\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b29b0d-a2c9-4fe1-a8d4-cb671366e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Load TEST dataset\n",
    "test_path = r\"C:\\Users\\areesa\\Documents\\Urdu_GLUE_xlm_roberta\\data\\raw\\XNLI_test_urdu - Sheet1.tsv\"\n",
    "\n",
    "test_df = pd.read_csv(test_path, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae0dd1f0-7231-4fc7-ae72-5c9bc2f60eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5010, 3), Index(['gold_label', 'sentence1', 'sentence2'], dtype='object'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2 Inspect shape and columns\n",
    "test_df.shape, test_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f2897f5-f4fb-48c9-9bed-aa2cde66b01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entailment</td>\n",
       "      <td>یہ تہوار تین سے چار دن سے منایا جاتا ہے، جس میں کئی کروڑ قریبی قسط واپس آنے کے لۓ.</td>\n",
       "      <td>- تہوار ایک ہفتےکے اندر ہوگا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>تمام ضروری حصوں یا عناصر کو شامل کرنا.</td>\n",
       "      <td>-انہیں نئے راکٹ کے حصوں میں شامل کرنا ہوگا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>پچھلے صدیوں میں، تاہم، یہ کیریبین قزاقوں کا شکار تھا،ہننا میں نوآبادیاتی اداروں کے چشموں سے دور،پیٹوٹو ریکو اور پاناما سٹی میں قریبی نوآبادیاتی جگہوں پر سان جوآن.</td>\n",
       "      <td>-کیریبین میں کبھی قزاقوں نہیں تھے</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>یہ آج ہم زندہ راستہ ہے، گیری کہہ رہا ہے، کیوں اس سے لطف اندوز نہیں ہے؟</td>\n",
       "      <td>-گہری کو خوشی کی فکر نہیں</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>لیکن اب میکسیل نے ایک مکھی مخلوق میں داخل ہوکر اس کو مدعو کیا، بعد میں میکسیل کے راکشس کو ڈوب دیا.</td>\n",
       "      <td>,د مهارت نشتوالی له کبله میکس ویل هیڅکله په خپل ټول ژوند کي  .هیڅح شی نه دی ایجاد کړي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entailment</td>\n",
       "      <td>غیر ملکیوں نے ملک چھوڑنے کے بعد نمائندوں کو ختم کرنے کے بارے میں کئی گواہوں کی گواہی دی.</td>\n",
       "      <td>,ډیری شاهدانو نماینده ګانې رد کړه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neutral</td>\n",
       "      <td>ہمیں یہی مشورہ دیا گیا تھا.</td>\n",
       "      <td>,کله چې ویل کیده چې څه وکړي اداره ناکامه شوه چي موږ دننه د  .سوداګري رازونو ته راپریږدي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neutral</td>\n",
       "      <td>تو سلیٹ کے پاس کتنے قارئین ہیں؟</td>\n",
       "      <td>،سټیټ یو بلیون لوستونکي لريسمه ده؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>اگر اور اس منصوبے کو مکمل کیا جائے تو، یہ پوری سلسلہ کا سب سے زیادہ دلچسپ ہونا چاہئے.</td>\n",
       "      <td>!یہ بہت بورنگ ہے</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entailment</td>\n",
       "      <td>..آپ کا حصہ بننے پر آپ پر فخر ہو گی؟</td>\n",
       "      <td>?ایک آپ بھی تعاون رکن ہو گے</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label  \\\n",
       "0     entailment   \n",
       "1        neutral   \n",
       "2  contradiction   \n",
       "3  contradiction   \n",
       "4  contradiction   \n",
       "5     entailment   \n",
       "6        neutral   \n",
       "7        neutral   \n",
       "8  contradiction   \n",
       "9     entailment   \n",
       "\n",
       "                                                                                                                                                            sentence1  \\\n",
       "0                                                                                  یہ تہوار تین سے چار دن سے منایا جاتا ہے، جس میں کئی کروڑ قریبی قسط واپس آنے کے لۓ.   \n",
       "1                                                                                                                              تمام ضروری حصوں یا عناصر کو شامل کرنا.   \n",
       "2  پچھلے صدیوں میں، تاہم، یہ کیریبین قزاقوں کا شکار تھا،ہننا میں نوآبادیاتی اداروں کے چشموں سے دور،پیٹوٹو ریکو اور پاناما سٹی میں قریبی نوآبادیاتی جگہوں پر سان جوآن.   \n",
       "3                                                                                              یہ آج ہم زندہ راستہ ہے، گیری کہہ رہا ہے، کیوں اس سے لطف اندوز نہیں ہے؟   \n",
       "4                                                                  لیکن اب میکسیل نے ایک مکھی مخلوق میں داخل ہوکر اس کو مدعو کیا، بعد میں میکسیل کے راکشس کو ڈوب دیا.   \n",
       "5                                                                            غیر ملکیوں نے ملک چھوڑنے کے بعد نمائندوں کو ختم کرنے کے بارے میں کئی گواہوں کی گواہی دی.   \n",
       "6                                                                                                                                         ہمیں یہی مشورہ دیا گیا تھا.   \n",
       "7                                                                                                                                     تو سلیٹ کے پاس کتنے قارئین ہیں؟   \n",
       "8                                                                               اگر اور اس منصوبے کو مکمل کیا جائے تو، یہ پوری سلسلہ کا سب سے زیادہ دلچسپ ہونا چاہئے.   \n",
       "9                                                                                                                                ..آپ کا حصہ بننے پر آپ پر فخر ہو گی؟   \n",
       "\n",
       "                                                                                 sentence2  \n",
       "0                                                             - تہوار ایک ہفتےکے اندر ہوگا  \n",
       "1                                               -انہیں نئے راکٹ کے حصوں میں شامل کرنا ہوگا  \n",
       "2                                                        -کیریبین میں کبھی قزاقوں نہیں تھے  \n",
       "3                                                                -گہری کو خوشی کی فکر نہیں  \n",
       "4    ,د مهارت نشتوالی له کبله میکس ویل هیڅکله په خپل ټول ژوند کي  .هیڅح شی نه دی ایجاد کړي  \n",
       "5                                                        ,ډیری شاهدانو نماینده ګانې رد کړه  \n",
       "6  ,کله چې ویل کیده چې څه وکړي اداره ناکامه شوه چي موږ دننه د  .سوداګري رازونو ته راپریږدي  \n",
       "7                                                       ،سټیټ یو بلیون لوستونکي لريسمه ده؟  \n",
       "8                                                                         !یہ بہت بورنگ ہے  \n",
       "9                                                              ?ایک آپ بھی تعاون رکن ہو گے  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.3 Look at first 10 rows\n",
    "test_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6099583-7ea4-4f4e-a046-ee5a041dfa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_label\n",
      "neutral          1670\n",
      "contradiction    1670\n",
      "entailment       1669\n",
      "gold_label          1\n",
      "Name: count, dtype: int64\n",
      "0\n",
      "['entailment' 'neutral' 'contradiction' 'gold_label']\n"
     ]
    }
   ],
   "source": [
    "# 3.4 Check labels (very important)\n",
    "if \"gold_label\" in test_df.columns:\n",
    "    print(test_df[\"gold_label\"].value_counts())\n",
    "    print(test_df[\"gold_label\"].isna().sum())\n",
    "    print(test_df[\"gold_label\"].unique())\n",
    "else:\n",
    "    print(\"No gold labels in test set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01dfc264-b384-4ba5-851a-a692f9e9d640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>gold_label</td>\n",
       "      <td>sentence1</td>\n",
       "      <td>sentence2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gold_label  sentence1  sentence2\n",
       "185  gold_label  sentence1  sentence2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.3 — FIX THE CORRUPTED ROW\n",
    "# 3.3.1 Locate the bad row\n",
    "test_df[test_df[\"gold_label\"] == \"gold_label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ac2a44-aab1-4de8-a2bf-50b81c48a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3.2 Remove it safely\n",
    "test_df = test_df[test_df[\"gold_label\"] != \"gold_label\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fecec220-b365-4d0c-b5bf-ef20e97a2fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5009, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.3.3 Re-check labels (must be clean)\n",
    "test_df[\"gold_label\"].value_counts()\n",
    "test_df[\"gold_label\"].unique()\n",
    "test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e1c3b49-0567-42a0-ac72-b2d1f5c334b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"contradiction\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba52d24a-53cc-4976-903a-0f06eef7e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Apply label mapping (DEV + TEST)\n",
    "dev_df[\"label\"] = dev_df[\"gold_label\"].map(label2id)\n",
    "test_df[\"label\"] = test_df[\"gold_label\"].map(label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "088142be-158f-427c-9780-c3a6db6eb96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entailment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label  label\n",
       "1     entailment      0\n",
       "0        neutral      1\n",
       "2  contradiction      2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.2 Verify mapping correctness\n",
    "dev_df[[\"gold_label\", \"label\"]].drop_duplicates().sort_values(\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1ae334c-b7bc-47a4-b16e-61d40c8007e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entailment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label  label\n",
       "0     entailment      0\n",
       "1        neutral      1\n",
       "2  contradiction      2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[[\"gold_label\", \"label\"]].drop_duplicates().sort_values(\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebdf84f4-8713-437d-b1b3-d284c7551172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\anaconda3\\envs\\urdu_glue_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 5 — Convert to HuggingFace Dataset\n",
    "# 5.1 Import required libraries\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a24c0c82-d7f2-43f9-b4f4-f2843cef02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force text columns to string to avoid tokenizer crash\n",
    "for col in [\"sentence1\", \"sentence2\"]:\n",
    "    dev_df[col] = dev_df[col].astype(str)\n",
    "    test_df[col] = test_df[col].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90750543-d053-4bb7-ae4d-059961f7a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Create HF datasets (DEV & TEST)\n",
    "from datasets import Dataset\n",
    "\n",
    "dev_dataset = Dataset.from_pandas(\n",
    "    dev_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(\n",
    "    test_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21e0c21f-595a-4920-a07e-504046899a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label'],\n",
       "    num_rows: 2490\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.3 Inspect dataset features\n",
    "dev_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0510ecd-da30-4549-9e8f-2dfbe3b8039b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': '، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.',\n",
       " 'sentence2': 'ان کے فوائد کا اندازہ لگایا گیا تھا لیکن اس کا امکان غلط تھا',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d41bd3b-a216-42f7-8063-07e8d5e4df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 — Tokenizer & Model Setup (XLM-R Large)\n",
    "# 6.1 Load tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8496a27-8121-4758-b8a3-bb3d490fd360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Define tokenization function (PAIR encoding)\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence1\"],\n",
    "        examples[\"sentence2\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03521d4e-9052-4b3b-9938-69ac9563b595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████| 2490/2490 [00:00<00:00, 27301.67 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████| 5009/5009 [00:00<00:00, 27673.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 6.3 Tokenize DEV and TEST\n",
    "dev_tokenized = dev_dataset.map(tokenize_function, batched=True)\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ac4a479-6a31-43c1-8d60-71f5f256724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4 — Set PyTorch format\n",
    "columns = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "\n",
    "dev_tokenized.set_format(type=\"torch\", columns=columns)\n",
    "test_tokenized.set_format(type=\"torch\", columns=columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec409cd2-176b-4e4e-948e-abee47bccfbe",
   "metadata": {},
   "source": [
    "# 7 — ZERO-SHOT XNLI EVALUATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "803245af-a89d-45d5-aa36-39360b67ebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Load model for sequence classification\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-large\",\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0be08024-a30e-4a0f-a32c-6a2748b66391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 Define evaluation metrics (Accuracy + Macro-F1)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64c65023-e224-4806-a9ae-7871674077e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_22860\\439675416.py:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_zero = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# 7.3 Create Trainer (evaluation-only)\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./xnli_zero_shot\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    logging_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer_zero = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=test_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bf0bfbe-0104-4739-b1d3-be43f01157b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1126903295516968,\n",
       " 'eval_model_preparation_time': 0.0019,\n",
       " 'eval_accuracy': 0.3333998802156119,\n",
       " 'eval_f1': 0.16669162050207117,\n",
       " 'eval_runtime': 15.5985,\n",
       " 'eval_samples_per_second': 321.121,\n",
       " 'eval_steps_per_second': 10.065}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.4 Run ZERO-SHOT evaluation\n",
    "zero_shot_results = trainer_zero.evaluate()\n",
    "zero_shot_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a33b4b5-e954-4acc-b3c4-67eee4074532",
   "metadata": {},
   "source": [
    "# 7 — ZERO-SHOT XNLI (STANDARD FINE-TUNING DEFINITION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56c46f29-1027-4650-b629-76019509f1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Load model (fresh, clean)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-large\",\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff3df593-b638-480e-94a8-415801727f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2  Freeze the encoder\n",
    "for param in model.roberta.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e572533-4bf4-4e4c-b201-e85b9c3c9d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 393)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_params = sum(p.requires_grad for p in model.parameters())\n",
    "total_params = sum(1 for _ in model.parameters())\n",
    "\n",
    "trainable_params, total_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18ca0759-d1fa-4907-b31c-299be7bc9a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 Define metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\")\n",
    "    }\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "061b265c-4e42-4179-8bae-8e832daf2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.4 TrainingArguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_xnli_zero = TrainingArguments(\n",
    "    output_dir=\"./xnli_zero_shot\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b11a322-82b1-41ac-bc41-cb0d8a233138",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_22860\\1543279949.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_zero = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# 7.5 Create Trainer\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_zero = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_xnli_zero,\n",
    "    train_dataset=dev_tokenized,   # classifier is trained here\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ad5d2f1-ebb1-437c-8f46-bd2faf0048e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1560' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1560/1560 04:02, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.099010</td>\n",
       "      <td>0.334997</td>\n",
       "      <td>0.251554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.101133</td>\n",
       "      <td>0.333600</td>\n",
       "      <td>0.167464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.104600</td>\n",
       "      <td>1.101087</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>0.166692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.104600</td>\n",
       "      <td>1.098098</td>\n",
       "      <td>0.336594</td>\n",
       "      <td>0.189615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.104600</td>\n",
       "      <td>1.098879</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>0.166692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.106200</td>\n",
       "      <td>1.097884</td>\n",
       "      <td>0.349970</td>\n",
       "      <td>0.243662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.106200</td>\n",
       "      <td>1.097849</td>\n",
       "      <td>0.339788</td>\n",
       "      <td>0.182869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.104400</td>\n",
       "      <td>1.097435</td>\n",
       "      <td>0.361948</td>\n",
       "      <td>0.302453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.104400</td>\n",
       "      <td>1.097940</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.266429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.104400</td>\n",
       "      <td>1.097140</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>0.368160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.103900</td>\n",
       "      <td>1.097188</td>\n",
       "      <td>0.352166</td>\n",
       "      <td>0.303154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.103900</td>\n",
       "      <td>1.097592</td>\n",
       "      <td>0.365941</td>\n",
       "      <td>0.290856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.100300</td>\n",
       "      <td>1.097198</td>\n",
       "      <td>0.346177</td>\n",
       "      <td>0.252906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.100300</td>\n",
       "      <td>1.097004</td>\n",
       "      <td>0.356159</td>\n",
       "      <td>0.304509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.100300</td>\n",
       "      <td>1.097021</td>\n",
       "      <td>0.357157</td>\n",
       "      <td>0.284754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.102600</td>\n",
       "      <td>1.096891</td>\n",
       "      <td>0.372130</td>\n",
       "      <td>0.328848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.102600</td>\n",
       "      <td>1.096766</td>\n",
       "      <td>0.367339</td>\n",
       "      <td>0.353670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.100400</td>\n",
       "      <td>1.096689</td>\n",
       "      <td>0.380914</td>\n",
       "      <td>0.374986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.100400</td>\n",
       "      <td>1.096738</td>\n",
       "      <td>0.373528</td>\n",
       "      <td>0.328971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.100400</td>\n",
       "      <td>1.096727</td>\n",
       "      <td>0.370134</td>\n",
       "      <td>0.331667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1560, training_loss=1.1028262896415515, metrics={'train_runtime': 242.7909, 'train_samples_per_second': 205.115, 'train_steps_per_second': 6.425, 'total_flos': 1.16025846759936e+16, 'train_loss': 1.1028262896415515, 'epoch': 20.0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.6  Run ZERO-SHOT training + evaluation\n",
    "trainer_zero.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0e76042-5d07-4d94-8ff3-e2addcba66bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.096689224243164,\n",
       " 'eval_accuracy': 0.38091435416250746,\n",
       " 'eval_f1': 0.3749860704506626,\n",
       " 'eval_runtime': 6.4827,\n",
       " 'eval_samples_per_second': 772.67,\n",
       " 'eval_steps_per_second': 24.218,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_results = trainer_zero.evaluate()\n",
    "zero_shot_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66fc7df-74d9-4cd4-99d2-122e1806aa7f",
   "metadata": {},
   "source": [
    "# 16-SHOT XNLI (Full Fine-Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62fc8235-faa0-4338-86ff-5db024368317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold_label\n",
       "neutral          830\n",
       "entailment       830\n",
       "contradiction    830\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.1 — Create 16-SHOT XNLI Dataset\n",
    "dev_df[\"gold_label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e1b8210-1c44-4e85-95b8-fc6dfd96a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1.2 Select FIRST 16 examples per class\n",
    "fewshot_df = (\n",
    "    dev_df\n",
    "    .groupby(\"gold_label\", sort=False)\n",
    "    .head(16)\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "265f7589-638d-48d5-bc30-9b6e11bf9648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 4)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8.1.3 Verify few-shot dataset\n",
    "fewshot_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5f4b7d5-4ad0-4eb4-9961-5a72bd929d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold_label\n",
       "neutral          16\n",
       "entailment       16\n",
       "contradiction    16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8.1.4 Verify class balance\n",
    "fewshot_df[\"gold_label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c507c328-fd5b-4bb9-88d6-8874f42c8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.2.1 Create HF dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "fewshot_dataset = Dataset.from_pandas(\n",
    "    fewshot_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "783a9eb3-5831-445e-9947-3544346d18ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label'],\n",
       "    num_rows: 48\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8.2.2 Inspect dataset\n",
    "fewshot_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "409a6043-7886-4d4d-882d-3eff5ca93c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████| 48/48 [00:00<00:00, 8243.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 8.3.1 Tokenize\n",
    "fewshot_tokenized = fewshot_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c8df9d7-d791-449d-a9ed-a384c8f7c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.3.2 Set PyTorch format\n",
    "columns = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "fewshot_tokenized.set_format(type=\"torch\", columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c270d1e7-503c-4b4e-9dc4-4e230aed1c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(1),\n",
       " 'input_ids': tensor([     0,    725,  33361,   6472,   6575,  39448,      6,  32410,    490,\n",
       "           9520,    425,    159,  10931,  14917,      6,  32410,  23198, 131110,\n",
       "            216,   5435,    216,  11987,    317, 204994,    423,     12,    706,\n",
       "            248,    347,    363,    523,  35169,  31743,    216, 125334,    317,\n",
       "           1541,  12037,    288, 116020, 141768,    639,      5,      2,      2,\n",
       "            716,    216, 131110,    499, 204994, 184100,   5023,   4566,   8880,\n",
       "            754,    499,  22363,  45019,   4566,      2,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8.3.3 Quick sanity check\n",
    "fewshot_tokenized[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0caf9f0-fd0d-4aea-8fe3-c203e761cd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 8.4.1 Reload model (clean state)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-large\",\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c3b5c7b-668f-4ea1-a8c8-31303170ad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.requires_grad for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f575c61-40c0-44d6-89e8-279e59392c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_xnli_16 = TrainingArguments(\n",
    "    output_dir=\"./xnli_16shot\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c4ce164-9bb9-4dc5-86fd-8f90497953c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_22860\\1338705381.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_16 = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# 8.6 — Trainer (16-SHOT)\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_16 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_xnli_16,\n",
    "    train_dataset=fewshot_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b31ac17-57b8-49c0-af8f-dc57651b215f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 16:28, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.143732</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>0.166692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.123744</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>0.166692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.113187</td>\n",
       "      <td>0.332002</td>\n",
       "      <td>0.264508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.109518</td>\n",
       "      <td>0.333999</td>\n",
       "      <td>0.173997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.108287</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>0.166692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.106159</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>0.166692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.105252</td>\n",
       "      <td>0.333400</td>\n",
       "      <td>0.166692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.103968</td>\n",
       "      <td>0.334797</td>\n",
       "      <td>0.195018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.103614</td>\n",
       "      <td>0.326812</td>\n",
       "      <td>0.245179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.103882</td>\n",
       "      <td>0.332801</td>\n",
       "      <td>0.179454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.103589</td>\n",
       "      <td>0.333200</td>\n",
       "      <td>0.167484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.102977</td>\n",
       "      <td>0.334198</td>\n",
       "      <td>0.169700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.102277</td>\n",
       "      <td>0.333600</td>\n",
       "      <td>0.183803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.100664</td>\n",
       "      <td>0.333600</td>\n",
       "      <td>0.265970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.099305</td>\n",
       "      <td>0.334997</td>\n",
       "      <td>0.227728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.098532</td>\n",
       "      <td>0.332601</td>\n",
       "      <td>0.171402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.099063</td>\n",
       "      <td>0.335995</td>\n",
       "      <td>0.173801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.101310</td>\n",
       "      <td>0.343582</td>\n",
       "      <td>0.199575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.107034</td>\n",
       "      <td>0.351567</td>\n",
       "      <td>0.236395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.111117</td>\n",
       "      <td>0.355560</td>\n",
       "      <td>0.254255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=40, training_loss=1.1084833145141602, metrics={'train_runtime': 988.4546, 'train_samples_per_second': 0.971, 'train_steps_per_second': 0.04, 'total_flos': 223664282910720.0, 'train_loss': 1.1084833145141602, 'epoch': 20.0})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_16.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2198e6fc-0a0c-429c-817b-7cfee3c4f4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1111172437667847,\n",
       " 'eval_accuracy': 0.3555599920143741,\n",
       " 'eval_f1': 0.254255429043113,\n",
       " 'eval_runtime': 7.1668,\n",
       " 'eval_samples_per_second': 698.918,\n",
       " 'eval_steps_per_second': 21.907,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_16shot = trainer_16.evaluate()\n",
    "\n",
    "results_16shot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eae169-6329-4471-9f66-d1c39eeab4de",
   "metadata": {},
   "source": [
    "# 80/20 FULL FINE-TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "012ebaa5-2f27-4d56-96cc-b6968b319fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1.1 Perform split (seed-fixed)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    dev_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=dev_df[\"label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7a3e7aaa-3201-4984-a9cf-d4393864e59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1992, 4), (498, 4))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9.1.2 Verify split sizes\n",
    "train_df.shape, val_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b576469c-d234-4f93-be77-13feb6d7bbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold_label\n",
       "contradiction    166\n",
       "neutral          166\n",
       "entailment       166\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9.1.3 Verify class balance\n",
    "train_df[\"gold_label\"].value_counts()\n",
    "val_df[\"gold_label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea6a0d2d-fd05-45ae-ab4e-64fa4fe61fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.2 — Convert to HuggingFace Datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(\n",
    "    train_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "val_dataset = Dataset.from_pandas(\n",
    "    val_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "311e51e4-1351-4e06-8653-571826c61ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['sentence1', 'sentence2', 'label'],\n",
       "     num_rows: 1992\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['sentence1', 'sentence2', 'label'],\n",
       "     num_rows: 498\n",
       " }))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "62c47bdf-13e6-4d5b-a3df-3e54ce431937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████| 1992/1992 [00:00<00:00, 24785.60 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████| 498/498 [00:00<00:00, 20094.89 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 9.3 — Tokenize (same tokenizer, same function)\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
    "val_tokenized = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "columns = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "train_tokenized.set_format(type=\"torch\", columns=columns)\n",
    "val_tokenized.set_format(type=\"torch\", columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d08c3fd2-83b4-43de-9b3b-75e9633c0ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(0),\n",
       " 'input_ids': tensor([     0,  15410,    258,  18062,    754,  99133,    904,    216, 104008,\n",
       "            490, 183790,    140,    216,   5818,    504,  89740,    216,   3685,\n",
       "          15737,    216,   1533,     50,   2598,    499,  25928,  18684,    216,\n",
       "          85841, 199478, 189490,     50,   6514,   1568,  30814,    900,    504,\n",
       "          85167,   1901,  25696,      2,      2, 183790,    140,    288,  89740,\n",
       "         199478,   1578,      2,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "865d98b7-4433-4b06-926b-860c79bbcdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 9.4 — Load Model (FULL FINE-TUNING)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-large\",\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "11e57740-1a67-43a8-8b4a-ed3f42aa503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.5 — TrainingArguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_xnli_8020 = TrainingArguments(\n",
    "    output_dir=\"./xnli_80_20\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf1e0c1c-cfc8-4a30-8f21-5968205d8121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_22860\\2934004533.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_8020 = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# 9.6 — Trainer (80/20)\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_8020 = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_xnli_8020,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ef5dd09d-2d1e-4f0a-9b6a-02488f079e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1260' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1260/1260 1:40:01, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.109850</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.099170</td>\n",
       "      <td>0.371486</td>\n",
       "      <td>0.289964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.080956</td>\n",
       "      <td>0.455823</td>\n",
       "      <td>0.438205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.113800</td>\n",
       "      <td>1.104645</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.113800</td>\n",
       "      <td>1.098956</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.113800</td>\n",
       "      <td>1.098649</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.110800</td>\n",
       "      <td>1.101055</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.110800</td>\n",
       "      <td>1.099649</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.110800</td>\n",
       "      <td>1.098951</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.105800</td>\n",
       "      <td>1.098941</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.105800</td>\n",
       "      <td>1.098635</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.105800</td>\n",
       "      <td>1.099260</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.102000</td>\n",
       "      <td>1.098958</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.102000</td>\n",
       "      <td>1.099186</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.102000</td>\n",
       "      <td>1.098939</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.105400</td>\n",
       "      <td>1.099274</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.105400</td>\n",
       "      <td>1.099019</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.105400</td>\n",
       "      <td>1.099264</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.105400</td>\n",
       "      <td>1.099600</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.102000</td>\n",
       "      <td>1.098958</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1260, training_loss=1.1064068627735926, metrics={'train_runtime': 6003.5619, 'train_samples_per_second': 6.636, 'train_steps_per_second': 0.21, 'total_flos': 9282067740794880.0, 'train_loss': 1.1064068627735926, 'epoch': 20.0})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_8020.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f0723196-e94b-4bc2-95f3-428adb37db75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0809556245803833,\n",
       " 'eval_accuracy': 0.45582329317269077,\n",
       " 'eval_f1': 0.43820489436084514,\n",
       " 'eval_runtime': 0.9718,\n",
       " 'eval_samples_per_second': 512.446,\n",
       " 'eval_steps_per_second': 16.464,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_8020 = trainer_8020.evaluate()\n",
    "results_8020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52298748-c739-4aaa-ba5b-626ad8806212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (urdu_glue_gpu)",
   "language": "python",
   "name": "urdu_glue_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
