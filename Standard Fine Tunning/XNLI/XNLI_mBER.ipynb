{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120878ba-f3c8-4199-bbd6-86db4baf338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1 — Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8a93b94-42b8-486f-b800-982bcb39a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2 — Load DEV dataset\n",
    "dev_path = r\"C:\\Users\\areesa\\Documents\\Urdu_GLUE_xlm_roberta\\data\\raw\\XNLI_Dev_Urdu - Sheet1 (1).tsv\"\n",
    "\n",
    "dev_df = pd.read_csv(dev_path, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a6567f-e332-4530-a513-38947a6f3b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2490, 3), Index(['gold_label', 'sentence1', 'sentence2'], dtype='object'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.3 — Inspect DEV shape & columns\n",
    "dev_df.shape, dev_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d62aff0-371e-45bd-ac81-0a7be8097b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.</td>\n",
       "      <td>ان کے فوائد کا اندازہ لگایا گیا تھا لیکن اس کا امکان غلط تھا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entailment</td>\n",
       "      <td>، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.</td>\n",
       "      <td>انہوں نے فوائد کا تخمینہ لگایا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.</td>\n",
       "      <td>انہیں فوائد کا تخمینیہ لگانے کا کوئی خیال  نہیں تھا ۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>.. کیوں ان کے پاس اتنی چھوٹی قدر ہے کہ وہ چور اور قاتلوں کی دوستی کی قدر کرتے ہیں.</td>\n",
       "      <td>ان کا کوئی ایک دوست بھی چور اچکا یا قاتل نہیں ہے۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entailment</td>\n",
       "      <td>.. کیوں ان کے پاس اتنی چھوٹی قدر ہے کہ وہ چور اور قاتلوں کی دوستی کی قدر کرتے ہیں.</td>\n",
       "      <td>ان کے کچھ دوست چور اور قاتل ہی۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutral</td>\n",
       "      <td>.. کیوں ان کے پاس اتنی چھوٹی قدر ہے کہ وہ چور اور قاتلوں کی دوستی کی قدر کرتے ہیں.</td>\n",
       "      <td>ان کے کچھ دوستو میں ببل گم چرائی ہے</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>..، لیکن دوسرا وقت سامنا ہے وہ دو دوستوں کے درمیان درمیان میں پکڑا جاتا ہے.</td>\n",
       "      <td>اس کے ساتھ صرف ایک مٹھ بھیڑ ہوئی جس میں اس کا دوست شامل ہے۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entailment</td>\n",
       "      <td>..، لیکن دوسرا وقت سامنا ہے وہ دو دوستوں کے درمیان درمیان میں پکڑا جاتا ہے.</td>\n",
       "      <td>دوسری مرتبہ ہونے والے مقابلے میں تین لوگ شامل ہیں۔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral</td>\n",
       "      <td>..، لیکن دوسرا وقت سامنا ہے وہ دو دوستوں کے درمیان درمیان میں پکڑا جاتا ہے.</td>\n",
       "      <td>وہ نہیں جانتا کہ اپنے دونوں دوستوں میں سے کسی کی طرف داری کریں</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entailment</td>\n",
       "      <td>.تم نہیں جاؤ گے؟س نے کہا سوال اور دعوے کے درمیان</td>\n",
       "      <td>کیا تم نہیں جا رہے ہو؟ اس نے پوچھا۔</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label  \\\n",
       "0        neutral   \n",
       "1     entailment   \n",
       "2  contradiction   \n",
       "3  contradiction   \n",
       "4     entailment   \n",
       "5        neutral   \n",
       "6  contradiction   \n",
       "7     entailment   \n",
       "8        neutral   \n",
       "9     entailment   \n",
       "\n",
       "                                                                                                                                 sentence1  \\\n",
       "0  ، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.   \n",
       "1  ، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.   \n",
       "2  ، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.   \n",
       "3                                                       .. کیوں ان کے پاس اتنی چھوٹی قدر ہے کہ وہ چور اور قاتلوں کی دوستی کی قدر کرتے ہیں.   \n",
       "4                                                       .. کیوں ان کے پاس اتنی چھوٹی قدر ہے کہ وہ چور اور قاتلوں کی دوستی کی قدر کرتے ہیں.   \n",
       "5                                                       .. کیوں ان کے پاس اتنی چھوٹی قدر ہے کہ وہ چور اور قاتلوں کی دوستی کی قدر کرتے ہیں.   \n",
       "6                                                              ..، لیکن دوسرا وقت سامنا ہے وہ دو دوستوں کے درمیان درمیان میں پکڑا جاتا ہے.   \n",
       "7                                                              ..، لیکن دوسرا وقت سامنا ہے وہ دو دوستوں کے درمیان درمیان میں پکڑا جاتا ہے.   \n",
       "8                                                              ..، لیکن دوسرا وقت سامنا ہے وہ دو دوستوں کے درمیان درمیان میں پکڑا جاتا ہے.   \n",
       "9                                                                                         .تم نہیں جاؤ گے؟س نے کہا سوال اور دعوے کے درمیان   \n",
       "\n",
       "                                                        sentence2  \n",
       "0    ان کے فوائد کا اندازہ لگایا گیا تھا لیکن اس کا امکان غلط تھا  \n",
       "1                                انہوں نے فوائد کا تخمینہ لگایا ۔  \n",
       "2           انہیں فوائد کا تخمینیہ لگانے کا کوئی خیال  نہیں تھا ۔  \n",
       "3               ان کا کوئی ایک دوست بھی چور اچکا یا قاتل نہیں ہے۔  \n",
       "4                                 ان کے کچھ دوست چور اور قاتل ہی۔  \n",
       "5                             ان کے کچھ دوستو میں ببل گم چرائی ہے  \n",
       "6     اس کے ساتھ صرف ایک مٹھ بھیڑ ہوئی جس میں اس کا دوست شامل ہے۔  \n",
       "7              دوسری مرتبہ ہونے والے مقابلے میں تین لوگ شامل ہیں۔  \n",
       "8  وہ نہیں جانتا کہ اپنے دونوں دوستوں میں سے کسی کی طرف داری کریں  \n",
       "9                             کیا تم نہیں جا رہے ہو؟ اس نے پوچھا۔  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.4 — First look at DEV data\n",
    "dev_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28388b83-8385-4594-a92a-2773af45d82f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.5 — Label sanity check (DEV)\n",
    "dev_df[\"gold_label\"].value_counts()\n",
    "dev_df[\"gold_label\"].unique()\n",
    "dev_df[\"gold_label\"].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e623106b-20bd-4ca8-bb53-6b9682b47cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 — Load TEST dataset\n",
    "test_path = r\"C:\\Users\\areesa\\Documents\\Urdu_GLUE_xlm_roberta\\data\\raw\\XNLI_test_urdu - Sheet1.tsv\"\n",
    "\n",
    "test_df = pd.read_csv(test_path, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f4f6d8-829f-4b2c-b071-060f5ea7014d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5010, 3), Index(['gold_label', 'sentence1', 'sentence2'], dtype='object'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2 — Inspect shape & columns\n",
    "test_df.shape, test_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33f7bfec-bbd9-4a85-8864-36448eccf055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entailment</td>\n",
       "      <td>یہ تہوار تین سے چار دن سے منایا جاتا ہے، جس میں کئی کروڑ قریبی قسط واپس آنے کے لۓ.</td>\n",
       "      <td>- تہوار ایک ہفتےکے اندر ہوگا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>تمام ضروری حصوں یا عناصر کو شامل کرنا.</td>\n",
       "      <td>-انہیں نئے راکٹ کے حصوں میں شامل کرنا ہوگا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>پچھلے صدیوں میں، تاہم، یہ کیریبین قزاقوں کا شکار تھا،ہننا میں نوآبادیاتی اداروں کے چشموں سے دور،پیٹوٹو ریکو اور پاناما سٹی میں قریبی نوآبادیاتی جگہوں پر سان جوآن.</td>\n",
       "      <td>-کیریبین میں کبھی قزاقوں نہیں تھے</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>یہ آج ہم زندہ راستہ ہے، گیری کہہ رہا ہے، کیوں اس سے لطف اندوز نہیں ہے؟</td>\n",
       "      <td>-گہری کو خوشی کی فکر نہیں</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>لیکن اب میکسیل نے ایک مکھی مخلوق میں داخل ہوکر اس کو مدعو کیا، بعد میں میکسیل کے راکشس کو ڈوب دیا.</td>\n",
       "      <td>,د مهارت نشتوالی له کبله میکس ویل هیڅکله په خپل ټول ژوند کي  .هیڅح شی نه دی ایجاد کړي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entailment</td>\n",
       "      <td>غیر ملکیوں نے ملک چھوڑنے کے بعد نمائندوں کو ختم کرنے کے بارے میں کئی گواہوں کی گواہی دی.</td>\n",
       "      <td>,ډیری شاهدانو نماینده ګانې رد کړه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>neutral</td>\n",
       "      <td>ہمیں یہی مشورہ دیا گیا تھا.</td>\n",
       "      <td>,کله چې ویل کیده چې څه وکړي اداره ناکامه شوه چي موږ دننه د  .سوداګري رازونو ته راپریږدي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neutral</td>\n",
       "      <td>تو سلیٹ کے پاس کتنے قارئین ہیں؟</td>\n",
       "      <td>،سټیټ یو بلیون لوستونکي لريسمه ده؟</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>اگر اور اس منصوبے کو مکمل کیا جائے تو، یہ پوری سلسلہ کا سب سے زیادہ دلچسپ ہونا چاہئے.</td>\n",
       "      <td>!یہ بہت بورنگ ہے</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entailment</td>\n",
       "      <td>..آپ کا حصہ بننے پر آپ پر فخر ہو گی؟</td>\n",
       "      <td>?ایک آپ بھی تعاون رکن ہو گے</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label  \\\n",
       "0     entailment   \n",
       "1        neutral   \n",
       "2  contradiction   \n",
       "3  contradiction   \n",
       "4  contradiction   \n",
       "5     entailment   \n",
       "6        neutral   \n",
       "7        neutral   \n",
       "8  contradiction   \n",
       "9     entailment   \n",
       "\n",
       "                                                                                                                                                            sentence1  \\\n",
       "0                                                                                  یہ تہوار تین سے چار دن سے منایا جاتا ہے، جس میں کئی کروڑ قریبی قسط واپس آنے کے لۓ.   \n",
       "1                                                                                                                              تمام ضروری حصوں یا عناصر کو شامل کرنا.   \n",
       "2  پچھلے صدیوں میں، تاہم، یہ کیریبین قزاقوں کا شکار تھا،ہننا میں نوآبادیاتی اداروں کے چشموں سے دور،پیٹوٹو ریکو اور پاناما سٹی میں قریبی نوآبادیاتی جگہوں پر سان جوآن.   \n",
       "3                                                                                              یہ آج ہم زندہ راستہ ہے، گیری کہہ رہا ہے، کیوں اس سے لطف اندوز نہیں ہے؟   \n",
       "4                                                                  لیکن اب میکسیل نے ایک مکھی مخلوق میں داخل ہوکر اس کو مدعو کیا، بعد میں میکسیل کے راکشس کو ڈوب دیا.   \n",
       "5                                                                            غیر ملکیوں نے ملک چھوڑنے کے بعد نمائندوں کو ختم کرنے کے بارے میں کئی گواہوں کی گواہی دی.   \n",
       "6                                                                                                                                         ہمیں یہی مشورہ دیا گیا تھا.   \n",
       "7                                                                                                                                     تو سلیٹ کے پاس کتنے قارئین ہیں؟   \n",
       "8                                                                               اگر اور اس منصوبے کو مکمل کیا جائے تو، یہ پوری سلسلہ کا سب سے زیادہ دلچسپ ہونا چاہئے.   \n",
       "9                                                                                                                                ..آپ کا حصہ بننے پر آپ پر فخر ہو گی؟   \n",
       "\n",
       "                                                                                 sentence2  \n",
       "0                                                             - تہوار ایک ہفتےکے اندر ہوگا  \n",
       "1                                               -انہیں نئے راکٹ کے حصوں میں شامل کرنا ہوگا  \n",
       "2                                                        -کیریبین میں کبھی قزاقوں نہیں تھے  \n",
       "3                                                                -گہری کو خوشی کی فکر نہیں  \n",
       "4    ,د مهارت نشتوالی له کبله میکس ویل هیڅکله په خپل ټول ژوند کي  .هیڅح شی نه دی ایجاد کړي  \n",
       "5                                                        ,ډیری شاهدانو نماینده ګانې رد کړه  \n",
       "6  ,کله چې ویل کیده چې څه وکړي اداره ناکامه شوه چي موږ دننه د  .سوداګري رازونو ته راپریږدي  \n",
       "7                                                       ،سټیټ یو بلیون لوستونکي لريسمه ده؟  \n",
       "8                                                                         !یہ بہت بورنگ ہے  \n",
       "9                                                              ?ایک آپ بھی تعاون رکن ہو گے  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3 — First look at TEST data\n",
    "test_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc7f8dbd-053b-4bd4-8f7e-7ff417dd3103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.4 — Label sanity check (TEST)\n",
    "test_df[\"gold_label\"].value_counts()\n",
    "test_df[\"gold_label\"].unique()\n",
    "test_df[\"gold_label\"].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c627502-1400-47d3-ace3-dc0c49b131a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>gold_label</td>\n",
       "      <td>sentence1</td>\n",
       "      <td>sentence2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gold_label  sentence1  sentence2\n",
       "185  gold_label  sentence1  sentence2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.5 — FIND THE BAD ROW\n",
    "test_df[test_df[\"gold_label\"] == \"gold_label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd242d54-3f21-4ba0-84e8-ee6298ac1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6 — REMOVE THE BAD ROW\n",
    "test_df = test_df[test_df[\"gold_label\"] != \"gold_label\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "157a9701-0528-490a-9ffe-e4a2b383ea4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5009, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8460954-1cf0-4e90-bcce-bdb3eafceec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold_label\n",
       "neutral          1670\n",
       "contradiction    1670\n",
       "entailment       1669\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"gold_label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3845057b-bfff-4e8f-9b1d-2af11da0074a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['entailment', 'neutral', 'contradiction'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"gold_label\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19865268-6e25-4534-923f-18f874d56e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Define mapping\n",
    "label2id = {\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1,\n",
    "    \"contradiction\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f23d64d3-eb8a-480e-8f2d-d6ff254f52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Apply mapping (DEV + TEST)\n",
    "dev_df[\"label\"] = dev_df[\"gold_label\"].map(label2id)\n",
    "test_df[\"label\"] = test_df[\"gold_label\"].map(label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cc6dbf5-31a6-4cae-b701-0e170ff0a379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entailment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label  label\n",
       "1     entailment      0\n",
       "0        neutral      1\n",
       "2  contradiction      2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.3 Verify mapping\n",
    "dev_df[[\"gold_label\", \"label\"]].drop_duplicates().sort_values(\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a97f323-a42a-4c5a-a67f-1fb2bdbe98ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entailment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contradiction</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_label  label\n",
       "0     entailment      0\n",
       "1        neutral      1\n",
       "2  contradiction      2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[[\"gold_label\", \"label\"]].drop_duplicates().sort_values(\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fa40c25-1494-4b72-88a7-043b34a22855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force string type\n",
    "for col in [\"sentence1\", \"sentence2\"]:\n",
    "    dev_df[col] = dev_df[col].astype(str)\n",
    "    test_df[col] = test_df[col].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74c7d51b-3767-484e-bfcc-4b4fc82fa2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Create DEV & TEST HF datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "dev_dataset = Dataset.from_pandas(\n",
    "    dev_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "test_dataset = Dataset.from_pandas(\n",
    "    test_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c40bdf18-a77a-4cfb-afb5-07728ca0c3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label'],\n",
       "    num_rows: 2490\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2 Inspect dataset objects\n",
    "dev_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cd5ca1b-8509-494d-8dbc-458e4ee28de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': '، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.',\n",
       " 'sentence2': 'ان کے فوائد کا اندازہ لگایا گیا تھا لیکن اس کا امکان غلط تھا',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50ec1273-1583-45c1-a120-d3f5048908d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Load mBERT tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e09df988-7ca2-401f-99dd-674d3804e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Define tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence1\"],\n",
    "        examples[\"sentence2\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50cc314f-3a81-430a-8597-b70eba9a3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Ensure text columns are strings\n",
    "for col in [\"sentence1\", \"sentence2\"]:\n",
    "    dev_df[col] = dev_df[col].astype(str)\n",
    "    test_df[col] = test_df[col].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be371971-420a-489e-ac0a-4564e95853d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████| 2490/2490 [00:00<00:00, 15432.04 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████| 5009/5009 [00:00<00:00, 16336.38 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Tokenize\n",
    "dev_tokenized = dev_dataset.map(tokenize_function, batched=True)\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54d31570-6e68-4632-9e8e-1062942f916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 — Set PyTorch format\n",
    "columns = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "\n",
    "dev_tokenized.set_format(type=\"torch\", columns=columns)\n",
    "test_tokenized.set_format(type=\"torch\", columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ec3eb65-b0db-4ece-887a-d367c8fe7d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(1),\n",
       " 'input_ids': tensor([   101,    752,    781,  20451,  41003,  15974,  30345,  56658,  10738,\n",
       "          11363,  49307,  10686,  39675,  11127,  11503,  10961,  56658,  10738,\n",
       "            114,    752,    784,  14556,  50933,  10691,  28745,  10691,  26830,\n",
       "          10916, 107289,  20688,  11242,  10208,    131,    175,    120,    181,\n",
       "          10884,  12190,  44556,  21337,  36455,    777,  41002,  10691,  21893,\n",
       "          10564,  10916,  12427,  40231,  11076,    769,  66461,  14666,    773,\n",
       "          33277,  17821,  10861,    119,    102,  14269,  10691,    784,  14556,\n",
       "          50933,  11503, 107289,  20688,  11242,    787,  47238,  17317,  17571,\n",
       "          19249,  45202,  11722,  11503,  80949,    782,  10961,  14286,  19249,\n",
       "            102,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_tokenized[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed7927a-f1c9-4de8-ad79-03f37be4a099",
   "metadata": {},
   "source": [
    "# ZERO-SHOT XNLI with mBERT (Frozen Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1e067f1-e434-4b27-bb32-9fe76d12ac30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Load mBERT model (fresh)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8430c799-6b7e-4327-bc57-2af8152807a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Freeze the encoder\n",
    "for param in model.bert.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99b7a8c1-c165-4b14-8007-8482c63fc3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 201)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable = sum(p.requires_grad for p in model.parameters())\n",
    "total = sum(1 for _ in model.parameters())\n",
    "trainable, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b968376-6ab3-4313-87a1-8f126dd48f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c91faba-a6fa-4db7-b964-9932b0b355db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4 TrainingArguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_xnli_zero = TrainingArguments(\n",
    "    output_dir=\"./xnli_zero_shot_mbert\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfeb0c6e-22a7-4b5e-adcd-39b9b04249d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_55116\\902718006.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_zero = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# 6.5 Trainer\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_zero = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_xnli_zero,\n",
    "    train_dataset=dev_tokenized,   # classifier trained here\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3024c21d-64e8-4d1b-948b-2457affa4922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1560' max='1560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1560/1560 01:46, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.099754</td>\n",
       "      <td>0.331204</td>\n",
       "      <td>0.181394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.099358</td>\n",
       "      <td>0.330206</td>\n",
       "      <td>0.218338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.100800</td>\n",
       "      <td>1.099109</td>\n",
       "      <td>0.332402</td>\n",
       "      <td>0.245494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.100800</td>\n",
       "      <td>1.098880</td>\n",
       "      <td>0.332202</td>\n",
       "      <td>0.290576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.100800</td>\n",
       "      <td>1.098722</td>\n",
       "      <td>0.335596</td>\n",
       "      <td>0.312800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.101400</td>\n",
       "      <td>1.098629</td>\n",
       "      <td>0.336594</td>\n",
       "      <td>0.330728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.101400</td>\n",
       "      <td>1.098489</td>\n",
       "      <td>0.334797</td>\n",
       "      <td>0.323221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.100100</td>\n",
       "      <td>1.098398</td>\n",
       "      <td>0.338591</td>\n",
       "      <td>0.322783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.100100</td>\n",
       "      <td>1.098274</td>\n",
       "      <td>0.337992</td>\n",
       "      <td>0.320222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.100100</td>\n",
       "      <td>1.098187</td>\n",
       "      <td>0.341785</td>\n",
       "      <td>0.329878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.100600</td>\n",
       "      <td>1.098077</td>\n",
       "      <td>0.343582</td>\n",
       "      <td>0.326795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.100600</td>\n",
       "      <td>1.098014</td>\n",
       "      <td>0.348573</td>\n",
       "      <td>0.342766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.099200</td>\n",
       "      <td>1.097945</td>\n",
       "      <td>0.345977</td>\n",
       "      <td>0.336629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.099200</td>\n",
       "      <td>1.097885</td>\n",
       "      <td>0.349171</td>\n",
       "      <td>0.331591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.099200</td>\n",
       "      <td>1.097838</td>\n",
       "      <td>0.348573</td>\n",
       "      <td>0.332127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.099800</td>\n",
       "      <td>1.097808</td>\n",
       "      <td>0.351368</td>\n",
       "      <td>0.331218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.099800</td>\n",
       "      <td>1.097780</td>\n",
       "      <td>0.350170</td>\n",
       "      <td>0.334019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.099500</td>\n",
       "      <td>1.097759</td>\n",
       "      <td>0.348173</td>\n",
       "      <td>0.332587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.099500</td>\n",
       "      <td>1.097739</td>\n",
       "      <td>0.350968</td>\n",
       "      <td>0.333057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.099500</td>\n",
       "      <td>1.097738</td>\n",
       "      <td>0.351368</td>\n",
       "      <td>0.333261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1560, training_loss=1.1000887748522636, metrics={'train_runtime': 106.632, 'train_samples_per_second': 467.027, 'train_steps_per_second': 14.63, 'total_flos': 3275762050713600.0, 'train_loss': 1.1000887748522636, 'epoch': 20.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_zero.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b5fb4e2-96f3-4f74-904c-322fe80f024a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.09780752658844,\n",
       " 'eval_accuracy': 0.3513675384308245,\n",
       " 'eval_f1': 0.3312180628080431,\n",
       " 'eval_runtime': 2.3049,\n",
       " 'eval_samples_per_second': 2173.199,\n",
       " 'eval_steps_per_second': 68.116,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_results_mbert = trainer_zero.evaluate()\n",
    "zero_shot_results_mbert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b1f793-42d9-4dbf-bb3f-8b2f88b6a786",
   "metadata": {},
   "source": [
    "# 16-SHOT XNLI with mBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ba27873-4bff-466d-ac76-62a171c92506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Create 16-shot dataset (from DEV)\n",
    "fewshot_df = (\n",
    "    dev_df\n",
    "    .groupby(\"gold_label\", sort=False)\n",
    "    .head(16)\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb733bd6-d19d-4613-b18e-309ba1c51ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold_label\n",
       "neutral          16\n",
       "entailment       16\n",
       "contradiction    16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.2 Verify size & balance\n",
    "fewshot_df.shape\n",
    "fewshot_df[\"gold_label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d46558b5-0dfe-4129-904a-39563fea0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 Convert to HuggingFace Dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "fewshot_dataset = Dataset.from_pandas(\n",
    "    fewshot_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c06fa4d-7a83-4ce8-b8a2-239f3a7ffdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': '، علاقائی حجم RIA اور NOx SIP کال RIA)، فوائد کے کم کے آخر میں اندازہ 15: g / m3 پر وزیراعظم صحت کے اثرات میں ایک حد کی حیثیت رکھتا ہے.',\n",
       " 'sentence2': 'ان کے فوائد کا اندازہ لگایا گیا تھا لیکن اس کا امکان غلط تھا',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fewshot_dataset\n",
    "fewshot_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e59357f4-a6e8-44bc-85e2-2061b1903926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████| 48/48 [00:00<00:00, 6859.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 7.4 Tokenize 16-shot dataset\n",
    "fewshot_tokenized = fewshot_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "columns = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "fewshot_tokenized.set_format(type=\"torch\", columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5633243f-bf24-409f-aa8a-b7de18c9daa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(1),\n",
       " 'input_ids': tensor([   101,    752,    781,  20451,  41003,  15974,  30345,  56658,  10738,\n",
       "          11363,  49307,  10686,  39675,  11127,  11503,  10961,  56658,  10738,\n",
       "            114,    752,    784,  14556,  50933,  10691,  28745,  10691,  26830,\n",
       "          10916, 107289,  20688,  11242,  10208,    131,    175,    120,    181,\n",
       "          10884,  12190,  44556,  21337,  36455,    777,  41002,  10691,  21893,\n",
       "          10564,  10916,  12427,  40231,  11076,    769,  66461,  14666,    773,\n",
       "          33277,  17821,  10861,    119,    102,  14269,  10691,    784,  14556,\n",
       "          50933,  11503, 107289,  20688,  11242,    787,  47238,  17317,  17571,\n",
       "          19249,  45202,  11722,  11503,  80949,    782,  10961,  14286,  19249,\n",
       "            102,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fewshot_tokenized[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "165689d0-43c9-4e71-bd10-00277a0f2908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 7.5 Load mBERT model (FULL fine-tuning)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b030d435-d6c5-4ffe-8597-fbe9ee37bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.6 TrainingArguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_xnli_16 = TrainingArguments(\n",
    "    output_dir=\"./xnli_16shot_mbert\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ae6d6d9-57f4-4fe1-bf98-0ad836c93099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_55116\\2075994648.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_16_mbert = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# 7.7 Trainer (16-shot, mBERT)\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_16_mbert = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_xnli_16,\n",
    "    train_dataset=fewshot_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6d7df79-9f82-4850-a0b6-034a2b86d705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 04:26, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.121457</td>\n",
       "      <td>0.332801</td>\n",
       "      <td>0.168274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.111658</td>\n",
       "      <td>0.330006</td>\n",
       "      <td>0.180411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.100728</td>\n",
       "      <td>0.338990</td>\n",
       "      <td>0.312017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.099608</td>\n",
       "      <td>0.339589</td>\n",
       "      <td>0.280300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.100435</td>\n",
       "      <td>0.334797</td>\n",
       "      <td>0.254159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.102891</td>\n",
       "      <td>0.342384</td>\n",
       "      <td>0.254027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.109594</td>\n",
       "      <td>0.351368</td>\n",
       "      <td>0.269642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.116907</td>\n",
       "      <td>0.355560</td>\n",
       "      <td>0.319423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.117892</td>\n",
       "      <td>0.365542</td>\n",
       "      <td>0.362390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.121912</td>\n",
       "      <td>0.374326</td>\n",
       "      <td>0.362088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.132431</td>\n",
       "      <td>0.379118</td>\n",
       "      <td>0.351220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.138976</td>\n",
       "      <td>0.374526</td>\n",
       "      <td>0.345990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.148703</td>\n",
       "      <td>0.376123</td>\n",
       "      <td>0.346064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.159052</td>\n",
       "      <td>0.373727</td>\n",
       "      <td>0.344183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.167016</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>0.340904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.172223</td>\n",
       "      <td>0.373328</td>\n",
       "      <td>0.347207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.175569</td>\n",
       "      <td>0.374326</td>\n",
       "      <td>0.351570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.178150</td>\n",
       "      <td>0.375524</td>\n",
       "      <td>0.352317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.179646</td>\n",
       "      <td>0.376722</td>\n",
       "      <td>0.353798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.180540</td>\n",
       "      <td>0.379317</td>\n",
       "      <td>0.357066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=40, training_loss=0.8122941970825195, metrics={'train_runtime': 266.2139, 'train_samples_per_second': 3.606, 'train_steps_per_second': 0.15, 'total_flos': 63147220254720.0, 'train_loss': 0.8122941970825195, 'epoch': 20.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_16_mbert.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39a67480-68b3-4223-abe3-cff0a9826a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1805402040481567,\n",
       " 'eval_accuracy': 0.37931722898782194,\n",
       " 'eval_f1': 0.3570661898237802,\n",
       " 'eval_runtime': 2.3095,\n",
       " 'eval_samples_per_second': 2168.84,\n",
       " 'eval_steps_per_second': 67.979,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_16shot_mbert = trainer_16_mbert.evaluate()\n",
    "results_16shot_mbert\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23366503-e853-479b-8677-04bb5b20a829",
   "metadata": {},
   "source": [
    "# 80/20 FULL FINE-TUNING (mBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ec1d691-2115-47ad-9bcc-fc4be30f98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Create 80/20 split (from DEV)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    dev_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=dev_df[\"label\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d886e064-ddfe-470b-b4d6-dcc136360f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1992, 4), (498, 4))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8.2 Verify split sizes & balance\n",
    "train_df.shape, val_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e266da3e-28b6-4a28-9fa6-bcccc8256d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold_label\n",
       "contradiction    166\n",
       "neutral          166\n",
       "entailment       166\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"gold_label\"].value_counts()\n",
    "val_df[\"gold_label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8ef90c56-2cbd-480d-a352-b2cf3bf9b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.3 — Convert to HuggingFace Datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(\n",
    "    train_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n",
    "\n",
    "val_dataset = Dataset.from_pandas(\n",
    "    val_df[[\"sentence1\", \"sentence2\", \"label\"]],\n",
    "    preserve_index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50e89615-401f-4771-a783-8d381c4b6f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['sentence1', 'sentence2', 'label'],\n",
       "     num_rows: 1992\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['sentence1', 'sentence2', 'label'],\n",
       "     num_rows: 498\n",
       " }))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "51250463-8e51-4e2c-bf4b-f05fb35dae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████| 1992/1992 [00:00<00:00, 15748.15 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████| 498/498 [00:00<00:00, 13821.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 8.4 — Tokenize (mBERT, same function)\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
    "val_tokenized = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "columns = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "train_tokenized.set_format(type=\"torch\", columns=columns)\n",
    "val_tokenized.set_format(type=\"torch\", columns=columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bc411d5-3892-4f7d-a4ab-7f94f729c7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(0),\n",
       " 'input_ids': tensor([   101,  56561,  10429,  47291,  11722,    829,  94586,  13378,  10691,\n",
       "          38672,  23473,  59338,  11363,    817,  85544,  35075,  10691,  31552,\n",
       "          11689,  12084,  49045,  10691,  38672,  36817,  10691,  11866,    752,\n",
       "          21035,  11503,  81560,  34382,  10691, 107459,  92740,  42114,  14634,\n",
       "          92690,  17317,    752,  76295,  17047,    819,  11326,  11689,    819,\n",
       "          25908,  11711,  46541,    102,    817,  85544,  35075,  11076,  12084,\n",
       "          49045,  42114,  14634,  14014,    102,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca99f790-fe22-4d63-8133-625ce9f34ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 8.5 — Load mBERT (FULL fine-tuning)\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\",\n",
    "    num_labels=3,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51471231-60c8-4237-8cdf-7cacc19e831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.6 — TrainingArguments\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args_xnli_8020_mbert = TrainingArguments(\n",
    "    output_dir=\"./xnli_80_20_mbert\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    report_to=\"none\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87f41468-2b99-4888-8a77-6148a10ff5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\areesa\\AppData\\Local\\Temp\\ipykernel_55116\\1664457139.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_8020_mbert = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# 8.7 — Trainer (80/20, mBERT)\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer_8020_mbert = Trainer(\n",
    "    model=model,\n",
    "    args=training_args_xnli_8020_mbert,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "05ed5fa4-11d2-482e-881e-155b4419c500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1260' max='1260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1260/1260 05:41, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.094534</td>\n",
       "      <td>0.339357</td>\n",
       "      <td>0.208589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.024512</td>\n",
       "      <td>0.435743</td>\n",
       "      <td>0.355162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.983180</td>\n",
       "      <td>0.532129</td>\n",
       "      <td>0.523211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.038600</td>\n",
       "      <td>1.015462</td>\n",
       "      <td>0.534137</td>\n",
       "      <td>0.530310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.038600</td>\n",
       "      <td>1.063379</td>\n",
       "      <td>0.522088</td>\n",
       "      <td>0.519826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.038600</td>\n",
       "      <td>1.240098</td>\n",
       "      <td>0.538153</td>\n",
       "      <td>0.533389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.663400</td>\n",
       "      <td>1.371592</td>\n",
       "      <td>0.548193</td>\n",
       "      <td>0.549175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.663400</td>\n",
       "      <td>1.650718</td>\n",
       "      <td>0.514056</td>\n",
       "      <td>0.508088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.663400</td>\n",
       "      <td>1.699204</td>\n",
       "      <td>0.508032</td>\n",
       "      <td>0.503745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.248900</td>\n",
       "      <td>1.913720</td>\n",
       "      <td>0.510040</td>\n",
       "      <td>0.505462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.248900</td>\n",
       "      <td>2.137853</td>\n",
       "      <td>0.518072</td>\n",
       "      <td>0.515658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.248900</td>\n",
       "      <td>2.252950</td>\n",
       "      <td>0.495984</td>\n",
       "      <td>0.492954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>2.505906</td>\n",
       "      <td>0.512048</td>\n",
       "      <td>0.510397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>2.604996</td>\n",
       "      <td>0.512048</td>\n",
       "      <td>0.509249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>2.709116</td>\n",
       "      <td>0.516064</td>\n",
       "      <td>0.514786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>2.799609</td>\n",
       "      <td>0.520080</td>\n",
       "      <td>0.517739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>2.950596</td>\n",
       "      <td>0.510040</td>\n",
       "      <td>0.506348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>2.991896</td>\n",
       "      <td>0.520080</td>\n",
       "      <td>0.516004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>3.015587</td>\n",
       "      <td>0.520080</td>\n",
       "      <td>0.517153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>3.018204</td>\n",
       "      <td>0.528112</td>\n",
       "      <td>0.524739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1260, training_loss=0.33622066066378636, metrics={'train_runtime': 341.1375, 'train_samples_per_second': 116.786, 'train_steps_per_second': 3.694, 'total_flos': 2620609640570880.0, 'train_loss': 0.33622066066378636, 'epoch': 20.0})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8.8 — Run FULL FINE-TUNING\n",
    "trainer_8020_mbert.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99bb46bc-6f38-41fc-ac58-c7695e0643a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.3715921640396118,\n",
       " 'eval_accuracy': 0.5481927710843374,\n",
       " 'eval_f1': 0.5491748908878847,\n",
       " 'eval_runtime': 0.2752,\n",
       " 'eval_samples_per_second': 1809.917,\n",
       " 'eval_steps_per_second': 58.15,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_8020_mbert = trainer_8020_mbert.evaluate()\n",
    "results_8020_mbert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0513fb-c052-40a1-af18-dee37149a757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (urdu_glue_gpu)",
   "language": "python",
   "name": "urdu_glue_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
