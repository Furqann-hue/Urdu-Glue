{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6a4ff0-8ec0-4a89-a5a4-3fe3fba42b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openprompt.data_utils import InputExample\n",
    "\n",
    "# ==============================\n",
    "# Load WNLI dataset\n",
    "# ==============================\n",
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\stdFurqan\\Desktop\\paft\\WNLI\\WNLI_train_urdu_entailment.csv\"\n",
    ")\n",
    "\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# ==============================\n",
    "# WNLI Label Mapping (BINARY)\n",
    "# ==============================\n",
    "label_map = {\n",
    "    \"entailment\": 1,\n",
    "    \"not_entailment\": 0\n",
    "}\n",
    "\n",
    "classes = list(label_map.keys())\n",
    "\n",
    "guid = 0\n",
    "examples = []\n",
    "class_stats = {}\n",
    "\n",
    "# ==============================\n",
    "# Take FIRST 16 examples per class\n",
    "# ==============================\n",
    "for label_name in classes:\n",
    "    class_df = df[df[\"label_text\"] == label_name].head(16)\n",
    "    class_stats[label_name] = len(class_df)\n",
    "\n",
    "    for _, row in class_df.iterrows():\n",
    "        examples.append(\n",
    "            InputExample(\n",
    "                guid=guid,\n",
    "                text_a=str(row[\"sentence1_urdu\"]).strip(),\n",
    "                text_b=str(row[\"sentence2_urdu\"]).strip(),\n",
    "                label=label_map[label_name]\n",
    "            )\n",
    "        )\n",
    "        guid += 1\n",
    "\n",
    "# ==============================\n",
    "# Print InputExamples (exact format)\n",
    "# ==============================\n",
    "print(\"\\n### InputExamples ###\\n\")\n",
    "for ex in examples:\n",
    "    print(\n",
    "        \"InputExample(\\n\"\n",
    "        f\"    guid={ex.guid},\\n\"\n",
    "        f\"    text_a=\\\"{ex.text_a}\\\",\\n\"\n",
    "        f\"    text_b=\\\"{ex.text_b}\\\",\\n\"\n",
    "        f\"    label={ex.label}\\n\"\n",
    "        \"),\"\n",
    "    )\n",
    "\n",
    "# ==============================\n",
    "# Metadata\n",
    "# ==============================\n",
    "print(\"\\n### Classes ###\")\n",
    "print(f\"classes = {classes}\")\n",
    "\n",
    "print(\"\\n### Label Map ###\")\n",
    "print(f\"label_map = {label_map}\")\n",
    "\n",
    "print(\"\\n### Samples per Class ###\")\n",
    "for cls, count in class_stats.items():\n",
    "    print(f\"{cls}: {count}\")\n",
    "\n",
    "print(f\"\\nTotal InputExamples generated: {guid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84084e5f-dbfe-475b-9c74-50765453cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [\n",
    "    (\"P1\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} Ø§ÙˆØ± {\"placeholder\":\"text_b\"} Ú©Ø§ ØªØ¹Ù„Ù‚ {\"mask\"} ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P2\", ManualTemplate(\n",
    "        text='Ù¾ÛÙ„Ø§ Ø¨ÛŒØ§Ù†: {\"placeholder\":\"text_a\"} Ø¯ÙˆØ³Ø±Ø§ Ø¨ÛŒØ§Ù†: {\"placeholder\":\"text_b\"} Ø§Ù† Ú©Ø§ ØªØ¹Ù„Ù‚ {\"mask\"} ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P3\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_b\"} Ú©ÛŒØ§ {\"placeholder\":\"text_a\"} Ø³Û’ {\"mask\"} ÛÙˆØªØ§ ÛÛ’ØŸ',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P4\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} Ú©ÛŒ Ø±ÙˆØ´Ù†ÛŒ Ù…ÛŒÚº {\"placeholder\":\"text_b\"} {\"mask\"} ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P5\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_b\"} Ú©Ø§ Ø¨ÛŒØ§Ù† {\"placeholder\":\"text_a\"} Ú©Û’ Ù…Ø·Ø§Ø¨Ù‚ {\"mask\"} ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P6\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} Ø§ÙˆØ± {\"placeholder\":\"text_b\"} Ú©Û’ Ø¯Ø±Ù…ÛŒØ§Ù† Ù…Ù†Ø·Ù‚ÛŒ Ø±Ø´ØªÛ {\"mask\"} ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P7\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_b\"}ØŒ {\"placeholder\":\"text_a\"} Ø³Û’ {\"mask\"} Ø·ÙˆØ± Ù¾Ø± Ø¬Ú‘Ø§ ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P8\", ManualTemplate(\n",
    "        text='Ø§Ú¯Ø± ÛÙ… {\"placeholder\":\"text_a\"} Ú©Ùˆ Ø¯ÛŒÚ©Ú¾ÛŒÚº ØªÙˆ {\"placeholder\":\"text_b\"} {\"mask\"} Ø¨Ù†ØªØ§ ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P9\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} Ú©Û’ Ø­ÙˆØ§Ù„Û’ Ø³Û’ {\"placeholder\":\"text_b\"} {\"mask\"} Ø³Ù…Ø¬Ú¾Ø§ Ø¬Ø§ØªØ§ ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P10\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} Ø§ÙˆØ± {\"placeholder\":\"text_b\"} Ù…ÛŒÚº ØªØ¹Ù„Ù‚ Ú©ÛŒ Ù†ÙˆØ¹ÛŒØª {\"mask\"} ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a410aca4-e699-4e6c-aa3e-c5456b9b7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbalizer = ManualVerbalizer(\n",
    "    classes=[\"not_entailment\", \"entailment\"],\n",
    "    label_words={\n",
    "        \"entailment\": [\"Ø¯Ø±Ø³Øª\", \"Ø«Ø§Ø¨Øª\"],\n",
    "        \"not_entailment\": [\"ØºÙ„Ø·\", \"Ù†Ø§Ù…Ø·Ø§Ø¨Ù‚\"]\n",
    "    },\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c987dad5-49da-47ee-8c6c-3a0284c4568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2e005b-05df-451d-b350-8efc0cad3fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 4080 SUPER\n",
      "CUDA version: 12.1\n",
      "GPU count: 1\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Imports\n",
    "# ==============================\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForMaskedLM\n",
    "from openprompt.prompts import ManualTemplate, ManualVerbalizer\n",
    "from openprompt.data_utils import InputExample\n",
    "from openprompt.plms import load_plm\n",
    "from openprompt import PromptForClassification, PromptDataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader, Sampler\n",
    "\n",
    "# ========================================\n",
    "# Check CUDA\n",
    "# ========================================\n",
    "device = \"cuda\" #if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU count:\", torch.cuda.device_count())\n",
    "\n",
    "# ========================================\n",
    "# Seeds for reproducibility\n",
    "# ========================================\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b886744-7d15-461f-a4cc-fec6258f9bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Balanced Batch Sampler\n",
    "# ==============================\n",
    "class BalancedBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        \"\"\"\n",
    "        dataset: list of InputExample\n",
    "        batch_size: total batch size (must be divisible by number of classes)\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.labels = [ex.label for ex in dataset]\n",
    "        self.classes = list(sorted(set(self.labels)))\n",
    "        self.num_classes = len(self.classes)\n",
    "        assert batch_size % self.num_classes == 0, \"Batch size must be divisible by number of classes\"\n",
    "        self.batch_size_per_class = batch_size // self.num_classes\n",
    "\n",
    "    def __iter__(self):\n",
    "        class_indices = {c: np.where(np.array(self.labels) == c)[0].tolist() for c in self.classes}\n",
    "        for c in self.classes:\n",
    "            np.random.shuffle(class_indices[c])\n",
    "\n",
    "        num_batches = min(len(class_indices[c]) // self.batch_size_per_class for c in self.classes)\n",
    "\n",
    "        for i in range(num_batches):\n",
    "            batch = []\n",
    "            for c in self.classes:\n",
    "                start = i * self.batch_size_per_class\n",
    "                end = start + self.batch_size_per_class\n",
    "                batch.extend(class_indices[c][start:end])\n",
    "            np.random.shuffle(batch)\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(np.where(np.array(self.labels) == c)[0]) // self.batch_size_per_class for c in self.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae777643-4a5d-4568-bfe1-6385059582ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Training data (16-shot) ha,m and spam\n",
    "train_dataset = [\n",
    "\n",
    "        InputExample(\n",
    "            guid=0,\n",
    "            text_a=\"ÛÙ†Ø±ÛŒ Ú©Ø¦ÛŒ Ø¨Ø§Ø± Ø§Ù† Ø§Ù†Ù¹Ø±ÙˆÛŒÙˆØ² Ù…ÛŒÚº Ù…ÙˆØ¬ÙˆØ¯ Ø±ÛØ§ ØªÚ¾Ø§ Ø¬Ùˆ Ø§Ø³ Ú©Û’ ÙˆØ§Ù„Ø¯ Ù†Û’ Ù…Ø¹Ø±ÙˆÙ Ø¬Ø§Ø³ÙˆØ³ÙˆÚº Ú©Û’ Ø³Ø§ØªÚ¾ Ú©ÛŒÛ’ ØªÚ¾Û’ Ø¬Ùˆ Ù¾ÛŒÚ†ÛŒØ¯Û Ø§Ø³Ø±Ø§Ø± Ú©Ùˆ Ø­Ù„ Ú©Ø±Ù†Û’ Ù…ÛŒÚº Ø§Ø³ Ú©ÛŒ Ù…Ø¯Ø¯ Ú†Ø§ÛØªÛ’ ØªÚ¾Û’ Ø§ÙˆØ± ÙˆÛ Ù…ÙˆØ§Ù‚Ø¹ Ø§Ø³ Ú©Û’ Ù„ÛŒÛ’ Ø³Ø±Ø® Ø­Ø±ÙˆÙ Ú©Û’ Ø¯Ù†ÙˆÚº Ú©Û’ Ø·ÙˆØ± Ù¾Ø± Ú©Ú¾Ú‘Û’ ØªÚ¾Û’ Û”\",\n",
    "            text_b=\"ÙˆÛ Ù…ÙˆØ§Ù‚Ø¹ ÛÙ†Ø±ÛŒ Ú©Û’ Ù„ÛŒÛ’ Ø³Ø±Ø® Ø­Ø±ÙˆÙ ÙˆØ§Ù„Û’ Ø¯Ù†ÙˆÚº Ú©Û’ Ø·ÙˆØ± Ù¾Ø± Ù†Ù…Ø§ÛŒØ§Úº ØªÚ¾Û’ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=1,\n",
    "            text_a=\"Ø¢Ø¯Ù… Ø§Ø³ ÙˆÙ‚Øª ØªÚ© ÛŒÛØ§Úº Ø³Û’ Ú©Ø§Ù… Ù†ÛÛŒÚº Ú†Ú¾ÙˆÚ‘ Ø³Ú©ØªØ§ Ø¬Ø¨ ØªÚ© Ú©Û Ø¨Ø§Ø¨ Ø§Ø³ Ú©ÛŒ Ø¬Ú¯Û Ù„ÛŒÙ†Û’ Ù†ÛÛŒÚº Ø¢ØªØ§ Û” Ø§Ú¯Ø± Ø¨Ø§Ø¨ ÙˆÙ‚Øª Ù¾Ø± Ú©Ø§Ù… Ú©Û’ Ù„ÛŒÛ’ Ú¯Ú¾Ø± Ø³Û’ Ù†Ú©Ù„ Ø¬Ø§ØªØ§ ØªÙˆ ÙˆÛ Ø§Ø³ ÙˆÙ‚Øª ØªÚ© Ú†Ù„Ø§ Ø¬Ø§ØªØ§ Û”\",\n",
    "            text_b=\"Ø¢Ø¯Ù… Ø§Ø³ ÙˆÙ‚Øª ØªÚ© Ú†Ù„Ø§ Ø¬Ø§Ø¦Û’ Ú¯Ø§ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=2,\n",
    "            text_a=\"Ø¢Ø¯Ù… Ø§Ø³ ÙˆÙ‚Øª ØªÚ© ÛŒÛØ§Úº Ø³Û’ Ú©Ø§Ù… Ù†ÛÛŒÚº Ú†Ú¾ÙˆÚ‘ Ø³Ú©ØªØ§ Ø¬Ø¨ ØªÚ© Ú©Û Ø¨Ø§Ø¨ Ø§Ø³ Ú©ÛŒ Ø¬Ú¯Û Ù„ÛŒÙ†Û’ Ù†ÛÛŒÚº Ø¢ØªØ§ Û” Ø§Ú¯Ø± Ø¨Ø§Ø¨ ÙˆÙ‚Øª Ù¾Ø± Ú©Ø§Ù… Ú©Û’ Ù„ÛŒÛ’ Ú¯Ú¾Ø± Ø³Û’ Ù†Ú©Ù„ Ø¬Ø§ØªØ§ ØªÙˆ ÙˆÛ Ø§Ø³ ÙˆÙ‚Øª ØªÚ© ÛŒÛØ§Úº Ù¾ÛÙ†Ú† Ø¬Ø§ØªØ§ Û”\",\n",
    "            text_b=\"Ø¨Ø§Ø¨ Ø§Ø³ ÙˆÙ‚Øª ØªÚ© ÛŒÛØ§Úº Ù¾ÛÙ†Ú† Ú†Ú©Ø§ ÛÙˆÚ¯Ø§ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=3,\n",
    "            text_a=\"Ø¢Ø¯Ù… Ø§Ø³ ÙˆÙ‚Øª ØªÚ© ÛŒÛØ§Úº Ø³Û’ Ú©Ø§Ù… Ù†ÛÛŒÚº Ú†Ú¾ÙˆÚ‘ Ø³Ú©ØªØ§ Ø¬Ø¨ ØªÚ© Ú©Û Ø¨Ø§Ø¨ Ø§Ø³ Ú©ÛŒ Ø¬Ú¯Û Ù„ÛŒÙ†Û’ Ù†ÛÛŒÚº Ø¢ØªØ§ Û” Ø§Ú¯Ø± Ø¨Ø§Ø¨ ÙˆÙ‚Øª Ù¾Ø± Ú©Ø§Ù… Ú©Û’ Ù„ÛŒÛ’ Ú¯Ú¾Ø± Ø³Û’ Ù†Ú©Ù„ Ø¬Ø§ØªØ§ ØªÙˆ ÙˆÛ Ø§Ø³ ÙˆÙ‚Øª ØªÚ© ÛŒÛØ§Úº Ù¾ÛÙ†Ú† Ø¬Ø§ØªØ§ Û”\",\n",
    "            text_b=\"Ø¨Ø§Ø¨ Ø§Ø³ ÙˆÙ‚Øª ØªÚ© ÛŒÛØ§Úº Ù¾ÛÙ†Ú† Ú†Ú©Ø§ ÛÙˆÚ¯Ø§ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=4,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ Ù†Û’ ÛØ¬ÙˆÙ… Ù…ÛŒÚº Ø§Ù¾Ù†ÛŒ Ø¯ÙˆØ³Øª Ø¬ÛŒÚˆ Ú©Ùˆ ØªÙ„Ø§Ø´ Ú©ÛŒØ§ Û” Ú†ÙˆÙ†Ú©Û ÙˆÛ ÛÙ…ÛŒØ´Û Ø®ÙˆØ´ Ù‚Ø³Ù…Øª Ø±ÛØªÛŒ ÛÛ’ Û” Ø§ÛŒÙ„Ø³ Ù†Û’ Ø§Ø³Û’ Ø¬Ù„Ø¯ÛŒ Ø³Û’ Ø¯ÛŒÚ©Ú¾ Ù„ÛŒØ§ Û”\",\n",
    "            text_b=\"Ú†ÙˆÙ†Ú©Û Ø§ÛŒÙ„Ø³ ÛÙ…ÛŒØ´Û Ø®ÙˆØ´ Ù‚Ø³Ù…Øª Ø±ÛØªÛŒ ÛÛ’ ØŒ Ø§Ø³ Ù„ÛŒÛ’ Ø§ÛŒÙ„Ø³ Ù†Û’ Ø§Ø³Û’ Ø¬Ù„Ø¯ÛŒ Ø³Û’ Ø¯ÛŒÚ©Ú¾ Ù„ÛŒØ§ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=5,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ Ù†Û’ ÛØ¬ÙˆÙ… Ù…ÛŒÚº Ø§Ù¾Ù†ÛŒ Ø¯ÙˆØ³Øª Ø¬ÛŒÚˆ Ú©Ùˆ ØªÙ„Ø§Ø´ Ú©ÛŒØ§ Û” Ú†ÙˆÙ†Ú©Û ÙˆÛ ÛÙ…ÛŒØ´Û Ø³Ø±Ø® Ù¾Ú¯Ú‘ÛŒ Ù¾ÛÙ†ØªÛŒ ÛÛ’ Ø§Ø³ Ù„ÛŒÛ’ Ø§ÛŒÙ„Ø³ Ù†Û’ Ø§Ø³Û’ Ø¬Ù„Ø¯ÛŒ Ø³Û’ Ø¯ÛŒÚ©Ú¾ Ù„ÛŒØ§ Û”\",\n",
    "            text_b=\"Ú†ÙˆÙ†Ú©Û Ø¬ÛŒÚˆ ÛÙ…ÛŒØ´Û Ø³Ø±Ø® Ù¾Ú¯Ú‘ÛŒ Ù¾ÛÙ†ØªÛŒ ÛÛ’ ØŒ Ø§Ø³ Ù„ÛŒÛ’ Ø§ÛŒÙ„Ø³ Ù†Û’ Ø§Ø³Û’ Ø¬Ù„Ø¯ÛŒ Ø³Û’ Ø¯ÛŒÚ©Ú¾Ø§ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=6,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ Ù†Û’ ÛØ¬ÙˆÙ… Ù…ÛŒÚº Ø§Ù¾Ù†ÛŒ Ø¯ÙˆØ³Øª Ø¬ÛŒÚˆ Ú©Ùˆ ØªÙ„Ø§Ø´ Ú©ÛŒØ§ Û” Ú†ÙˆÙ†Ú©Û ÙˆÛ ÛÙ…ÛŒØ´Û Ø³Ø±Ø® Ù¾Ú¯Ú‘ÛŒ Ù¾ÛÙ†ØªÛŒ ÛÛ’ Ø§Ø³ Ù„ÛŒÛ’ Ø§ÛŒÙ„Ø³ Ù†Û’ Ø§Ø³Û’ Ø¬Ù„Ø¯ÛŒ Ø³Û’ Ø¯ÛŒÚ©Ú¾ Ù„ÛŒØ§ Û”\",\n",
    "            text_b=\"Ú†ÙˆÙ†Ú©Û Ø¬ÛŒÚˆ ÛÙ…ÛŒØ´Û Ø³Ø±Ø® Ù¾Ú¯Ú‘ÛŒ Ù¾ÛÙ†ØªÛŒ ÛÛ’ ØŒ Ø§Ø³ Ù„ÛŒÛ’ Ø§ÛŒÙ„Ø³ Ù†Û’ Ø§Ø³Û’ Ø¬Ù„Ø¯ÛŒ Ø³Û’ Ø¯ÛŒÚ©Ú¾Ø§ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=7,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ Ù†Û’ Ù¾Ø§Ø±Ù¹ÛŒ Ù…ÛŒÚº Ø§Ù¾Ù†ÛŒ Ø¨ÛŒÙ¹ÛŒ Ú©Ùˆ Ø¨Ú¾ÙˆÙ†Ú©Ù†Û’ Ø³Û’ Ø±ÙˆÚ©Ù†Û’ Ú©ÛŒ Ø¨Û’ Ú†ÛŒÙ†ÛŒ Ø³Û’ Ú©ÙˆØ´Ø´ Ú©ÛŒØŒ Ø¬Ø³ Ø³Û’ ÛÙ… ÛŒÛ Ø³ÙˆÚ†Ù†Û’ Ù¾Ø± Ù…Ø¬Ø¨ÙˆØ± ÛÙˆ Ú¯Ø¦Û’ Ú©Û ÙˆÛ Ø§ØªÙ†Ø§ Ø¹Ø¬ÛŒØ¨ Ø¨Ø±ØªØ§Ø¤ Ú©ÛŒÙˆÚº Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒÛ”\",\n",
    "            text_b=\"Ø§ÛŒÙ„Ø³ Ú©ÛŒ Ø¨ÛŒÙ¹ÛŒ Ø¨ÛØª Ø¹Ø¬ÛŒØ¨ Ø³Ù„ÙˆÚ© Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=8,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ Ù†Û’ Ú¯Ú¾Ø¨Ø±Ø§ÛÙ¹ Ù…ÛŒÚº Ø§Ù¾Ù†ÛŒ Ø¨ÛŒÙ¹ÛŒ Ú©Ùˆ Ù¾Ø§Ø±Ù¹ÛŒ Ù…ÛŒÚº Ø¨Ø§ØªÛŒÚº Ú©Ø±Ù†Û’ Ø³Û’ Ø±ÙˆÚ©Ù†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©ÛŒØŒ Ø¬Ø³ Ø³Û’ ÛÙ…ÛŒÚº ÛŒÛ Ø³ÙˆÚ†Ù†Û’ Ù¾Ø± Ù…Ø¬Ø¨ÙˆØ± ÛÙˆÙ†Ø§ Ù¾Ú‘Ø§ Ú©Û ÙˆÛ Ø§ØªÙ†Ø§ Ø¹Ø¬ÛŒØ¨ Ø±ÙˆÛŒÛ Ú©ÛŒÙˆÚº Ø§Ø®ØªÛŒØ§Ø± Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒÛ”\",\n",
    "            text_b=\"Ø§ÛŒÙ„Ø³ Ø¨ÛØª Ø¹Ø¬ÛŒØ¨ Ø³Ù„ÙˆÚ© Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=9,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ ÚˆØ±Ø§Ø¦Ù†Ú¯ Ø±ÙˆÙ… Ú©ÛŒ Ú¯Ø±Ø¯ Ø¬Ú¾Ø§Ú‘ Ø±ÛÛŒ ØªÚ¾ÛŒ Ø§ÙˆØ± ÙˆÛ Ø¨Ù¹Ù† ÚˆÚ¾ÙˆÙ†ÚˆÙ†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒ Ø¬Ùˆ Ù…Ø§Úº Ù†Û’ Ú†Ú¾Ù¾Ø§ Ø¯ÛŒØ§ ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³ Ú©Û’ Ù¾Ø§Ø³ Ø§Ù¾Ù†ÛŒ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û ÙÙˆÙ¹Ùˆ Ø§Ù„Ø¨Ù… Ù…ÛŒÚº Ù¾Ø±Ø§Ù†ÛŒ ØªØµÙˆÛŒØ±ÛŒÚº Ø¯ÛŒÚ©Ú¾Ù†Û’ Ú©Ø§ ÙˆÙ‚Øª Ù†ÛÛŒÚº ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³Û’ Ø§ÛŒÚ© Ø¨Ù¹Ù† ØªÙ„Ø§Ø´ Ú©Ø±Ù†Ø§ ØªÚ¾Ø§ØŒ Ø§Ø³ Ù„ÛŒÛ’ Ø§Ø³ Ù†Û’ Ø§Ù„Ø¨Ù… Ú©Ùˆ Ø¨ØºÛŒØ± Ú©Ú¾ÙˆÙ„Û’ ÛÛŒ Ø§ÛŒÚ© Ú©Ø±Ø³ÛŒ Ù¾Ø± Ø±Ú©Ú¾ Ø¯ÛŒØ§Û”\",\n",
    "            text_b=\"Ø§ÛŒÙ„Ø³ Ú©Û’ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û ÙÙˆÙ¹Ùˆ Ø§Ù„Ø¨Ù… Ù…ÛŒÚº Ù¾Ø±Ø§Ù†ÛŒ ØªØµØ§ÙˆÛŒØ± Ø¯ÛŒÚ©Ú¾Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¢Ø¬ ÙˆÙ‚Øª Ù†ÛÛŒÚº ÛÛ’ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=10,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ ÚˆØ±Ø§Ø¦Ù†Ú¯ Ø±ÙˆÙ… Ú©ÛŒ Ú¯Ø±Ø¯ Ø¬Ú¾Ø§Ú‘ Ø±ÛÛŒ ØªÚ¾ÛŒ Ø§ÙˆØ± ÙˆÛ Ø¨Ù¹Ù† ÚˆÚ¾ÙˆÙ†ÚˆÙ†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒ Ø¬Ùˆ Ù…Ø§Úº Ù†Û’ Ú†Ú¾Ù¾Ø§ Ø¯ÛŒØ§ ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³ Ú©Û’ Ù¾Ø§Ø³ Ø§Ù¾Ù†ÛŒ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û ÙÙˆÙ¹Ùˆ Ø§Ù„Ø¨Ù… Ù…ÛŒÚº Ù¾Ø±Ø§Ù†ÛŒ ØªØµÙˆÛŒØ±ÛŒÚº Ø¯ÛŒÚ©Ú¾Ù†Û’ Ú©Ø§ ÙˆÙ‚Øª Ù†ÛÛŒÚº ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³Û’ Ø§ÛŒÚ© Ø¨Ù¹Ù† ØªÙ„Ø§Ø´ Ú©Ø±Ù†Ø§ ØªÚ¾Ø§ØŒ Ø§Ø³ Ù„ÛŒÛ’ Ø§Ø³ Ù†Û’ Ø§Ù„Ø¨Ù… Ú©Ùˆ Ø¨ØºÛŒØ± Ú©Ú¾ÙˆÙ„Û’ ÛÛŒ Ø§ÛŒÚ© Ú©Ø±Ø³ÛŒ Ù¾Ø± Ø±Ú©Ú¾ Ø¯ÛŒØ§Û”\",\n",
    "            text_b=\"Ø§Ø³ Ù†Û’ Ø§Ù„Ø¨Ù… Ú©Ùˆ Ú©Ú¾ÙˆÙ„Û’ Ø¨ØºÛŒØ± ÛÛŒ Ø§Ø³Û’ Ú©Ø±Ø³ÛŒ Ù¾Ø± Ø±Ú©Ú¾ Ø¯ÛŒØ§ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=11,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ ÚˆØ±Ø§Ø¦Ù†Ú¯ Ø±ÙˆÙ… Ú©ÛŒ Ú¯Ø±Ø¯ Ø¬Ú¾Ø§Ú‘ Ø±ÛÛŒ ØªÚ¾ÛŒ Ø§ÙˆØ± ÙˆÛ Ø¨Ù¹Ù† ÚˆÚ¾ÙˆÙ†ÚˆÙ†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒ Ø¬Ùˆ Ù…Ø§Úº Ù†Û’ Ú†Ú¾Ù¾Ø§ Ø¯ÛŒØ§ ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³ Ú©Û’ Ù¾Ø§Ø³ Ø§Ù¾Ù†ÛŒ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û ÙÙˆÙ¹Ùˆ Ø§Ù„Ø¨Ù… Ù…ÛŒÚº Ù¾Ø±Ø§Ù†ÛŒ ØªØµÙˆÛŒØ±ÛŒÚº Ø¯ÛŒÚ©Ú¾Ù†Û’ Ú©Ø§ ÙˆÙ‚Øª Ù†ÛÛŒÚº ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³Û’ Ø§ÛŒÚ© Ø¨Ù¹Ù† ØªÙ„Ø§Ø´ Ú©Ø±Ù†Ø§ ØªÚ¾Ø§ØŒ Ø§Ø³ Ù„ÛŒÛ’ Ø§Ø³ Ù†Û’ Ø§Ù„Ø¨Ù… Ú©Ùˆ Ø¨ØºÛŒØ± Ú©Ú¾ÙˆÙ„Û’ ÛÛŒ Ø§ÛŒÚ© Ú©Ø±Ø³ÛŒ Ù¾Ø± Ø±Ú©Ú¾ Ø¯ÛŒØ§Û”\",\n",
    "            text_b=\"Ø§ÛŒÙ„Ø³ Ú©Ùˆ Ø§ÛŒÚ© Ø¨Ù¹Ù† ØªÙ„Ø§Ø´ Ú©Ø±Ù†Ø§ Ù¾Ú‘Ø§ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=12,\n",
    "            text_a=\"ÚˆÙˆØ±Ø§ Ú©Û’ Ú†ÛŒÚ© Ø¯Ø§Ø± Ù„Ø¨Ø§Ø³ Ú©ÛŒ Ù¾Ø´Øª Ù¾Ø± Ù„Ú¯Û’ ØªÙ…Ø§Ù… Ø¨Ù¹Ù† Ø§Ù„Ù¹Û’ Ø±Ø® Ø³Û’ Ø¨Ù†Ø¯ Ú©ÛŒÛ’ Ú¯Ø¦Û’ ØªÚ¾Û’Û” Ù…Ø§ÙˆÚˆ Ú©Ùˆ Ú†Ø§ÛÛŒÛ’ ØªÚ¾Ø§ Ú©Û ÙˆÛ Ø§Ø³Û’ Ø®ÙˆØ¯ Ø¨Ù¹Ù† Ù„Ú¯Ø§ Ø¯ÛŒØªÛŒØŒ Ù…Ú¯Ø± Ù†ÛÛŒÚºØ› Ø§Ø³ Ù†Û’ Ø¨ÛŒÚ†Ø§Ø±ÛŒ Ù†Ù†Ú¾ÛŒ ÚˆÙˆØ±Ø§ Ú©Ùˆ Ø§Ú©ÛŒÙ„Ø§ ÛÛŒ Ø§Ù¾Ù†ÛŒ Ø¨Ø³Ø§Ø· Ú©Û’ Ù…Ø·Ø§Ø¨Ù‚ Ø³Ø¨ Ú©Ú†Ú¾ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ú†Ú¾ÙˆÚ‘ Ø¯ÛŒØ§ ØªÚ¾Ø§Û”\",\n",
    "            text_b=\"Ø§Ø³ Ù†Û’ Ø¨ÛŒÚ†Ø§Ø±ÛŒ Ù†Ù†Ú¾ÛŒ ÚˆÙˆØ±Ø§ Ú©Ùˆ Ø§Ú©ÛŒÙ„Ø§ ÛÛŒ Ú†Ú¾ÙˆÚ‘ Ø¯ÛŒØ§ ØªÚ¾Ø§ Ú©Û ÙˆÛ Ø§Ù¾Ù†ÛŒ Ø¨Ø³Ø§Ø· Ú©Û’ Ù…Ø·Ø§Ø¨Ù‚ Ø®ÙˆØ¯ ÛÛŒ Ø³Ø¨ Ú©Ú†Ú¾ Ú©Ø± Ù„Û’Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=13,\n",
    "            text_a=\"Ø§Ú¯Ø±Ú†Û ÙˆÛ ØªÙ‚Ø±ÛŒØ¨Ø§ Ø§ÛŒÚ© ÛÛŒ Ø±ÙØªØ§Ø± Ø³Û’ Ø¯ÙˆÚ‘ØªÛ’ ØªÚ¾Û’ Û” Ø³Ùˆ Ù†Û’ Ø³ÛŒÙ„ÛŒ Ú©Ùˆ Ø´Ú©Ø³Øª Ø¯ÛŒ Ú©ÛŒÙˆÙ†Ú©Û Ø§Ø³ Ú©ÛŒ Ø´Ø±ÙˆØ¹Ø§Øª Ø§ØªÙ†ÛŒ Ø®Ø±Ø§Ø¨ ØªÚ¾ÛŒ Û”\",\n",
    "            text_b=\"Ø³ÛŒÙ„ÛŒ Ú©ÛŒ Ø´Ø±ÙˆØ¹Ø§Øª Ø§ØªÙ†ÛŒ Ø®Ø±Ø§Ø¨ ØªÚ¾ÛŒ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=14,\n",
    "            text_a=\"Ø§Ú¯Ø±Ú†Û ÙˆÛ ØªÙ‚Ø±ÛŒØ¨Ø§ Ø§ÛŒÚ© ÛÛŒ Ø±ÙØªØ§Ø± Ø³Û’ Ø¯ÙˆÚ‘ØªÛ’ ØªÚ¾Û’ Û” Ø³Ùˆ Ù†Û’ Ø³ÛŒÙ„ÛŒ Ú©Ùˆ Ø´Ú©Ø³Øª Ø¯ÛŒ Ú©ÛŒÙˆÙ†Ú©Û Ø§Ø³ Ù†Û’ Ø§ØªÙ†ÛŒ Ø§Ú†Ú¾ÛŒ Ø´Ø±ÙˆØ¹Ø§Øª Ú©ÛŒ ØªÚ¾ÛŒ Û”\",\n",
    "            text_b=\"Ø³Ùˆ Ú©ÛŒ Ø´Ø±ÙˆØ¹Ø§Øª Ø§Ú†Ú¾ÛŒ Ø±ÛÛŒ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=15,\n",
    "            text_a=\"ÛÙ…ÛŒØ´Û Ù¾ÛÙ„Û’ Ù„ÛŒØ±ÛŒ Ù†Û’ ÙˆØ§Ù„Ø¯ Ú©Ùˆ Ø§Ù† Ú©Û’ Ú©Ø§Ù… Ù…ÛŒÚº Ù…Ø¯Ø¯ Ú©ÛŒ ØªÚ¾ÛŒ Û” Ù„ÛŒÚ©Ù† ÙˆÛ Ø§Ø¨ Ø§Ù† Ú©ÛŒ Ù…Ø¯Ø¯ Ù†ÛÛŒÚº Ú©Ø± Ø³Ú©Û’ Ú©ÛŒÙˆÙ†Ú©Û ÙˆØ§Ù„Ø¯ Ù†Û’ Ú©ÛØ§ Ú©Û Ø±ÛŒÙ„ÙˆÛ’ Ú©Ù…Ù¾Ù†ÛŒ Ù…ÛŒÚº Ø§Ù† Ú©Û’ Ø¨Ø§Ø³ Ù†ÛÛŒÚº Ú†Ø§ÛÛŒÚº Ú¯Û’ Ú©Û Ø§Ù† Ú©Û’ Ø¹Ù„Ø§ÙˆÛ Ú©ÙˆØ¦ÛŒ Ø¯ÙØªØ± Ù…ÛŒÚº Ú©Ø§Ù… Ú©Ø±Û’ Û”\",\n",
    "            text_b=\"ÙˆÛ Ø§Ø¨ ÙˆØ§Ù„Ø¯ Ú©ÛŒ Ù…Ø¯Ø¯ Ù†ÛÛŒÚº Ú©Ø± Ø³Ú©ØªØ§ ØªÚ¾Ø§ Û”\",\n",
    "            label=1\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=16,\n",
    "            text_a=\"ÛÙ†Ø±ÛŒ Ú©Ø¦ÛŒ Ø¨Ø§Ø± Ø§Ù† Ø§Ù†Ù¹Ø±ÙˆÛŒÙˆØ² Ù…ÛŒÚº Ù…ÙˆØ¬ÙˆØ¯ Ø±ÛØ§ ØªÚ¾Ø§ Ø¬Ùˆ Ø§Ø³ Ú©Û’ ÙˆØ§Ù„Ø¯ Ù†Û’ Ù…Ø¹Ø±ÙˆÙ Ø¬Ø§Ø³ÙˆØ³ÙˆÚº Ú©Û’ Ø³Ø§ØªÚ¾ Ú©ÛŒÛ’ ØªÚ¾Û’ Ø¬Ùˆ Ù¾ÛŒÚ†ÛŒØ¯Û Ø§Ø³Ø±Ø§Ø± Ú©Ùˆ Ø­Ù„ Ú©Ø±Ù†Û’ Ù…ÛŒÚº Ø§Ø³ Ú©ÛŒ Ù…Ø¯Ø¯ Ú†Ø§ÛØªÛ’ ØªÚ¾Û’ Ø§ÙˆØ± ÙˆÛ Ù…ÙˆØ§Ù‚Ø¹ Ø§Ø³ Ú©Û’ Ù„ÛŒÛ’ Ø³Ø±Ø® Ø­Ø±ÙˆÙ Ú©Û’ Ø¯Ù†ÙˆÚº Ú©Û’ Ø·ÙˆØ± Ù¾Ø± Ú©Ú¾Ú‘Û’ ØªÚ¾Û’ Û”\",\n",
    "            text_b=\"ÙˆÛ Ù…ÙˆØ§Ù‚Ø¹ ÙˆØ§Ù„Ø¯ Ú©Û’ Ù„ÛŒÛ’ ÛŒØ§Ø¯Ú¯Ø§Ø± Ø§ÙˆØ± Ø®Ø§Øµ Ø¯Ù†ÙˆÚº Ú©ÛŒ Ø­ÛŒØ«ÛŒØª Ø±Ú©Ú¾ØªÛ’ ØªÚ¾Û’Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=17,\n",
    "            text_a=\"Ø¢Ø¯Ù… Ø§Ø³ ÙˆÙ‚Øª ØªÚ© ÛŒÛØ§Úº Ø³Û’ Ú©Ø§Ù… Ù†ÛÛŒÚº Ú†Ú¾ÙˆÚ‘ Ø³Ú©ØªØ§ Ø¬Ø¨ ØªÚ© Ú©Û Ø¨Ø§Ø¨ Ø§Ø³ Ú©ÛŒ Ø¬Ú¯Û Ù„ÛŒÙ†Û’ Ù†ÛÛŒÚº Ø¢ØªØ§ Û” Ø§Ú¯Ø± Ø¨Ø§Ø¨ ÙˆÙ‚Øª Ù¾Ø± Ú©Ø§Ù… Ú©Û’ Ù„ÛŒÛ’ Ú¯Ú¾Ø± Ø³Û’ Ù†Ú©Ù„ Ø¬Ø§ØªØ§ ØªÙˆ ÙˆÛ Ø§Ø³ ÙˆÙ‚Øª ØªÚ© Ú†Ù„Ø§ Ø¬Ø§ØªØ§ Û”\",\n",
    "            text_b=\"Ø¨Ø§Ø¨ Ø§Ø³ ÙˆÙ‚Øª ØªÚ© Ú†Ù„Ø§ Ø¬Ø§Ø¦Û’ Ú¯Ø§ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=18,\n",
    "            text_a=\"Ø¢Ø¯Ù… Ø§Ø³ ÙˆÙ‚Øª ØªÚ© ÛŒÛØ§Úº Ø³Û’ Ú©Ø§Ù… Ù†ÛÛŒÚº Ú†Ú¾ÙˆÚ‘ Ø³Ú©ØªØ§ Ø¬Ø¨ ØªÚ© Ú©Û Ø¨Ø§Ø¨ Ø§Ø³ Ú©ÛŒ Ø¬Ú¯Û Ù„ÛŒÙ†Û’ Ù†ÛÛŒÚº Ø¢ØªØ§ Û” Ø§Ú¯Ø± Ø¨Ø§Ø¨ ÙˆÙ‚Øª Ù¾Ø± Ú©Ø§Ù… Ú©Û’ Ù„ÛŒÛ’ Ú¯Ú¾Ø± Ø³Û’ Ù†Ú©Ù„ Ø¬Ø§ØªØ§ ØªÙˆ ÙˆÛ Ø§Ø³ ÙˆÙ‚Øª ØªÚ© ÛŒÛØ§Úº Ù¾ÛÙ†Ú† Ø¬Ø§ØªØ§ Û”\",\n",
    "            text_b=\"Ø¢Ø¯Ù… Ø§Ø³ ÙˆÙ‚Øª ØªÚ© ÛŒÛØ§Úº Ù¾ÛÙ†Ú† Ú†Ú©Ø§ ÛÙˆÚ¯Ø§ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=19,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ Ù†Û’ ÛØ¬ÙˆÙ… Ù…ÛŒÚº Ø§Ù¾Ù†ÛŒ Ø¯ÙˆØ³Øª Ø¬ÛŒÚˆ Ú©Ùˆ ØªÙ„Ø§Ø´ Ú©ÛŒØ§ Û” Ú†ÙˆÙ†Ú©Û ÙˆÛ ÛÙ…ÛŒØ´Û Ø®ÙˆØ´ Ù‚Ø³Ù…Øª Ø±ÛØªÛŒ ÛÛ’ Û” Ø§ÛŒÙ„Ø³ Ù†Û’ Ø§Ø³Û’ Ø¬Ù„Ø¯ÛŒ Ø³Û’ Ø¯ÛŒÚ©Ú¾ Ù„ÛŒØ§ Û”\",\n",
    "            text_b=\"Ú†ÙˆÙ†Ú©Û Ø¬ÛŒÚˆ ÛÙ…ÛŒØ´Û Ø®ÙˆØ´ Ù‚Ø³Ù…Øª Ø±ÛØªÛŒ ÛÛ’ ØŒ Ø§Ø³ Ù„ÛŒÛ’ Ø§ÛŒÙ„Ø³ Ù†Û’ Ø§Ø³Û’ Ø¬Ù„Ø¯ÛŒ Ø³Û’ Ø¯ÛŒÚ©Ú¾ Ù„ÛŒØ§ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=20,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ Ù†Û’ Ù¾Ø§Ø±Ù¹ÛŒ Ù…ÛŒÚº Ø§Ù¾Ù†ÛŒ Ø¨ÛŒÙ¹ÛŒ Ú©Ùˆ Ø¨Ú¾ÙˆÙ†Ú©Ù†Û’ Ø³Û’ Ø±ÙˆÚ©Ù†Û’ Ú©ÛŒ Ø¨Û’ Ú†ÛŒÙ†ÛŒ Ø³Û’ Ú©ÙˆØ´Ø´ Ú©ÛŒØŒ Ø¬Ø³ Ø³Û’ ÛÙ… ÛŒÛ Ø³ÙˆÚ†Ù†Û’ Ù¾Ø± Ù…Ø¬Ø¨ÙˆØ± ÛÙˆ Ú¯Ø¦Û’ Ú©Û ÙˆÛ Ø§ØªÙ†Ø§ Ø¹Ø¬ÛŒØ¨ Ø¨Ø±ØªØ§Ø¤ Ú©ÛŒÙˆÚº Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒÛ”\",\n",
    "            text_b=\"Ø§ÛŒÙ„Ø³ Ø¨ÛØª Ø¹Ø¬ÛŒØ¨ Ø³Ù„ÙˆÚ© Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=21,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ Ù†Û’ Ú¯Ú¾Ø¨Ø±Ø§ÛÙ¹ Ù…ÛŒÚº Ø§Ù¾Ù†ÛŒ Ø¨ÛŒÙ¹ÛŒ Ú©Ùˆ Ù¾Ø§Ø±Ù¹ÛŒ Ù…ÛŒÚº Ø¨Ø§ØªÛŒÚº Ú©Ø±Ù†Û’ Ø³Û’ Ø±ÙˆÚ©Ù†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©ÛŒØŒ Ø¬Ø³ Ø³Û’ ÛÙ…ÛŒÚº ÛŒÛ Ø³ÙˆÚ†Ù†Û’ Ù¾Ø± Ù…Ø¬Ø¨ÙˆØ± ÛÙˆÙ†Ø§ Ù¾Ú‘Ø§ Ú©Û ÙˆÛ Ø§ØªÙ†Ø§ Ø¹Ø¬ÛŒØ¨ Ø±ÙˆÛŒÛ Ú©ÛŒÙˆÚº Ø§Ø®ØªÛŒØ§Ø± Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒÛ”\",\n",
    "            text_b=\"Ø§ÛŒÙ„Ø³ Ú©ÛŒ Ø¨ÛŒÙ¹ÛŒ Ø¨ÛØª Ø¹Ø¬ÛŒØ¨ Ø³Ù„ÙˆÚ© Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=22,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ Ù†Û’ Ú¯Ú¾Ø¨Ø±Ø§ÛÙ¹ Ù…ÛŒÚº Ø§Ù¾Ù†ÛŒ Ø¨ÛŒÙ¹ÛŒ Ú©Ùˆ Ù¾Ø§Ø±Ù¹ÛŒ Ù…ÛŒÚº Ø¨Ø§ØªÛŒÚº Ú©Ø±Ù†Û’ Ø³Û’ Ø±ÙˆÚ©Ù†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©ÛŒØŒ Ø¬Ø³ Ø³Û’ ÛÙ…ÛŒÚº ÛŒÛ Ø³ÙˆÚ†Ù†Û’ Ù¾Ø± Ù…Ø¬Ø¨ÙˆØ± ÛÙˆÙ†Ø§ Ù¾Ú‘Ø§ Ú©Û ÙˆÛ Ø§ØªÙ†Ø§ Ø¹Ø¬ÛŒØ¨ Ø±ÙˆÛŒÛ Ú©ÛŒÙˆÚº Ø§Ø®ØªÛŒØ§Ø± Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒÛ”\",\n",
    "            text_b=\"Ø§ÛŒÙ„Ø³ Ú©ÛŒ Ø¨ÛŒÙ¹ÛŒ Ø¨ÛØª Ø¹Ø¬ÛŒØ¨ Ø³Ù„ÙˆÚ© Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=23,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ ÚˆØ±Ø§Ø¦Ù†Ú¯ Ø±ÙˆÙ… Ú©ÛŒ Ú¯Ø±Ø¯ Ø¬Ú¾Ø§Ú‘ Ø±ÛÛŒ ØªÚ¾ÛŒ Ø§ÙˆØ± ÙˆÛ Ø¨Ù¹Ù† ÚˆÚ¾ÙˆÙ†ÚˆÙ†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒ Ø¬Ùˆ Ù…Ø§Úº Ù†Û’ Ú†Ú¾Ù¾Ø§ Ø¯ÛŒØ§ ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³ Ú©Û’ Ù¾Ø§Ø³ Ø§Ù¾Ù†ÛŒ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û ÙÙˆÙ¹Ùˆ Ø§Ù„Ø¨Ù… Ù…ÛŒÚº Ù¾Ø±Ø§Ù†ÛŒ ØªØµÙˆÛŒØ±ÛŒÚº Ø¯ÛŒÚ©Ú¾Ù†Û’ Ú©Ø§ ÙˆÙ‚Øª Ù†ÛÛŒÚº ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³Û’ Ø§ÛŒÚ© Ø¨Ù¹Ù† ØªÙ„Ø§Ø´ Ú©Ø±Ù†Ø§ ØªÚ¾Ø§ØŒ Ø§Ø³ Ù„ÛŒÛ’ Ø§Ø³ Ù†Û’ Ø§Ù„Ø¨Ù… Ú©Ùˆ Ø¨ØºÛŒØ± Ú©Ú¾ÙˆÙ„Û’ ÛÛŒ Ø§ÛŒÚ© Ú©Ø±Ø³ÛŒ Ù¾Ø± Ø±Ú©Ú¾ Ø¯ÛŒØ§Û”\",\n",
    "            text_b=\"Ø§Ø³ Ù†Û’ Ø±ÛÙ†Û’ Ú©Ø§ Ú©Ù…Ø±Û Ú©Ú¾ÙˆÙ„Û’ Ø¨ØºÛŒØ± Ø¨Ú¾ÛŒ Ø§Ù„Ø¨Ù… Ú©Ùˆ Ú©Ø±Ø³ÛŒ Ù¾Ø± Ø±Ú©Ú¾ Ø¯ÛŒØ§ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=24,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ ÚˆØ±Ø§Ø¦Ù†Ú¯ Ø±ÙˆÙ… Ú©ÛŒ Ú¯Ø±Ø¯ Ø¬Ú¾Ø§Ú‘ Ø±ÛÛŒ ØªÚ¾ÛŒ Ø§ÙˆØ± ÙˆÛ Ø¨Ù¹Ù† ÚˆÚ¾ÙˆÙ†ÚˆÙ†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒ Ø¬Ùˆ Ù…Ø§Úº Ù†Û’ Ú†Ú¾Ù¾Ø§ Ø¯ÛŒØ§ ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³ Ú©Û’ Ù¾Ø§Ø³ Ø§Ù¾Ù†ÛŒ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û ÙÙˆÙ¹Ùˆ Ø§Ù„Ø¨Ù… Ù…ÛŒÚº Ù¾Ø±Ø§Ù†ÛŒ ØªØµÙˆÛŒØ±ÛŒÚº Ø¯ÛŒÚ©Ú¾Ù†Û’ Ú©Ø§ ÙˆÙ‚Øª Ù†ÛÛŒÚº ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³Û’ Ø§ÛŒÚ© Ø¨Ù¹Ù† ØªÙ„Ø§Ø´ Ú©Ø±Ù†Ø§ ØªÚ¾Ø§ØŒ Ø§Ø³ Ù„ÛŒÛ’ Ø§Ø³ Ù†Û’ Ø§Ù„Ø¨Ù… Ú©Ùˆ Ø¨ØºÛŒØ± Ú©Ú¾ÙˆÙ„Û’ ÛÛŒ Ø§ÛŒÚ© Ú©Ø±Ø³ÛŒ Ù¾Ø± Ø±Ú©Ú¾ Ø¯ÛŒØ§Û”\",\n",
    "            text_b=\"Ù…Ø§Ù…Ø§ Ú©Ùˆ Ø¨Ù¹Ù† ØªÙ„Ø§Ø´ Ú©Ø±Ù†Ø§ Ù¾Ú‘Ø§ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=25,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ ÚˆØ±Ø§Ø¦Ù†Ú¯ Ø±ÙˆÙ… Ú©ÛŒ Ú¯Ø±Ø¯ Ø¬Ú¾Ø§Ú‘ Ø±ÛÛŒ ØªÚ¾ÛŒ Ø§ÙˆØ± ÙˆÛ Ø¨Ù¹Ù† ÚˆÚ¾ÙˆÙ†ÚˆÙ†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒ Ø¬Ùˆ Ù…Ø§Úº Ù†Û’ Ú†Ú¾Ù¾Ø§ Ø¯ÛŒØ§ ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³ Ú©Û’ Ù¾Ø§Ø³ Ø§Ù¾Ù†ÛŒ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û ÙÙˆÙ¹Ùˆ Ø§Ù„Ø¨Ù… Ù…ÛŒÚº Ù¾Ø±Ø§Ù†ÛŒ ØªØµÙˆÛŒØ±ÛŒÚº Ø¯ÛŒÚ©Ú¾Ù†Û’ Ú©Ø§ ÙˆÙ‚Øª Ù†ÛÛŒÚº ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³Û’ Ø§ÛŒÚ© Ø¨Ù¹Ù† ØªÙ„Ø§Ø´ Ú©Ø±Ù†Ø§ ØªÚ¾Ø§ØŒ Ø§Ø³ Ù„ÛŒÛ’ Ø§Ø³ Ù†Û’ Ø§Ù„Ø¨Ù… Ú©Ùˆ Ø¨ØºÛŒØ± Ú©Ú¾ÙˆÙ„Û’ ÛÛŒ Ø§ÛŒÚ© Ú©Ø±Ø³ÛŒ Ù¾Ø± Ø±Ú©Ú¾ Ø¯ÛŒØ§Û”\",\n",
    "            text_b=\"Ø¢Ø¬ Ù…Ø§Ù…Ø§ Ú©Û’ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û ÙÙˆÙ¹Ùˆ Ø§Ù„Ø¨Ù… Ù…ÛŒÚº Ù¾Ø±Ø§Ù†ÛŒ ØªØµØ§ÙˆÛŒØ± Ø¯ÛŒÚ©Ú¾Ù†Û’ Ú©Ø§ ÙˆÙ‚Øª Ù†ÛÛŒÚº ÛÛ’ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=26,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ ÚˆØ±Ø§Ø¦Ù†Ú¯ Ø±ÙˆÙ… Ú©ÛŒ Ú¯Ø±Ø¯ Ø¬Ú¾Ø§Ú‘ Ø±ÛÛŒ ØªÚ¾ÛŒ Ø§ÙˆØ± ÙˆÛ Ø¨Ù¹Ù† ÚˆÚ¾ÙˆÙ†ÚˆÙ†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒ Ø¬Ùˆ Ù…Ø§Úº Ù†Û’ Ú†Ú¾Ù¾Ø§ Ø¯ÛŒØ§ ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³ Ú©Û’ Ù¾Ø§Ø³ Ø§Ù¾Ù†ÛŒ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û ÙÙˆÙ¹Ùˆ Ø§Ù„Ø¨Ù… Ù…ÛŒÚº Ù¾Ø±Ø§Ù†ÛŒ ØªØµÙˆÛŒØ±ÛŒÚº Ø¯ÛŒÚ©Ú¾Ù†Û’ Ú©Ø§ ÙˆÙ‚Øª Ù†ÛÛŒÚº ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³Û’ Ø§ÛŒÚ© Ø¨Ù¹Ù† ØªÙ„Ø§Ø´ Ú©Ø±Ù†Ø§ ØªÚ¾Ø§ØŒ Ø§Ø³ Ù„ÛŒÛ’ Ø§Ø³ Ù†Û’ Ø§Ù„Ø¨Ù… Ú©Ùˆ Ø¨ØºÛŒØ± Ú©Ú¾ÙˆÙ„Û’ ÛÛŒ Ø§ÛŒÚ© Ú©Ø±Ø³ÛŒ Ù¾Ø± Ø±Ú©Ú¾ Ø¯ÛŒØ§Û”\",\n",
    "            text_b=\"Ø§Ø³ Ù†Û’ Ú©Ø±Ø³ÛŒ Ú©Ú¾ÙˆÙ„Û’ Ø¨ØºÛŒØ± Ø§Ù„Ø¨Ù… Ú©Ùˆ Ú©Ø±Ø³ÛŒ Ù¾Ø± Ø±Ú©Ú¾ Ø¯ÛŒØ§ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=27,\n",
    "            text_a=\"Ø§ÛŒÙ„Ø³ ÚˆØ±Ø§Ø¦Ù†Ú¯ Ø±ÙˆÙ… Ú©ÛŒ Ú¯Ø±Ø¯ Ø¬Ú¾Ø§Ú‘ Ø±ÛÛŒ ØªÚ¾ÛŒ Ø§ÙˆØ± ÙˆÛ Ø¨Ù¹Ù† ÚˆÚ¾ÙˆÙ†ÚˆÙ†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©Ø± Ø±ÛÛŒ ØªÚ¾ÛŒ Ø¬Ùˆ Ù…Ø§Úº Ù†Û’ Ú†Ú¾Ù¾Ø§ Ø¯ÛŒØ§ ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³ Ú©Û’ Ù¾Ø§Ø³ Ø§Ù¾Ù†ÛŒ Ù¾Ø³Ù†Ø¯ÛŒØ¯Û ÙÙˆÙ¹Ùˆ Ø§Ù„Ø¨Ù… Ù…ÛŒÚº Ù¾Ø±Ø§Ù†ÛŒ ØªØµÙˆÛŒØ±ÛŒÚº Ø¯ÛŒÚ©Ú¾Ù†Û’ Ú©Ø§ ÙˆÙ‚Øª Ù†ÛÛŒÚº ØªÚ¾Ø§Û” Ø¢Ø¬ Ø§Ø³Û’ Ø§ÛŒÚ© Ø¨Ù¹Ù† ØªÙ„Ø§Ø´ Ú©Ø±Ù†Ø§ ØªÚ¾Ø§ØŒ Ø§Ø³ Ù„ÛŒÛ’ Ø§Ø³ Ù†Û’ Ø§Ù„Ø¨Ù… Ú©Ùˆ Ø¨ØºÛŒØ± Ú©Ú¾ÙˆÙ„Û’ ÛÛŒ Ø§ÛŒÚ© Ú©Ø±Ø³ÛŒ Ù¾Ø± Ø±Ú©Ú¾ Ø¯ÛŒØ§Û”\",\n",
    "            text_b=\"Ø§Ø³ Ù†Û’ Ø¨Ù¹Ù† Ú©Ú¾ÙˆÙ„Û’ Ø¨ØºÛŒØ± Ø§Ù„Ø¨Ù… Ú©Ùˆ Ú©Ø±Ø³ÛŒ Ù¾Ø± Ø±Ú©Ú¾ Ø¯ÛŒØ§ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=28,\n",
    "            text_a=\"ÚˆÙˆØ±Ø§ Ú©Û’ Ú†ÛŒÚ© Ø¯Ø§Ø± Ù„Ø¨Ø§Ø³ Ú©ÛŒ Ù¾Ø´Øª Ù¾Ø± Ù„Ú¯Û’ ØªÙ…Ø§Ù… Ø¨Ù¹Ù† Ø§Ù„Ù¹Û’ Ø±Ø® Ø³Û’ Ø¨Ù†Ø¯ Ú©ÛŒÛ’ Ú¯Ø¦Û’ ØªÚ¾Û’Û” Ù…Ø§ÙˆÚˆ Ú©Ùˆ Ú†Ø§ÛÛŒÛ’ ØªÚ¾Ø§ Ú©Û ÙˆÛ Ø§Ø³Û’ Ø®ÙˆØ¯ Ø¨Ù¹Ù† Ù„Ú¯Ø§ Ø¯ÛŒØªÛŒØŒ Ù…Ú¯Ø± Ù†ÛÛŒÚºØ› Ø§Ø³ Ù†Û’ Ø¨ÛŒÚ†Ø§Ø±ÛŒ Ù†Ù†Ú¾ÛŒ ÚˆÙˆØ±Ø§ Ú©Ùˆ Ø§Ú©ÛŒÙ„Ø§ ÛÛŒ Ø§Ù¾Ù†ÛŒ Ø¨Ø³Ø§Ø· Ú©Û’ Ù…Ø·Ø§Ø¨Ù‚ Ø³Ø¨ Ú©Ú†Ú¾ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ú†Ú¾ÙˆÚ‘ Ø¯ÛŒØ§ ØªÚ¾Ø§Û”\",\n",
    "            text_b=\"Ø§Ø³ Ù†Û’ Ø¨Û’Ú†Ø§Ø±ÛŒ Ù†Ù†Ú¾ÛŒ ÚˆÙˆØ±Ø§ Ú©Ùˆ Ø§Ú©ÛŒÙ„Ø§ Ú†Ú¾ÙˆÚ‘ Ø¯ÛŒØ§ ØªÚ¾Ø§ Ú©Û ÙˆÛ Ø§Ù¾Ù†ÛŒ Ù¾ÙˆØ±ÛŒ Ú©ÙˆØ´Ø´ Ø®ÙˆØ¯ ÛÛŒ Ú©Ø±Û’Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=29,\n",
    "            text_a=\"Ø§Ú¯Ø±Ú†Û ÙˆÛ ØªÙ‚Ø±ÛŒØ¨Ø§ Ø§ÛŒÚ© ÛÛŒ Ø±ÙØªØ§Ø± Ø³Û’ Ø¯ÙˆÚ‘ØªÛ’ ØªÚ¾Û’ Û” Ø³Ùˆ Ù†Û’ Ø³ÛŒÙ„ÛŒ Ú©Ùˆ Ø´Ú©Ø³Øª Ø¯ÛŒ Ú©ÛŒÙˆÙ†Ú©Û Ø§Ø³ Ú©ÛŒ Ø´Ø±ÙˆØ¹Ø§Øª Ø§ØªÙ†ÛŒ Ø®Ø±Ø§Ø¨ ØªÚ¾ÛŒ Û”\",\n",
    "            text_b=\"Ø³Ùˆ Ú©ÛŒ Ø´Ø±ÙˆØ¹Ø§Øª Ø§ØªÙ†ÛŒ Ø®Ø±Ø§Ø¨ ØªÚ¾ÛŒ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=30,\n",
    "            text_a=\"ÛÙ…ÛŒØ´Û Ù¾ÛÙ„Û’ Ù„ÛŒØ±ÛŒ Ù†Û’ ÙˆØ§Ù„Ø¯ Ú©Ùˆ Ø§Ù† Ú©Û’ Ú©Ø§Ù… Ù…ÛŒÚº Ù…Ø¯Ø¯ Ú©ÛŒ ØªÚ¾ÛŒ Û” Ù„ÛŒÚ©Ù† ÙˆÛ Ø§Ø¨ Ø§Ù† Ú©ÛŒ Ù…Ø¯Ø¯ Ù†ÛÛŒÚº Ú©Ø± Ø³Ú©Û’ Ú©ÛŒÙˆÙ†Ú©Û ÙˆØ§Ù„Ø¯ Ù†Û’ Ú©ÛØ§ Ú©Û Ø±ÛŒÙ„ÙˆÛ’ Ú©Ù…Ù¾Ù†ÛŒ Ù…ÛŒÚº Ø§Ù† Ú©Û’ Ø¨Ø§Ø³ Ù†ÛÛŒÚº Ú†Ø§ÛÛŒÚº Ú¯Û’ Ú©Û Ø§Ù† Ú©Û’ Ø¹Ù„Ø§ÙˆÛ Ú©ÙˆØ¦ÛŒ Ø¯ÙØªØ± Ù…ÛŒÚº Ú©Ø§Ù… Ú©Ø±Û’ Û”\",\n",
    "            text_b=\"Ø¨Ø§Ø¨Ø§ Ø§Ø¨ Ø§Ø³ Ú©ÛŒ Ù…Ø¯Ø¯ Ù†ÛÛŒÚº Ú©Ø± Ø³Ú©ØªÛ’ ØªÚ¾Û’ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        InputExample(\n",
    "            guid=31,\n",
    "            text_a=\"ÛÙ…ÛŒØ´Û Ù¾ÛÙ„Û’ Ù„ÛŒØ±ÛŒ Ù†Û’ ÙˆØ§Ù„Ø¯ Ú©Ùˆ Ø§Ù† Ú©Û’ Ú©Ø§Ù… Ù…ÛŒÚº Ù…Ø¯Ø¯ Ú©ÛŒ ØªÚ¾ÛŒ Û” Ù„ÛŒÚ©Ù† ÙˆÛ Ø§Ø¨ Ø§Ù† Ú©ÛŒ Ù…Ø¯Ø¯ Ù†ÛÛŒÚº Ú©Ø± Ø³Ú©Û’ Ú©ÛŒÙˆÙ†Ú©Û ÙˆØ§Ù„Ø¯ Ù†Û’ Ú©ÛØ§ Ú©Û Ø±ÛŒÙ„ÙˆÛ’ Ú©Ù…Ù¾Ù†ÛŒ Ù…ÛŒÚº Ø§Ù† Ú©Û’ Ø¨Ø§Ø³ Ù†ÛÛŒÚº Ú†Ø§ÛÛŒÚº Ú¯Û’ Ú©Û Ø§Ù† Ú©Û’ Ø¹Ù„Ø§ÙˆÛ Ú©ÙˆØ¦ÛŒ Ø¯ÙØªØ± Ù…ÛŒÚº Ú©Ø§Ù… Ú©Ø±Û’ Û”\",\n",
    "            text_b=\"Ø±ÛŒÙ„ÙˆÛ’ Ú©Ù…Ù¾Ù†ÛŒ Ù…ÛŒÚº Ù„ÛŒØ±ÛŒ Ú©Ø§ Ø¨Ø§Ø³ Ù†ÛÛŒÚº Ú†Ø§ÛØªØ§ ØªÚ¾Ø§ Ú©Û Ø§Ø³ Ú©Û’ Ø¹Ù„Ø§ÙˆÛ Ú©ÙˆØ¦ÛŒ Ø¨Ú¾ÛŒ Ø¯ÙØªØ± Ù…ÛŒÚº Ú©Ø§Ù… Ú©Ø±Û’ Û”\",\n",
    "            label=0\n",
    "        ),\n",
    "        \n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4054dc6-73ce-49c2-97cd-45c8e604c0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['cls.predictions.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "### Classes ###\n",
    "classes = ['entailment', 'not_entailment']\n",
    "\n",
    "### Label Map ###\n",
    "label_map = {'entailment': 1, 'not_entailment': 0}\n",
    "\n",
    "\n",
    "\n",
    "# # # Step 1: Use load_plm with 'roberta' to get the correct WrapperClass\n",
    "# _, _, _, WrapperClass = load_plm(\"roberta\", \"roberta-base\")  # Just to get the wrapper\n",
    "\n",
    "# # # # Step 2: Manually load XLM-RoBERTa model/tokenizer\n",
    "# model_name = \"xlm-roberta-base\"\n",
    "# tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
    "# plm = XLMRobertaForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "# ==============================\n",
    "# Load Pretrained Language Model (mBERT)\n",
    "# ==============================\n",
    "plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3be590d0-fa46-4d5e-be16-95c770c471cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Define Prompt Template (Manual)\n",
    "# ==============================\n",
    "template = ManualTemplate(\n",
    "    text = '{\"placeholder\":\"text_a\"} Ø§ÙˆØ± {\"placeholder\":\"text_b\"} Ú©Ø§ ØªØ¹Ù„Ù‚ {\"mask\"} ÛÛ’Û”',\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "templates = [\n",
    "    (\"P1\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} Ø§ÙˆØ± {\"placeholder\":\"text_b\"} Ú©Ø§ ØªØ¹Ù„Ù‚ {\"mask\"} ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P2\", ManualTemplate(\n",
    "        text='Ù¾ÛÙ„Ø§ Ø¨ÛŒØ§Ù†: {\"placeholder\":\"text_a\"} Ø¯ÙˆØ³Ø±Ø§ Ø¨ÛŒØ§Ù†: {\"placeholder\":\"text_b\"} Ø§Ù† Ú©Ø§ ØªØ¹Ù„Ù‚ {\"mask\"} ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P3\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_b\"} Ú©ÛŒØ§ {\"placeholder\":\"text_a\"} Ø³Û’ {\"mask\"} ÛÙˆØªØ§ ÛÛ’ØŸ',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P4\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} Ú©ÛŒ Ø±ÙˆØ´Ù†ÛŒ Ù…ÛŒÚº {\"placeholder\":\"text_b\"} {\"mask\"} ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P5\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_b\"} Ú©Ø§ Ø¨ÛŒØ§Ù† {\"placeholder\":\"text_a\"} Ú©Û’ Ù…Ø·Ø§Ø¨Ù‚ {\"mask\"} ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P6\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} Ø§ÙˆØ± {\"placeholder\":\"text_b\"} Ú©Û’ Ø¯Ø±Ù…ÛŒØ§Ù† Ù…Ù†Ø·Ù‚ÛŒ Ø±Ø´ØªÛ {\"mask\"} ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P7\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_b\"}ØŒ {\"placeholder\":\"text_a\"} Ø³Û’ {\"mask\"} Ø·ÙˆØ± Ù¾Ø± Ø¬Ú‘Ø§ ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P8\", ManualTemplate(\n",
    "        text='Ø§Ú¯Ø± ÛÙ… {\"placeholder\":\"text_a\"} Ú©Ùˆ Ø¯ÛŒÚ©Ú¾ÛŒÚº ØªÙˆ {\"placeholder\":\"text_b\"} {\"mask\"} Ø¨Ù†ØªØ§ ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P9\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} Ú©Û’ Ø­ÙˆØ§Ù„Û’ Ø³Û’ {\"placeholder\":\"text_b\"} {\"mask\"} Ø³Ù…Ø¬Ú¾Ø§ Ø¬Ø§ØªØ§ ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "\n",
    "    (\"P10\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} Ø§ÙˆØ± {\"placeholder\":\"text_b\"} Ù…ÛŒÚº ØªØ¹Ù„Ù‚ Ú©ÛŒ Ù†ÙˆØ¹ÛŒØª {\"mask\"} ÛÛ’Û”',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "verbalizer = ManualVerbalizer(\n",
    "    classes=classes,\n",
    "    label_words={\n",
    "        \"entailment\": [\"Ø¯Ø±Ø³Øª\", \"Ø«Ø§Ø¨Øª\"],\n",
    "        \"not_entailment\": [\"ØºÙ„Ø·\", \"Ù†Ø§Ù…Ø·Ø§Ø¨Ù‚\"]\n",
    "    },\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec3a8fcc-641f-47ee-b5c3-e0cad605103e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŸ¦ Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 508.10it/s]\n",
      "tokenizing: 32it [00:00, 843.61it/s]\n",
      "tokenizing: 32it [00:00, 793.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 5.5924\n",
      "Prompt pattern: ['P2', 'P1']\n",
      "\n",
      "ğŸŸ¦ Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 841.62it/s]\n",
      "tokenizing: 32it [00:00, 873.42it/s]\n",
      "tokenizing: 32it [00:00, 735.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 2.8597\n",
      "Prompt pattern: ['P4', 'P4']\n",
      "\n",
      "ğŸŸ¦ Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 728.11it/s]\n",
      "tokenizing: 32it [00:00, 619.58it/s]\n",
      "tokenizing: 32it [00:00, 650.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 1.6914\n",
      "Prompt pattern: ['P2', 'P9']\n",
      "\n",
      "ğŸŸ¦ Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 559.70it/s]\n",
      "tokenizing: 32it [00:00, 805.44it/s]\n",
      "tokenizing: 32it [00:00, 747.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 3.5679\n",
      "Prompt pattern: ['P10', 'P7']\n",
      "\n",
      "ğŸŸ¦ Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 874.68it/s]\n",
      "tokenizing: 32it [00:00, 670.27it/s]\n",
      "tokenizing: 32it [00:00, 1003.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 1.4459\n",
      "Prompt pattern: ['P1', 'P2']\n",
      "\n",
      "ğŸŸ¦ Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 539.21it/s]\n",
      "tokenizing: 32it [00:00, 719.72it/s]\n",
      "tokenizing: 32it [00:00, 818.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 1.6310\n",
      "Prompt pattern: ['P4', 'P9']\n",
      "\n",
      "ğŸŸ¦ Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 937.60it/s]\n",
      "tokenizing: 32it [00:00, 821.30it/s]\n",
      "tokenizing: 32it [00:00, 900.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 1.3434\n",
      "Prompt pattern: ['P1', 'P9']\n",
      "\n",
      "ğŸŸ¦ Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 822.02it/s]\n",
      "tokenizing: 32it [00:00, 784.33it/s]\n",
      "tokenizing: 32it [00:00, 811.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 1.8168\n",
      "Prompt pattern: ['P9', 'P7']\n",
      "\n",
      "ğŸŸ¦ Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 871.42it/s]\n",
      "tokenizing: 32it [00:00, 809.55it/s]\n",
      "tokenizing: 32it [00:00, 842.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 1.6349\n",
      "Prompt pattern: ['P8', 'P10']\n",
      "\n",
      "ğŸŸ¦ Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 876.70it/s]\n",
      "tokenizing: 32it [00:00, 722.82it/s]\n",
      "tokenizing: 32it [00:00, 883.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 1.4894\n",
      "Prompt pattern: ['P1', 'P3']\n",
      "\n",
      "ğŸŸ¦ Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 716.06it/s]\n",
      "tokenizing: 32it [00:00, 892.39it/s]\n",
      "tokenizing: 32it [00:00, 791.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss: 1.8453\n",
      "Prompt pattern: ['P6', 'P5']\n",
      "\n",
      "ğŸŸ¦ Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 924.13it/s]\n",
      "tokenizing: 32it [00:00, 937.05it/s]\n",
      "tokenizing: 32it [00:00, 840.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss: 1.6384\n",
      "Prompt pattern: ['P4', 'P6']\n",
      "\n",
      "ğŸŸ¦ Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 772.84it/s]\n",
      "tokenizing: 32it [00:00, 605.12it/s]\n",
      "tokenizing: 32it [00:00, 751.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss: 1.5160\n",
      "Prompt pattern: ['P2', 'P7']\n",
      "\n",
      "ğŸŸ¦ Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 844.76it/s]\n",
      "tokenizing: 32it [00:00, 892.10it/s]\n",
      "tokenizing: 32it [00:00, 583.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss: 1.7115\n",
      "Prompt pattern: ['P6', 'P6']\n",
      "\n",
      "ğŸŸ¦ Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 838.09it/s]\n",
      "tokenizing: 32it [00:00, 567.92it/s]\n",
      "tokenizing: 32it [00:00, 925.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss: 1.4881\n",
      "Prompt pattern: ['P5', 'P1']\n",
      "\n",
      "ğŸŸ¦ Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 571.00it/s]\n",
      "tokenizing: 32it [00:00, 817.04it/s]\n",
      "tokenizing: 32it [00:00, 840.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Loss: 1.5492\n",
      "Prompt pattern: ['P9', 'P2']\n",
      "\n",
      "ğŸŸ¦ Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 782.32it/s]\n",
      "tokenizing: 32it [00:00, 890.69it/s]\n",
      "tokenizing: 32it [00:00, 1152.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Loss: 1.5074\n",
      "Prompt pattern: ['P2', 'P9']\n",
      "\n",
      "ğŸŸ¦ Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 912.86it/s]\n",
      "tokenizing: 32it [00:00, 899.12it/s]\n",
      "tokenizing: 32it [00:00, 853.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Loss: 1.7202\n",
      "Prompt pattern: ['P10', 'P6']\n",
      "\n",
      "ğŸŸ¦ Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 945.72it/s]\n",
      "tokenizing: 32it [00:00, 749.48it/s]\n",
      "tokenizing: 32it [00:00, 950.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Loss: 1.1938\n",
      "Prompt pattern: ['P4', 'P2']\n",
      "\n",
      "ğŸŸ¦ Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 32it [00:00, 746.78it/s]\n",
      "tokenizing: 32it [00:00, 893.64it/s]\n",
      "tokenizing: 32it [00:00, 850.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Loss: 1.2499\n",
      "Prompt pattern: ['P4', 'P5']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Create Prompt Model\n",
    "# ==============================\n",
    "prompt_model = PromptForClassification(\n",
    "    template=template,\n",
    "    plm=plm,\n",
    "    verbalizer=verbalizer\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# Training loop with BalancedBatchSampler + random template switching\n",
    "# ==============================\n",
    "T = 20   # epochs\n",
    "K = 1    # steps per prompt\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt_model.train()\n",
    "optimizer = AdamW(prompt_model.parameters(), lr=1e-5)\n",
    "all_epoch_patterns = {}\n",
    "\n",
    "for epoch in range(T):\n",
    "    print(f\"\\nğŸŸ¦ Epoch {epoch+1}/{T}\")\n",
    "\n",
    "    # Random initial template\n",
    "    prompt_name, current_template = random.choice(templates)\n",
    "    epoch_pattern = []\n",
    "\n",
    "    # Create PromptDataLoader with BalancedBatchSampler\n",
    "    sampler = BalancedBatchSampler(train_dataset, batch_size=batch_size)\n",
    "    train_loader = PromptDataLoader(\n",
    "        dataset=train_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        template=current_template,\n",
    "        tokenizer_wrapper_class=WrapperClass,\n",
    "        max_seq_length=128,\n",
    "        batch_size=batch_size,\n",
    "        batch_sampler=sampler,\n",
    "        shuffle=False  # shuffle is ignored when batch_sampler is used\n",
    "    )\n",
    "\n",
    "    step_counter = 0\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # Move batch to device\n",
    "        # batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        logits = prompt_model(batch)\n",
    "        loss = torch.nn.CrossEntropyLoss()(logits, batch['label'])\n",
    "        # loss = criterion(logits, batch[\"label\"])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_pattern.append(prompt_name)\n",
    "\n",
    "        step_counter += 1\n",
    "\n",
    "        # Switch template every K steps\n",
    "        if step_counter % K == 0:\n",
    "            prompt_name, current_template = random.choice(templates)\n",
    "\n",
    "            # Rebuild PromptDataLoader with new template but same sampler\n",
    "            train_loader = PromptDataLoader(\n",
    "                dataset=train_dataset,\n",
    "                tokenizer=tokenizer,\n",
    "                template=current_template,\n",
    "                tokenizer_wrapper_class=WrapperClass,\n",
    "                max_seq_length=128,\n",
    "                batch_size=batch_size,\n",
    "                batch_sampler=sampler,\n",
    "                shuffle=False\n",
    "            )\n",
    "\n",
    "    all_epoch_patterns[f\"epoch_{epoch+1}\"] = epoch_pattern\n",
    "    print(f\"Epoch {epoch+1} Loss: {epoch_loss:.4f}\")\n",
    "    print(f\"Prompt pattern: {epoch_pattern}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7f77886-2e9a-46b4-9450-d10175f3913c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 71it [00:00, 1171.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š WNLI Urdu Dev Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    entailment     0.5185    0.3500    0.4179        40\n",
      "not_entailment     0.4091    0.5806    0.4800        31\n",
      "\n",
      "      accuracy                         0.4507        71\n",
      "     macro avg     0.4638    0.4653    0.4490        71\n",
      "  weighted avg     0.4707    0.4507    0.4450        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Load Evaluation Dataset\n",
    "# ==============================\n",
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\stdFurqan\\Desktop\\paft\\WNLI\\WNLI_dev_urdu_entailment.csv\"\n",
    ")\n",
    "\n",
    "# Make InputExamples\n",
    "eval_dataset = [\n",
    "    InputExample(\n",
    "        guid=i,\n",
    "        text_a=row['Sentence1'],\n",
    "        text_b=row['Sentence2'],\n",
    "        label=label_map[row['label_text']]\n",
    "    )\n",
    "    for i, row in df.iterrows()\n",
    "]\n",
    "\n",
    "# ==============================\n",
    "# PromptDataLoader\n",
    "# ==============================\n",
    "eval_loader = PromptDataLoader(\n",
    "    dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    template=template,              # your ManualTemplate for XNLI\n",
    "    tokenizer_wrapper_class=WrapperClass,\n",
    "    max_seq_length=128,\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# Evaluate Model\n",
    "# ==============================\n",
    "prompt_model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in eval_loader:\n",
    "        logits = prompt_model(batch)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_labels.extend(batch['label'].cpu().tolist())\n",
    "\n",
    "# ==============================\n",
    "# Print Classification Report\n",
    "# ==============================\n",
    "print(\"\\nğŸ“Š WNLI Urdu Dev Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=classes, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a79a2b-957c-4198-a17a-b5ac3f6520df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398760d-eae5-4fda-af37-c8fc2222563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta\n",
    "BS = 8\n",
    "ğŸ“Š WNLI Urdu Dev Classification Report:\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "    entailment     0.6667    0.0500    0.0930        40\n",
    "not_entailment     0.4412    0.9677    0.6061        31\n",
    "\n",
    "      accuracy                         0.4507        71\n",
    "     macro avg     0.5539    0.5089    0.3495        71\n",
    "  weighted avg     0.5682    0.4507    0.3170        71\n",
    "\n",
    "\n",
    "\n",
    "BS = 16\n",
    "\n",
    "ğŸ“Š WNLI Urdu Dev Classification Report:\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "    entailment     0.8571    0.1500    0.2553        40\n",
    "not_entailment     0.4688    0.9677    0.6316        31\n",
    "\n",
    "      accuracy                         0.5070        71\n",
    "     macro avg     0.6629    0.5589    0.4434        71\n",
    "  weighted avg     0.6876    0.5070    0.4196        71\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfb3c0-3631-46f7-aac2-cbc8c2e437d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert\n",
    "BS = 8\n",
    "ğŸ“Š WNLI Urdu Dev Classification Report:\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "    entailment     0.6429    0.4500    0.5294        40\n",
    "not_entailment     0.4884    0.6774    0.5676        31\n",
    "\n",
    "      accuracy                         0.5493        71\n",
    "     macro avg     0.5656    0.5637    0.5485        71\n",
    "  weighted avg     0.5754    0.5493    0.5461        71\n",
    "\n",
    "BS = 16\n",
    "ğŸ“Š WNLI Urdu Dev Classification Report:\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "    entailment     0.5185    0.3500    0.4179        40\n",
    "not_entailment     0.4091    0.5806    0.4800        31\n",
    "\n",
    "      accuracy                         0.4507        71\n",
    "     macro avg     0.4638    0.4653    0.4490        71\n",
    "  weighted avg     0.4707    0.4507    0.4450        71"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
