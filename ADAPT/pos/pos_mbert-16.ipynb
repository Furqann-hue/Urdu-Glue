{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1cabbae-17d0-400a-a000-9a0b83521d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779528ed-684d-4819-896d-1aec1da7f1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 4080 SUPER\n",
      "CUDA version: 12.1\n",
      "GPU count: 1\n",
      "Unique POS tags: ['PN' 'G' 'NN' 'P' 'U' 'VB' 'SM' 'PM' 'PP' 'CC' 'ADJ' 'CA' 'RP' 'SC' 'SE'\n",
      " 'ADV' 'EXP' 'I' 'NEG' 'TA' 'AP' 'Q' 'PD' 'WALA' 'KP' 'GR' 'REP' 'A' 'KD'\n",
      " 'AA' 'QW' 'KER' 'OR' 'AKP' 'MUL' 'INT' 'AD' 'FR' 'DATE' 'RD']\n",
      "Label map: {'PN': 0, 'G': 1, 'NN': 2, 'P': 3, 'U': 4, 'VB': 5, 'SM': 6, 'PM': 7, 'PP': 8, 'CC': 9, 'ADJ': 10, 'CA': 11, 'RP': 12, 'SC': 13, 'SE': 14, 'ADV': 15, 'EXP': 16, 'I': 17, 'NEG': 18, 'TA': 19, 'AP': 20, 'Q': 21, 'PD': 22, 'WALA': 23, 'KP': 24, 'GR': 25, 'REP': 26, 'A': 27, 'KD': 28, 'AA': 29, 'QW': 30, 'KER': 31, 'OR': 32, 'AKP': 33, 'MUL': 34, 'INT': 35, 'AD': 36, 'FR': 37, 'DATE': 38, 'RD': 39}\n",
      "‚úÖ Few-shot dataset created with total examples: 627\n",
      "GUID: 0 | Word: ‚Äô | Label: 0\n",
      "GUID: 1 | Word: ÿß€å | Label: 0\n",
      "GUID: 2 | Word: ÿ®ŸÑÿßŸÑ | Label: 0\n",
      "GUID: 3 | Word: ÿ®⁄æÿßÿ¶€å | Label: 0\n",
      "GUID: 4 | Word: ÿ≥ÿ™ŸÖÿ®ÿ± | Label: 0\n",
      "GUID: 5 | Word: ÿß⁄ë⁄æÿßÿ¶€å | Label: 0\n",
      "GUID: 6 | Word: ‚Äú | Label: 0\n",
      "GUID: 7 | Word: Ÿπ€å⁄Ø | Label: 0\n",
      "GUID: 8 | Word: ÿ±Ÿà | Label: 0\n",
      "GUID: 9 | Word: ŸÖ€åŸÜ | Label: 0\n",
      "GUID: 10 | Word: ÿπÿ¥ÿßÿ° | Label: 0\n",
      "GUID: 11 | Word: ÿ¨ÿ®ŸÑ | Label: 0\n",
      "GUID: 12 | Word: ÿ±ÿ∂€å | Label: 0\n",
      "GUID: 13 | Word: ÿßŸÑŸÑ€Å | Label: 0\n",
      "GUID: 14 | Word: Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ | Label: 0\n",
      "GUID: 15 | Word: ⁄©ÿ±⁄©Ÿπ | Label: 0\n",
      "GUID: 16 | Word: ŸÖ€åÿ±€í | Label: 1\n",
      "GUID: 17 | Word: ŸÖ€åÿ±ÿß | Label: 1\n",
      "GUID: 18 | Word: ŸÖ€åÿ±€å | Label: 1\n",
      "GUID: 19 | Word: ŸÖ€åÿ±ÿß | Label: 1\n",
      "Classes: ['PN', 'G', 'NN', 'P', 'U', 'VB', 'SM', 'PM', 'PP', 'CC', 'ADJ', 'CA', 'RP', 'SC', 'SE', 'ADV', 'EXP', 'I', 'NEG', 'TA', 'AP', 'Q', 'PD', 'WALA', 'KP', 'GR', 'REP', 'A', 'KD', 'AA', 'QW', 'KER', 'OR', 'AKP', 'MUL', 'INT', 'AD', 'FR', 'DATE', 'RD']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['cls.predictions.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Imports\n",
    "# ==============================\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForMaskedLM\n",
    "from openprompt.prompts import ManualTemplate, ManualVerbalizer\n",
    "from openprompt.data_utils import InputExample\n",
    "from openprompt.plms import load_plm\n",
    "from openprompt import PromptForClassification, PromptDataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "\n",
    "# ========================================\n",
    "# Check CUDA\n",
    "# ========================================\n",
    "device = \"cuda\" #if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU count:\", torch.cuda.device_count())\n",
    "\n",
    "# ========================================\n",
    "# Seeds for reproducibility\n",
    "# ========================================\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ==============================\n",
    "# Load POS Train Dataset\n",
    "# ==============================\n",
    "df = pd.read_csv(r\"C:\\Users\\stdFurqan\\Desktop\\paft\\pos\\train.csv\")  # columns: 'word', 'tag'\n",
    "\n",
    "# Find unique tags\n",
    "unique_tags = df['tag'].unique()\n",
    "print(\"Unique POS tags:\", unique_tags)\n",
    "\n",
    "# Create label map\n",
    "label_map = {tag: i for i, tag in enumerate(unique_tags)}\n",
    "print(\"Label map:\", label_map)\n",
    "\n",
    "# ==============================\n",
    "# Prepare Few-Shot Training Dataset: first 16 examples per tag\n",
    "# ==============================\n",
    "train_dataset = []\n",
    "guid = 0\n",
    "\n",
    "for tag in unique_tags:\n",
    "    tag_rows = df[df['tag'] == tag].head(16)  # first 16 examples\n",
    "    for _, row in tag_rows.iterrows():\n",
    "        example = InputExample(\n",
    "            guid=str(guid),\n",
    "            text_a=row['word'],\n",
    "            label=label_map[row['tag']]\n",
    "        )\n",
    "        train_dataset.append(example)\n",
    "        guid += 1\n",
    "\n",
    "print(\"‚úÖ Few-shot dataset created with total examples:\", len(train_dataset))\n",
    "\n",
    "# ==============================\n",
    "# Inspect first few examples\n",
    "# ==============================\n",
    "for ex in train_dataset[:20]:\n",
    "    print(\"GUID:\", ex.guid, \"| Word:\", ex.text_a, \"| Label:\", ex.label)\n",
    "\n",
    "# ==============================\n",
    "# Define Classes\n",
    "# ==============================\n",
    "classes = list(label_map.keys())\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "# ==============================\n",
    "# Load Pretrained Model and Tokenizer\n",
    "# ==============================\n",
    "# # # Step 1: Use load_plm with 'roberta' to get the correct WrapperClass\n",
    "# _, _, _, WrapperClass = load_plm(\"roberta\", \"roberta-base\")  # Just to get the wrapper\n",
    "\n",
    "# # # Step 2: Manually load XLM-RoBERTa model/tokenizer\n",
    "# model_name = \"xlm-roberta-base\"\n",
    "# tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
    "# plm = XLMRobertaForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "# # ==============================\n",
    "# # Load Pretrained Language Model (mBERT)\n",
    "# # ==============================\n",
    "plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-base-multilingual-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302d9b42-e3cc-45ab-a74c-39035abdb1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò FINAL VERBALIZER CONTENT:\n",
      "\n",
      "PN ‚Üí ['PN', '‚Äô', 'ÿß€å']\n",
      "G ‚Üí ['G', 'ŸÖ€åÿ±€í', 'ŸÖ€åÿ±ÿß']\n",
      "NN ‚Üí ['NN', 'ÿ®⁄æÿßÿ¶€å', 'ŸÖÿ≠ŸÜÿ™']\n",
      "P ‚Üí ['P', '⁄©ÿß', '⁄©€å']\n",
      "U ‚Üí ['U', 'ŸÖ€åŸÑ', 'ŸÖŸÜ']\n",
      "VB ‚Üí ['VB', 'ÿ¢€åÿß€Å€í', '€Å€å⁄∫']\n",
      "SM ‚Üí ['SM', '€î', '!']\n",
      "PM ‚Üí ['PM', 'ÿå', '\"']\n",
      "PP ‚Üí ['PP', '€ÅŸÖ', 'ÿ¢Ÿæ']\n",
      "CC ‚Üí ['CC', 'ÿßŸàÿ±', 'Ÿà']\n",
      "ADJ ‚Üí ['ADJ', 'ŸÇÿßÿ¶ŸÑ', 'ŸÖ€åÿ±€åÿ¶Ÿπ']\n",
      "CA ‚Üí ['CA', 'ÿß⁄©€åÿ≥', 'ÿØŸà']\n",
      "RP ‚Üí ['RP', 'ÿÆŸàÿØ', 'ÿßŸæŸÜ€íÿ¢Ÿæ']\n",
      "SC ‚Üí ['SC', 'ÿ¨ÿ®⁄©€Å', '⁄©€Å']\n",
      "SE ‚Üí ['SE', 'ÿ≥€í']\n",
      "ADV ‚Üí ['ADV', 'ÿ®ÿ±ÿßÿ¶€í', 'ÿ≤€åÿßÿØ€Å']\n",
      "EXP ‚Üí ['EXP', '‚Äù', '(']\n",
      "I ‚Üí ['I', 'ÿ™Ÿà', '€Å€å']\n",
      "NEG ‚Üí ['NEG', 'ŸÜ€Å€å⁄∫', 'ŸÜ€Å']\n",
      "TA ‚Üí ['TA', '€Å€å⁄∫', '€Å€í']\n",
      "AP ‚Üí ['AP', 'Ÿà€Åÿß⁄∫', 'ÿßÿ®']\n",
      "Q ‚Üí ['Q', '⁄©⁄Ü⁄æ', '€Åÿ±']\n",
      "PD ‚Üí ['PD', 'ÿßÿ≥', 'ÿßŸÜ']\n",
      "WALA ‚Üí ['WALA', 'ŸàÿßŸÑÿß', 'ŸàÿßŸÑ€í']\n",
      "KP ‚Üí ['KP', '⁄©ÿ≥', '⁄©€åÿß']\n",
      "GR ‚Üí ['GR', 'ÿßŸæŸÜ€å', 'ÿßŸæŸÜÿß']\n",
      "REP ‚Üí ['REP', 'ÿ¨ÿ≥', 'ÿ¨ŸÜ']\n",
      "A ‚Üí ['A', 'ÿ≥€å', 'ÿ≥ÿß']\n",
      "KD ‚Üí ['KD', '⁄©ÿ≥€å', '⁄©ÿ≥']\n",
      "AA ‚Üí ['AA', 'ÿ≥⁄©ÿ™€í', '⁄Ø€åÿß']\n",
      "QW ‚Üí ['QW', '⁄©€åÿß', '⁄©€åŸà⁄∫']\n",
      "KER ‚Üí ['KER', '⁄©ÿ±']\n",
      "OR ‚Üí ['OR', 'ÿØŸàŸÜŸà⁄∫', 'ÿ≥ÿßÿ™Ÿà€å⁄∫']\n",
      "AKP ‚Üí ['AKP', '⁄©€Å€å⁄∫', '⁄©€åÿ≥€í']\n",
      "MUL ‚Üí ['MUL', 'ÿ¥ÿßŸæŸÜ⁄Ø', 'ÿßŸÅÿ∑ÿßÿ±']\n",
      "INT ‚Üí ['INT', 'Ÿàÿß€Å', 'ÿßŸÑŸÇÿßÿØÿ±€å']\n",
      "AD ‚Üí ['AD', 'ÿß€åÿ≥€å']\n",
      "FR ‚Üí ['FR', 'ÿ¢ÿØ⁄æ€í', 'ÿ≥ÿß⁄ë⁄æ€í']\n",
      "DATE ‚Üí ['DATE', '‚Äô', '‚Äù']\n",
      "RD ‚Üí ['RD', 'ÿ¨ÿ™ŸÜ€í', 'js']\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Define Prompt Template\n",
    "# ==============================\n",
    "template = ManualTemplate(\n",
    "    text='ŸÑŸÅÿ∏: {\"placeholder\":\"text_a\"} ‚Üí ÿ≠ÿµ€Å ⁄©ŸÑÿßŸÖ: {\"mask\"}',\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    " \n",
    "# Group words by POS tag\n",
    "tag_to_words = defaultdict(list)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    word = str(row[\"word\"]).strip()\n",
    "    tag = row[\"tag\"]\n",
    "    if word and word not in tag_to_words[tag]:\n",
    "        tag_to_words[tag].append(word)\n",
    "\n",
    "# Build verbalizer map\n",
    "label_words_map = {}\n",
    "\n",
    "for tag in classes:\n",
    "    examples = tag_to_words.get(tag, [])\n",
    "\n",
    "    # Take first 2 words if available\n",
    "    sample_words = examples[:2]\n",
    "\n",
    "    # Always include the tag itself\n",
    "    label_words_map[tag] = [tag] + sample_words\n",
    "\n",
    "\n",
    "verbalizer = ManualVerbalizer(\n",
    "    classes=classes,\n",
    "    label_words=label_words_map,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nüìò FINAL VERBALIZER CONTENT:\\n\")\n",
    "\n",
    "for tag, words in label_words_map.items():\n",
    "    print(f\"{tag} ‚Üí {words}\")\n",
    "\n",
    " \n",
    "\n",
    "# ==============================\n",
    "# Create Prompt Model\n",
    "# ==============================\n",
    "prompt_model = PromptForClassification(\n",
    "    template=template,\n",
    "    plm=plm,\n",
    "    verbalizer=verbalizer\n",
    ")\n",
    "# prompt_model = prompt_model.to(device)\n",
    "# prompt_model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d84c20-e009-44e6-987d-33b0e57fec19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 627it [00:00, 2515.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 248.5424\n",
      "Epoch 2 Loss: 129.0269\n",
      "Epoch 3 Loss: 87.9056\n",
      "Epoch 4 Loss: 60.9828\n",
      "Epoch 5 Loss: 56.5743\n",
      "Epoch 6 Loss: 38.4644\n",
      "Epoch 7 Loss: 37.7544\n",
      "Epoch 8 Loss: 33.3675\n",
      "Epoch 9 Loss: 28.4013\n",
      "Epoch 10 Loss: 27.2644\n",
      "Epoch 11 Loss: 25.8812\n",
      "Epoch 12 Loss: 27.5564\n",
      "Epoch 13 Loss: 24.7527\n",
      "Epoch 14 Loss: 25.6735\n",
      "Epoch 15 Loss: 29.6333\n",
      "Epoch 16 Loss: 24.1659\n",
      "Epoch 17 Loss: 24.1308\n",
      "Epoch 18 Loss: 22.8382\n",
      "Epoch 19 Loss: 22.4680\n",
      "Epoch 20 Loss: 21.0522\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# DataLoader for Training\n",
    "# ==============================\n",
    "train_loader = PromptDataLoader(\n",
    "    dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    template=template,\n",
    "    tokenizer_wrapper_class=WrapperClass,\n",
    "    max_seq_length=128,\n",
    "    batch_size=4,\n",
    "    shuffle=True  # reproducibility preserved by seed\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt_model.train()\n",
    "optimizer = AdamW(prompt_model.parameters(), lr=1e-5)\n",
    "\n",
    "for epoch in range(20):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = prompt_model(batch)\n",
    "        loss = torch.nn.CrossEntropyLoss()(logits, batch['label'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n",
    "# ==============================\n",
    "# Fine-Tuning the Prompt Model\n",
    "# ==============================\n",
    "# prompt_model.train()\n",
    "# optimizer = AdamW(prompt_model.parameters(), lr=1e-5)\n",
    "\n",
    "# for epoch in range(20):\n",
    "#     torch.cuda.empty_cache()\n",
    "#     total_loss = 0\n",
    "#     for batch in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         # Move batch to device\n",
    "#         batch = {k: v.to(device) if torch.is_tensor(v) else v for k, v in batch.items()}\n",
    "#         logits = prompt_model(batch)\n",
    "#         loss = torch.nn.CrossEntropyLoss()(logits, batch['label'])\n",
    "#         if torch.isnan(loss):\n",
    "#             print(\"NaN detected!\")\n",
    "#             print(\"Logits:\", logits)\n",
    "#             print(\"Labels:\", batch[\"label\"])\n",
    "#             break        \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "#     print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd656a81-2b72-44ed-a82e-1a4f0a99aa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 86676it [00:37, 2325.96it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==============================\n",
    "# Prepare Evaluation Dataset\n",
    "# ==============================\n",
    "df_eval = pd.read_csv(r\"C:\\Users\\stdFurqan\\Desktop\\paft\\pos\\test.csv\")  # columns: 'word', 'tag'\n",
    "eval_dataset = [\n",
    "    InputExample(guid=str(i), text_a=row['word'], label=label_map[row['tag']])\n",
    "    for i, row in df_eval.iterrows()\n",
    "]\n",
    "\n",
    "# ==============================\n",
    "# DataLoader for Evaluation\n",
    "# ==============================\n",
    "eval_loader = PromptDataLoader(\n",
    "    dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    template=template,\n",
    "    tokenizer_wrapper_class=WrapperClass,\n",
    "    max_seq_length=128,\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# Evaluate Model\n",
    "# ==============================\n",
    "prompt_model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in eval_loader:\n",
    "        # Move tensors to device\n",
    "        # batch = {k: v.to(device) if torch.is_tensor(v) else v for k, v in batch.items()}\n",
    "        logits = prompt_model(batch)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_labels.extend(batch['label'].cpu().tolist())\n",
    "\n",
    "# # ==============================\n",
    "# # Classification Report\n",
    "# # ==============================\n",
    "# print(\"\\nüìä POS Tagging Classification Report:\")\n",
    "# print(classification_report(all_labels, all_preds, target_names=classes, digits=4))\n",
    "# # ==============================\n",
    "# # Classification Report (FIXED)\n",
    "# # ==============================\n",
    "\n",
    "# all_label_ids = list(range(len(classes)))  # [0, 1, 2, ..., 39]\n",
    "\n",
    "# print(\"\\nüìä POS Tagging Classification Report:\")\n",
    "# print(\n",
    "#     classification_report(\n",
    "#         all_labels,\n",
    "#         all_preds,\n",
    "#         labels=all_label_ids,      # üëà IMPORTANT FIX\n",
    "#         target_names=classes,\n",
    "#         digits=4,\n",
    "#         zero_division=0\n",
    "#     )\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db33ae5-9acc-4fed-963e-7cd5a0765186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä POS Tagging Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          PN     0.3514    0.2851    0.3148      6065\n",
      "           G     0.4299    0.9515    0.5923       474\n",
      "          NN     0.7692    0.3514    0.4824     21792\n",
      "           P     0.9470    0.9806    0.9635     10256\n",
      "           U     0.0233    1.0000    0.0456        40\n",
      "          VB     0.6170    0.3049    0.4081     10060\n",
      "          SM     0.9991    0.9281    0.9623      3464\n",
      "          PM     0.9918    0.8820    0.9337      1924\n",
      "          PP     0.8483    0.4958    0.6258      3316\n",
      "          CC     0.9328    0.9954    0.9631      1938\n",
      "         ADJ     0.2753    0.1919    0.2261      5342\n",
      "          CA     0.4731    0.7584    0.5827      1763\n",
      "          RP     0.8830    0.9881    0.9326        84\n",
      "          SC     0.9623    0.6518    0.7771      2504\n",
      "          SE     0.8546    1.0000    0.9216      1440\n",
      "         ADV     0.3278    0.7351    0.4534      1480\n",
      "         EXP     0.2306    0.8274    0.3606       197\n",
      "           I     0.7386    0.9389    0.8268      1800\n",
      "         NEG     0.8669    1.0000    0.9287      1062\n",
      "          TA     0.5941    0.6677    0.6288      3181\n",
      "          AP     0.5463    0.9718    0.6994       710\n",
      "           Q     0.6192    0.5603    0.5883      1219\n",
      "          PD     0.3517    0.9948    0.5196      1164\n",
      "        WALA     0.8605    1.0000    0.9250       253\n",
      "          KP     0.1239    0.6577    0.2086       111\n",
      "          GR     0.9954    1.0000    0.9977       437\n",
      "         REP     0.8158    1.0000    0.8986       589\n",
      "           A     0.1933    0.9175    0.3193       206\n",
      "          KD     0.9890    0.8404    0.9086       213\n",
      "          AA     0.5704    0.6363    0.6016      2571\n",
      "          QW     0.3120    1.0000    0.4756       219\n",
      "         KER     0.2104    1.0000    0.3476       211\n",
      "          OR     0.3401    0.8772    0.4902       171\n",
      "         AKP     0.2668    0.8949    0.4111       257\n",
      "         MUL     0.0010    0.2222    0.0020        27\n",
      "         INT     0.0709    0.7966    0.1302        59\n",
      "          AD     0.2656    1.0000    0.4198        51\n",
      "          FR     0.0299    1.0000    0.0581        26\n",
      "        DATE     0.0000    0.0000    0.0000         0\n",
      "          RD     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.5764     86676\n",
      "   macro avg     0.5170    0.7576    0.5483     86676\n",
      "weighted avg     0.6965    0.5764    0.5978     86676\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Classification Report\n",
    "# ==============================\n",
    "print(\"\\nüìä POS Tagging Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=classes, digits=4))\n",
    "# ==============================\n",
    "# Classification Report (FIXED)\n",
    "# ==============================\n",
    "\n",
    "# all_label_ids = list(range(len(classes)))  # [0, 1, 2, ..., 39]\n",
    "\n",
    "# print(\"\\nüìä POS Tagging Classification Report:\")\n",
    "# print(\n",
    "#     classification_report(\n",
    "#         all_labels,\n",
    "#         all_preds,\n",
    "#         labels=all_label_ids,      # üëà IMPORTANT FIX\n",
    "#         target_names=classes,\n",
    "#         digits=4,\n",
    "#         zero_division=0\n",
    "#     )\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dddbf1-07fe-446e-bfd2-cfced30c0cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b653ad-0a57-4da8-880d-588f5a245d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbert\n",
    "\n",
    "üìä POS Tagging Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          PN     0.3514    0.2851    0.3148      6065\n",
    "           G     0.4299    0.9515    0.5923       474\n",
    "          NN     0.7692    0.3514    0.4824     21792\n",
    "           P     0.9470    0.9806    0.9635     10256\n",
    "           U     0.0233    1.0000    0.0456        40\n",
    "          VB     0.6170    0.3049    0.4081     10060\n",
    "          SM     0.9991    0.9281    0.9623      3464\n",
    "          PM     0.9918    0.8820    0.9337      1924\n",
    "          PP     0.8483    0.4958    0.6258      3316\n",
    "          CC     0.9328    0.9954    0.9631      1938\n",
    "         ADJ     0.2753    0.1919    0.2261      5342\n",
    "          CA     0.4731    0.7584    0.5827      1763\n",
    "          RP     0.8830    0.9881    0.9326        84\n",
    "          SC     0.9623    0.6518    0.7771      2504\n",
    "          SE     0.8546    1.0000    0.9216      1440\n",
    "         ADV     0.3278    0.7351    0.4534      1480\n",
    "         EXP     0.2306    0.8274    0.3606       197\n",
    "           I     0.7386    0.9389    0.8268      1800\n",
    "         NEG     0.8669    1.0000    0.9287      1062\n",
    "          TA     0.5941    0.6677    0.6288      3181\n",
    "          AP     0.5463    0.9718    0.6994       710\n",
    "           Q     0.6192    0.5603    0.5883      1219\n",
    "          PD     0.3517    0.9948    0.5196      1164\n",
    "        WALA     0.8605    1.0000    0.9250       253\n",
    "          KP     0.1239    0.6577    0.2086       111\n",
    "          GR     0.9954    1.0000    0.9977       437\n",
    "         REP     0.8158    1.0000    0.8986       589\n",
    "           A     0.1933    0.9175    0.3193       206\n",
    "          KD     0.9890    0.8404    0.9086       213\n",
    "          AA     0.5704    0.6363    0.6016      2571\n",
    "          QW     0.3120    1.0000    0.4756       219\n",
    "         KER     0.2104    1.0000    0.3476       211\n",
    "          OR     0.3401    0.8772    0.4902       171\n",
    "         AKP     0.2668    0.8949    0.4111       257\n",
    "         MUL     0.0010    0.2222    0.0020        27\n",
    "         INT     0.0709    0.7966    0.1302        59\n",
    "          AD     0.2656    1.0000    0.4198        51\n",
    "          FR     0.0299    1.0000    0.0581        26\n",
    "        DATE     0.0000    0.0000    0.0000         0\n",
    "          RD     0.0000    0.0000    0.0000         0\n",
    "\n",
    "    accuracy                         0.5764     86676\n",
    "   macro avg     0.5170    0.7576    0.5483     86676\n",
    "weighted avg     0.6965    0.5764    0.5978     86676"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
