{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e5e14a-f435-4fea-8c1e-027967121ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Get user profile path\n",
    "user_profile = os.environ[\"USERPROFILE\"]\n",
    "\n",
    "# Paths to Hugging Face cached models\n",
    "cached_models = [\n",
    "    os.path.join(user_profile, r\".cache\\huggingface\\hub\\models--bert-base-multilingual-cased\"),\n",
    "    os.path.join(user_profile, r\".cache\\huggingface\\hub\\models--xlm-roberta-base\")\n",
    "]\n",
    "\n",
    "# Remove cached models if they exist\n",
    "for path in cached_models:\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "        print(f\"Removed cache: {path}\")\n",
    "    else:\n",
    "        print(f\"No cache found at: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42fb3673-e6d3-4c1b-b9e3-d3e62a80313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15579873-a110-4b82-b1b9-5db067858a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 4080 SUPER\n",
      "CUDA version: 12.1\n",
      "GPU count: 1\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Imports\n",
    "# ==============================\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForMaskedLM\n",
    "from openprompt.prompts import ManualTemplate, ManualVerbalizer\n",
    "from openprompt.data_utils import InputExample\n",
    "from openprompt.plms import load_plm\n",
    "from openprompt import PromptForClassification, PromptDataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader, Sampler\n",
    "\n",
    "# ========================================\n",
    "# Check CUDA\n",
    "# ========================================\n",
    "device = \"cuda\" #if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU count:\", torch.cuda.device_count())\n",
    "\n",
    "# ========================================\n",
    "# Seeds for reproducibility\n",
    "# ========================================\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ccd5428-2982-48ce-aa9e-b83708883d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Define Classes\n",
    "# ==============================\n",
    "classes = [\"unacc\", \"acc\"]\n",
    "label_map = {\"unacc\": 0, \"acc\": 1}\n",
    "\n",
    "# # Step 1: Use load_plm with 'roberta' to get the correct WrapperClass\n",
    "_, _, _, WrapperClass = load_plm(\"roberta\", \"roberta-base\")  # Just to get the wrapper\n",
    "\n",
    "# # Step 2: Manually load XLM-RoBERTa model/tokenizer\n",
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)\n",
    "plm = XLMRobertaForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "# ==============================\n",
    "# Load Pretrained Language Model (mBERT)\n",
    "# ==============================\n",
    "# plm, tokenizer, model_config, WrapperClass = load_plm(\"bert\", \"bert-base-multilingual-cased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27e18e97-ead9-482a-b46c-8e037627b4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Define Prompt Template (Manual)\n",
    "# ==============================\n",
    "template = ManualTemplate(\n",
    "    # text = '{\"placeholder\":\"text_a\"} Ÿáÿ∞Ÿá ÿßŸÑÿ¨ŸÖŸÑÿ© {\"mask\"}.',\n",
    "    text='{\"placeholder\":\"text_a\"} €å€Å ÿ¨ŸÖŸÑ€Å {\"mask\"} €Å€í€î',\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "templates = [\n",
    "    (\"P1\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} €å€Å ÿ¨ŸÖŸÑ€Å {\"mask\"} €Å€í€î',  # Keep as is\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "    (\"P2\", ManualTemplate(\n",
    "        text='ÿØ€å ⁄Øÿ¶€å ÿπÿ®ÿßÿ±ÿ™: {\"placeholder\":\"text_a\"} ⁄©ÿß ŸÖŸàÿßÿØ ÿßŸàÿ± Ÿæ€åÿ∫ÿßŸÖ {\"mask\"} €Å€í€î',  # generalized for neg/pos\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "    (\"P3\", ManualTemplate(\n",
    "        text='ÿßÿ≥ ÿπÿ®ÿßÿ±ÿ™ ⁄©ÿß ÿ™ÿ¨ÿ≤€å€Å ⁄©ÿ±€å⁄∫: {\"placeholder\":\"text_a\"} ÿßÿ≥ ⁄©ÿß ÿßÿ≠ÿ≥ÿßÿ≥ €åÿß ŸÖŸà⁄à {\"mask\"} €Å€í€î',  # focuses on sentiment/intent\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "    (\"P4\", ManualTemplate(\n",
    "        text='ÿ¨ŸÖŸÑ€Å: {\"placeholder\":\"text_a\"} €ÅŸÖ€å⁄∫ ÿ®ÿ™ÿßÿ™ÿß €Å€í ⁄©€Å €å€Å ŸÖŸàÿßÿØ {\"mask\"} €Å€í€î',  # clear statement aligned with label\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "    (\"P5\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} ÿßÿ≥ ÿπÿ®ÿßÿ±ÿ™ ⁄©ÿß ŸÖÿ∑ŸÑÿ® {\"mask\"} €Å€í€î',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "    (\"P6\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} ÿßÿ≥ ŸÖÿπÿßŸÖŸÑ€í ŸÖ€å⁄∫ ÿ≠ÿ™ŸÖ€å ÿ±ÿßÿ¶€í {\"mask\"}',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "    (\"P7\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} ÿßÿ≥ ŸÖŸàÿßÿØ ⁄©€å ÿ™ÿ¥ÿ±€åÿ≠ {\"mask\"}',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "    (\"P8\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} ÿßÿ≥ ÿ≠ŸàÿßŸÑ€í ÿ≥€í ŸÅ€åÿµŸÑ€Å {\"mask\"}',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "    (\"P9\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} ÿßÿ≥ ŸÖÿ™ŸÜ ⁄©€å ÿØÿ±ÿ¨€Å ÿ®ŸÜÿØ€å {\"mask\"}',\n",
    "        tokenizer=tokenizer,\n",
    "    )),\n",
    "    (\"P10\", ManualTemplate(\n",
    "        text='{\"placeholder\":\"text_a\"} ÿßÿ≥ ÿßÿ∏€Åÿßÿ± ⁄©ÿß ŸÜÿ™€åÿ¨€Å {\"mask\"}',\n",
    "        tokenizer=tokenizer,\n",
    "    )), \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Define Verbalizer (Manual)\n",
    "# ==============================\n",
    "verbalizer = ManualVerbalizer(\n",
    "    classes=classes,\n",
    "    label_words = {\n",
    "        \"acc\": [\"ÿµÿ≠€åÿ≠\",\"ÿØÿ±ÿ≥ÿ™\"], \n",
    "       \"unacc\": [\"ŸÜÿß ÿØÿ±ÿ≥ÿ™\",\"ÿ∫ŸÑÿ∑\"]\n",
    "    },\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbfa212f-f27f-4f80-97e5-96ef3e2ab9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Create Prompt Model\n",
    "# ==============================\n",
    "prompt_model = PromptForClassification(\n",
    "    template=template,\n",
    "    plm=plm,\n",
    "    verbalizer=verbalizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fcb89e0-6506-458c-963e-664fcb5e5660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üü¶ 0-Shot Evaluation - Template P1 (1/10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 1043it [00:00, 3007.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STS_B Urdu Dev Classification Report - Template P1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       unacc     0.2222    0.0062    0.0121       322\n",
      "         acc     0.6905    0.9903    0.8137       721\n",
      "\n",
      "    accuracy                         0.6865      1043\n",
      "   macro avg     0.4564    0.4983    0.4129      1043\n",
      "weighted avg     0.5459    0.6865    0.5662      1043\n",
      "\n",
      "\n",
      "üü¶ 0-Shot Evaluation - Template P2 (2/10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 1043it [00:00, 2548.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STS_B Urdu Dev Classification Report - Template P2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       unacc     0.3423    0.3168    0.3290       322\n",
      "         acc     0.7047    0.7282    0.7162       721\n",
      "\n",
      "    accuracy                         0.6012      1043\n",
      "   macro avg     0.5235    0.5225    0.5226      1043\n",
      "weighted avg     0.5928    0.6012    0.5967      1043\n",
      "\n",
      "\n",
      "üü¶ 0-Shot Evaluation - Template P3 (3/10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 1043it [00:00, 2469.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STS_B Urdu Dev Classification Report - Template P3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       unacc     0.3022    0.2112    0.2486       322\n",
      "         acc     0.6895    0.7822    0.7329       721\n",
      "\n",
      "    accuracy                         0.6059      1043\n",
      "   macro avg     0.4959    0.4967    0.4908      1043\n",
      "weighted avg     0.5699    0.6059    0.5834      1043\n",
      "\n",
      "\n",
      "üü¶ 0-Shot Evaluation - Template P4 (4/10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 1043it [00:00, 2398.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STS_B Urdu Dev Classification Report - Template P4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       unacc     0.1818    0.0186    0.0338       322\n",
      "         acc     0.6871    0.9626    0.8018       721\n",
      "\n",
      "    accuracy                         0.6711      1043\n",
      "   macro avg     0.4345    0.4906    0.4178      1043\n",
      "weighted avg     0.5311    0.6711    0.5647      1043\n",
      "\n",
      "\n",
      "üü¶ 0-Shot Evaluation - Template P5 (5/10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 1043it [00:00, 2854.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STS_B Urdu Dev Classification Report - Template P5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       unacc     0.2588    0.2981    0.2771       322\n",
      "         acc     0.6637    0.6186    0.6403       721\n",
      "\n",
      "    accuracy                         0.5197      1043\n",
      "   macro avg     0.4612    0.4584    0.4587      1043\n",
      "weighted avg     0.5387    0.5197    0.5282      1043\n",
      "\n",
      "\n",
      "üü¶ 0-Shot Evaluation - Template P6 (6/10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 1043it [00:00, 2998.06it/s]\n",
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STS_B Urdu Dev Classification Report - Template P6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       unacc     0.3087    1.0000    0.4718       322\n",
      "         acc     0.0000    0.0000    0.0000       721\n",
      "\n",
      "    accuracy                         0.3087      1043\n",
      "   macro avg     0.1544    0.5000    0.2359      1043\n",
      "weighted avg     0.0953    0.3087    0.1457      1043\n",
      "\n",
      "\n",
      "üü¶ 0-Shot Evaluation - Template P7 (7/10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 1043it [00:00, 3422.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STS_B Urdu Dev Classification Report - Template P7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       unacc     0.2835    0.6957    0.4029       322\n",
      "         acc     0.6126    0.2150    0.3183       721\n",
      "\n",
      "    accuracy                         0.3634      1043\n",
      "   macro avg     0.4481    0.4553    0.3606      1043\n",
      "weighted avg     0.5110    0.3634    0.3444      1043\n",
      "\n",
      "\n",
      "üü¶ 0-Shot Evaluation - Template P8 (8/10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 1043it [00:00, 3317.56it/s]\n",
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STS_B Urdu Dev Classification Report - Template P8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       unacc     0.3087    1.0000    0.4718       322\n",
      "         acc     0.0000    0.0000    0.0000       721\n",
      "\n",
      "    accuracy                         0.3087      1043\n",
      "   macro avg     0.1544    0.5000    0.2359      1043\n",
      "weighted avg     0.0953    0.3087    0.1457      1043\n",
      "\n",
      "\n",
      "üü¶ 0-Shot Evaluation - Template P9 (9/10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 1043it [00:00, 3186.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STS_B Urdu Dev Classification Report - Template P9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       unacc     0.3075    0.9224    0.4612       322\n",
      "         acc     0.6753    0.0721    0.1303       721\n",
      "\n",
      "    accuracy                         0.3346      1043\n",
      "   macro avg     0.4914    0.4972    0.2958      1043\n",
      "weighted avg     0.5618    0.3346    0.2325      1043\n",
      "\n",
      "\n",
      "üü¶ 0-Shot Evaluation - Template P10 (10/10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 1043it [00:00, 3300.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STS_B Urdu Dev Classification Report - Template P10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       unacc     0.2976    0.8012    0.4340       322\n",
      "         acc     0.6364    0.1553    0.2497       721\n",
      "\n",
      "    accuracy                         0.3547      1043\n",
      "   macro avg     0.4670    0.4783    0.3418      1043\n",
      "weighted avg     0.5318    0.3547    0.3066      1043\n",
      "\n",
      "\n",
      "‚úÖ Templates used per pass: {'pass_1': 'P1', 'pass_2': 'P2', 'pass_3': 'P3', 'pass_4': 'P4', 'pass_5': 'P5', 'pass_6': 'P6', 'pass_7': 'P7', 'pass_8': 'P8', 'pass_9': 'P9', 'pass_10': 'P10'}\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Load Evaluation Dataset\n",
    "# ==============================\n",
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\stdFurqan\\Desktop\\paft\\cola_dataset\\final_ColA_Dev_Urdu_labeled - Sheet1.csv\"\n",
    ")\n",
    "\n",
    "# Make InputExamples\n",
    "eval_dataset = [\n",
    "    InputExample(guid=i, text_a=row['Urdu Sentence'], label=label_map[row['label']])\n",
    "    for i, row in df.iterrows()\n",
    "]\n",
    "\n",
    "# ==============================\n",
    "# 0-Shot Evaluation with Each Template\n",
    "# ==============================\n",
    "prompt_model.eval()  # ensure model is in evaluation mode\n",
    "batch_size = 8    # eval batch size\n",
    "\n",
    "# Optional: store template order and results\n",
    "all_pass_patterns = {}\n",
    "\n",
    "for pass_idx, (prompt_name, current_template) in enumerate(templates, start=1):\n",
    "    print(f\"\\nüü¶ 0-Shot Evaluation - Template {prompt_name} ({pass_idx}/{len(templates)})\")\n",
    "\n",
    "    # Create PromptDataLoader with current template\n",
    "    eval_loader = PromptDataLoader(\n",
    "        dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        template=current_template,\n",
    "        tokenizer_wrapper_class=WrapperClass,\n",
    "        max_seq_length=128,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    pass_preds = []\n",
    "    pass_labels = []\n",
    "\n",
    "    # Run evaluation\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            logits = prompt_model(batch)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            pass_preds.extend(preds.cpu().tolist())\n",
    "            pass_labels.extend(batch['label'].cpu().tolist())\n",
    "\n",
    "    # Print report immediately after this template\n",
    "    print(f\"\\nüìä STS_B Urdu Dev Classification Report - Template {prompt_name}\")\n",
    "    print(classification_report(pass_labels, pass_preds, target_names=classes, digits=4))\n",
    "\n",
    "    # Store template name (optional)\n",
    "    all_pass_patterns[f\"pass_{pass_idx}\"] = prompt_name\n",
    "\n",
    "# Optional: print template order at the end\n",
    "print(\"\\n‚úÖ Templates used per pass:\", all_pass_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d822b-6839-499d-9698-ea98adfb19f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Roberta\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P1 (1/10)\n",
    "tokenizing: 1043it [00:00, 3007.73it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P1\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.2222    0.0062    0.0121       322\n",
    "         acc     0.6905    0.9903    0.8137       721\n",
    "\n",
    "    accuracy                         0.6865      1043\n",
    "   macro avg     0.4564    0.4983    0.4129      1043\n",
    "weighted avg     0.5459    0.6865    0.5662      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P2 (2/10)\n",
    "tokenizing: 1043it [00:00, 2548.50it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P2\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.3423    0.3168    0.3290       322\n",
    "         acc     0.7047    0.7282    0.7162       721\n",
    "\n",
    "    accuracy                         0.6012      1043\n",
    "   macro avg     0.5235    0.5225    0.5226      1043\n",
    "weighted avg     0.5928    0.6012    0.5967      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P3 (3/10)\n",
    "tokenizing: 1043it [00:00, 2469.83it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P3\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.3022    0.2112    0.2486       322\n",
    "         acc     0.6895    0.7822    0.7329       721\n",
    "\n",
    "    accuracy                         0.6059      1043\n",
    "   macro avg     0.4959    0.4967    0.4908      1043\n",
    "weighted avg     0.5699    0.6059    0.5834      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P4 (4/10)\n",
    "tokenizing: 1043it [00:00, 2398.71it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P4\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.1818    0.0186    0.0338       322\n",
    "         acc     0.6871    0.9626    0.8018       721\n",
    "\n",
    "    accuracy                         0.6711      1043\n",
    "   macro avg     0.4345    0.4906    0.4178      1043\n",
    "weighted avg     0.5311    0.6711    0.5647      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P5 (5/10)\n",
    "tokenizing: 1043it [00:00, 2854.27it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P5\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.2588    0.2981    0.2771       322\n",
    "         acc     0.6637    0.6186    0.6403       721\n",
    "\n",
    "    accuracy                         0.5197      1043\n",
    "   macro avg     0.4612    0.4584    0.4587      1043\n",
    "weighted avg     0.5387    0.5197    0.5282      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P6 (6/10)\n",
    "tokenizing: 1043it [00:00, 2998.06it/s]\n",
    "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P6\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.3087    1.0000    0.4718       322\n",
    "         acc     0.0000    0.0000    0.0000       721\n",
    "\n",
    "    accuracy                         0.3087      1043\n",
    "   macro avg     0.1544    0.5000    0.2359      1043\n",
    "weighted avg     0.0953    0.3087    0.1457      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P7 (7/10)\n",
    "tokenizing: 1043it [00:00, 3422.37it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P7\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.2835    0.6957    0.4029       322\n",
    "         acc     0.6126    0.2150    0.3183       721\n",
    "\n",
    "    accuracy                         0.3634      1043\n",
    "   macro avg     0.4481    0.4553    0.3606      1043\n",
    "weighted avg     0.5110    0.3634    0.3444      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P8 (8/10)\n",
    "tokenizing: 1043it [00:00, 3317.56it/s]\n",
    "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P8\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.3087    1.0000    0.4718       322\n",
    "         acc     0.0000    0.0000    0.0000       721\n",
    "\n",
    "    accuracy                         0.3087      1043\n",
    "   macro avg     0.1544    0.5000    0.2359      1043\n",
    "weighted avg     0.0953    0.3087    0.1457      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P9 (9/10)\n",
    "tokenizing: 1043it [00:00, 3186.07it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P9\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.3075    0.9224    0.4612       322\n",
    "         acc     0.6753    0.0721    0.1303       721\n",
    "\n",
    "    accuracy                         0.3346      1043\n",
    "   macro avg     0.4914    0.4972    0.2958      1043\n",
    "weighted avg     0.5618    0.3346    0.2325      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P10 (10/10)\n",
    "tokenizing: 1043it [00:00, 3300.70it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P10\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.2976    0.8012    0.4340       322\n",
    "         acc     0.6364    0.1553    0.2497       721\n",
    "\n",
    "    accuracy                         0.3547      1043\n",
    "   macro avg     0.4670    0.4783    0.3418      1043\n",
    "weighted avg     0.5318    0.3547    0.3066      1043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2396914e-bd62-490c-953b-b8c11667941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MBERT\n",
    "üü¶ 0-Shot Evaluation - Template P1 (1/10)\n",
    "tokenizing: 1043it [00:00, 3609.98it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P1\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.3119    0.6025    0.4110       322\n",
    "         acc     0.6960    0.4064    0.5131       721\n",
    "\n",
    "    accuracy                         0.4669      1043\n",
    "   macro avg     0.5039    0.5044    0.4621      1043\n",
    "weighted avg     0.5774    0.4669    0.4816      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P2 (2/10)\n",
    "tokenizing: 1043it [00:00, 1738.66it/s]\n",
    "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "C:\\Users\\stdFurqan\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
    "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P2\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.0000    0.0000    0.0000       322\n",
    "         acc     0.6913    1.0000    0.8175       721\n",
    "\n",
    "    accuracy                         0.6913      1043\n",
    "   macro avg     0.3456    0.5000    0.4087      1043\n",
    "weighted avg     0.4779    0.6913    0.5651      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P3 (3/10)\n",
    "tokenizing: 1043it [00:00, 1631.28it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P3\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.3310    0.8634    0.4785       322\n",
    "         acc     0.7833    0.2205    0.3442       721\n",
    "\n",
    "    accuracy                         0.4190      1043\n",
    "   macro avg     0.5571    0.5419    0.4113      1043\n",
    "weighted avg     0.6436    0.4190    0.3856      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P4 (4/10)\n",
    "tokenizing: 1043it [00:00, 1837.70it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P4\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.3345    0.5807    0.4245       322\n",
    "         acc     0.7211    0.4840    0.5793       721\n",
    "\n",
    "    accuracy                         0.5139      1043\n",
    "   macro avg     0.5278    0.5324    0.5019      1043\n",
    "weighted avg     0.6017    0.5139    0.5315      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P5 (5/10)\n",
    "tokenizing: 1043it [00:00, 2850.99it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P5\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.3487    0.4224    0.3820       322\n",
    "         acc     0.7152    0.6477    0.6798       721\n",
    "\n",
    "    accuracy                         0.5781      1043\n",
    "   macro avg     0.5319    0.5350    0.5309      1043\n",
    "weighted avg     0.6020    0.5781    0.5878      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P6 (6/10)\n",
    "tokenizing: 1043it [00:00, 3509.68it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P6\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.3186    0.4472    0.3721       322\n",
    "         acc     0.6988    0.5728    0.6296       721\n",
    "\n",
    "    accuracy                         0.5340      1043\n",
    "   macro avg     0.5087    0.5100    0.5008      1043\n",
    "weighted avg     0.5814    0.5340    0.5501      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P7 (7/10)\n",
    "tokenizing: 1043it [00:00, 2102.33it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P7\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.1667    0.0093    0.0176       322\n",
    "         acc     0.6888    0.9792    0.8087       721\n",
    "\n",
    "    accuracy                         0.6798      1043\n",
    "   macro avg     0.4277    0.4943    0.4132      1043\n",
    "weighted avg     0.5276    0.6798    0.5645      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P8 (8/10)\n",
    "tokenizing: 1043it [00:00, 2303.86it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P8\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.3127    0.8789    0.4613       322\n",
    "         acc     0.7174    0.1373    0.2305       721\n",
    "\n",
    "    accuracy                         0.3663      1043\n",
    "   macro avg     0.5150    0.5081    0.3459      1043\n",
    "weighted avg     0.5925    0.3663    0.3018      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P9 (9/10)\n",
    "tokenizing: 1043it [00:00, 2174.24it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P9\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.2713    0.4255    0.3313       322\n",
    "         acc     0.6561    0.4896    0.5608       721\n",
    "\n",
    "    accuracy                         0.4698      1043\n",
    "   macro avg     0.4637    0.4575    0.4460      1043\n",
    "weighted avg     0.5373    0.4698    0.4899      1043\n",
    "\n",
    "\n",
    "üü¶ 0-Shot Evaluation - Template P10 (10/10)\n",
    "tokenizing: 1043it [00:00, 2084.16it/s]\n",
    "\n",
    "üìä STS_B Urdu Dev Classification Report - Template P10\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "       unacc     0.3087    1.0000    0.4718       322\n",
    "         acc     0.0000    0.0000    0.0000       721\n",
    "\n",
    "    accuracy                         0.3087      1043\n",
    "   macro avg     0.1544    0.5000    0.2359      1043\n",
    "weighted avg     0.0953    0.3087    0.1457      1043"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
